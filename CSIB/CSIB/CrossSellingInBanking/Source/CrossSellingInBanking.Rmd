---
title: '<br>
 <img style="background: #FDE70F;" src="https://www.fhnw.ch/de/++theme++web16theme/assets/media/img/fachhochschule-nordwestschweiz-fhnw-logo.svg" alt="FHNW Logo" height="50rem" id="logo">
  <br><br>Challenge: Cross Selling in Banking (CED1)'
author: Gisler Luca, Heeb Christian, Studer Aaron, Bécheiraz Léonie
date: "`r format(Sys.time(), '%d.%m.%y')`"
output:
   html_document:
      toc: true
      toc_depth: 6
      toc_float: true
      collapsed: false
      code_folding: show
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE,
                      warning = FALSE)
```

```{=html}
<style type="text/css" media="screen">
h1, h2, h3 {
    color: #4D4D4D;
   }

.list-group-item.active {
    background-color: #FDE70F;
    border-color: #FDE70F;
    color: #4D4D4D;
    font-weight: bold;
}

#logo {
    padding-left: 1rem;
}

</style>
```
## Aufgabenstellung

### Allgemein[^1]

[^1]: Erstellt von Christian Heeb

Eine tschechische Bank möchte ihre Dienstleistungen für Privatkunden
verbessern und "interessante Kundengruppen" identifizieren. Die
Geschäftsleitung hat keine präzise Vorstellung, möchte aber zusätzliches
Business generieren ohne unnötige Risiken einzugehen und Verluste
einzufahren.

Der analytische Auftrag umfasst die folgenden Aufgaben:

-   Qualität und Repräsentativität der Daten zu überprüfen
-   Die Verteilung der einzelnen Datenattribute zu erheben
-   Deren Veränderung über die Zeit zu analysieren
-   Korrelationen zwischen verschiedenen Datenattributen zu
    quantifizieren und zu visualisieren sowie Hypothesen hinsichtlich
    optimaler Produktverkauf / -nutzung zu erstellen

### Datengrundlage

Wir erhalten die Daten von einer Tschechischen Bank. Die Datengrundlage
ist auf [dieser
Webseite](https://sorry.vse.cz/~berka/challenge/PAST/index.html)
beschrieben.

### Datenbeschreibung

Die Datengrundlage enthält 8 verschiedene Tabellen (Data Frames) im .csv
Format mit Total 47 Attributen. Diese Tabellen mit den jeweiligen
Attributen werden hier genauer beschrieben.

Relation disposition (df_raw_disposition): disp_id: record identifier\
client_id: identification of a client\
account_id: identification of an account\
type: type of disposition (owner/user) only owner can issue permanent
orders and ask for a loan

#### ERD Daten IST-Zustand

![ERD Daten IST-Zustand](../Ressources/IST-Zustand.png)

## Setup[^2]

[^2]: Erstellt von Aaron Studer

Notwendige Pakete laden

```{r include=FALSE}
library(tidyverse)
library(ggmosaic)
library(ggalluvial)
library(DALEXtra)
library(visdat)
library(DT)
library(patchwork)
library(ggpubr)
library(ggplot2)
library(plotly)
library(rpart)
library(rpart.plot)
library(randomForest)
library(tidymodels)
library(lubridate)
library(cluster)
library(imputeTS)
#Used to display district information in a map of the Czech Republic.
library(RCzechia)
library(readxl)
library(httr)
library(tidyquant)
library(xts)
library(ggridges)
library(ggfortify)

# Package ROSE (Random Over Sampling Examples) for undersampling Problem
#install.packages("ROSE")
library(ROSE)

tidymodels_prefer()
```

### Setup Account Data Frame

In diesem Schritt wird das Data Frame "Account" vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}

df_raw_account <- read.csv("../xselling_banking_data/account.csv", header = TRUE, sep = ";")

str(df_raw_account)

```

Es wird wie folgt die Spalte 'date' von dem Type Integer zu dem Typ Date
umgewandelt. Dabei brauchen wir die Funktionalitäten von
[Lubridate](https://lubridate.tidyverse.org/). Die Spalte 'frequency'
ist eine kategoriale Variable mit Tschechischen Werten, daher
transformieren wir auch diese Werte auf Englisch.

```{r}

df_account <- df_raw_account %>%
  mutate(date = ymd(date)) %>%
  mutate(frequency = case_when(frequency == "POPLATEK MESICNE" ~ "Monthly",
                              frequency == "POPLATEK TYDNE" ~ "Weekly",
                              frequency == "POPLATEK PO OBRATU" ~ "After_Transaction")
  ) %>%
  arrange(account_id)

rm(df_raw_account)
```

### Setup Client Data Frame

In diesem Schritt wird das Data Frame Account vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_client <- read.csv("../xselling_banking_data/client.csv", header = TRUE, sep = ";")

str(df_raw_client)

```

Es wird wie folgt die Spalte 'birth_number' von dem Type Integer zu dem
Typ Date umgewandelt, zusätzlich nennen wir die Spalte neu
'dateofbirth'. Dabei brauchen wir die Funktionalitäten von
[Lubridate](https://lubridate.tidyverse.org/). Es wird eine neue Spalte
'sex' hinzugefügt, mithilfe der Dokumentation der Daten kennen wir die
Kondition, welches Geschlecht der Kunde hat.

```{r}

df_client <- df_raw_client %>%
  mutate(dateofbirth = case_when(
    strtoi(substr(as.character(birth_number), 3, 3)) > 1 ~ (ymd(birth_number - 5000)),
    TRUE ~ (ymd(birth_number)),
  )) %>%
  mutate(sex = case_when(
    strtoi(substr(as.character(birth_number), 3, 3)) > 1 ~ "Female",
    TRUE  ~ "Male"
  ))

df_client <- df_client %>%
 mutate(dateofbirth = case_when(
   year(ymd(dateofbirth)) > 2000 ~ ymd(dateofbirth) - years(100),
   TRUE ~ ymd(dateofbirth)
 )) %>%
 select(client_id, district_id, dateofbirth, sex) %>%
 arrange(client_id) 

rm(df_raw_client)
```

### Setup Disposition Data Frame

In diesem Schritt wird das Data Frame Disposition vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_disposition <- read.csv("../xselling_banking_data/disp.csv", header = TRUE, sep = ";")

str(df_raw_disposition)

```

In dem Date Frame disposition müssen keine weitere Schritte erledigt
werden für das Transformieren der Daten.

```{r}

df_disposition <- df_raw_disposition %>%
 select(disp_id, client_id, account_id, type) %>%
 arrange(disp_id) 

rm(df_raw_disposition)
```

### Setup Order Data Frame

In diesem Schritt wird das Data Frame Order vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_perm_order <- read.csv("../xselling_banking_data/order.csv", header = TRUE, sep = ";")

str(df_raw_perm_order)

```

In dem Data Frame perm_order müssen wir die kategoriale Variable
'k_symbol' noch übersetzen, da der Name 'k_symbol' nicht ausschlaggeben
ist, benennen wir die Spalte zu 'payment_type' um.

```{r}

df_perm_order <- df_raw_perm_order %>%
 mutate(payment_type = case_when(k_symbol == "POJISTNE" ~ "INSURRANCE",
                              k_symbol == "SIPO" ~ "HOUSEHOLD",
                              k_symbol == "LEASING" ~ "LEASING",
                              k_symbol == "UVER" ~ "LOAN",
                              TRUE ~ "UNKNOWN")
 ) %>%
 select(order_id, account_id, bank_to, account_to, amount, payment_type) %>%
 arrange(order_id) 

rm(df_raw_perm_order)
```

### Setup Transaction Data Frame

In diesem Schritt wird das Data Frame Transaction vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_transaction <- read.csv("../xselling_banking_data/trans.csv", header = TRUE, sep = ";")

str(df_raw_transaction)

```

Es wird wie folgt die Spalte 'date' von dem Type Integer zu dem Typ Date
umgewandelt. Dabei brauchen wir die Funktionalitäten von
[Lubridate](https://lubridate.tidyverse.org/). Die Spalte 'type' muss
von Tschechisch noch auf Englisch übersetzt werden. Dasselbe zählt auch
für die Spalte 'operation' und 'k_symbol'. Jedoch benennen wir die
Splate 'k_symbol' noch um in die neue Spalte 'characterization'.

```{r}

df_transaction <- df_raw_transaction %>%
 mutate(date = ymd(date)) %>%
 mutate(type = case_when(type == "PRIJEM" ~ "CREDIT",
                         type == "VYDAJ" ~ "WITHDRAWAL") 
 ) %>%
 mutate(operation = case_when(operation == "VYBER KARTOU" ~ "CREDIT CARD WITHDRAWAL",
                              operation == "VKLAD" ~ "CASH CREDIT",
                              operation == "PREVOD Z UCTU" ~ "COLLECTION OTHER BANK",
                              operation == "VYBER" ~ "CASH WIDTHDRAWAL",
                              operation == "PREVOD NA UCET" ~ "REMITTANCE OTHER BANK")
 ) %>%
 mutate(characterization = case_when(k_symbol == "POJISTNE" ~ "INSURRANCE PAYMENT",
                              k_symbol == "SLUZBY" ~ "STATEMENT PAYMENT",
                              k_symbol == "UROK" ~ "CREDIT INTEREST",
                              k_symbol == "SANKC. UROK" ~ "SANCTION INTEREST",
                              k_symbol == "SIPO" ~ "HOUSEHOLD",
                              k_symbol == "DUCHOD" ~ "OLD AGE PENSION",
                              k_symbol == "UVER" ~ "LOAN PAYMENT")
 ) %>%
 select(trans_id, account_id, date, type, operation, amount, balance, characterization, bank, account) %>%
 arrange(trans_id) 

rm(df_raw_transaction)
```

### Setup Loan Data Frame

In diesem Schritt wird das Data Frame Loan vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_loan <- read.csv("../xselling_banking_data/loan.csv", header = TRUE, sep = ";")

str(df_raw_loan)

```

Es wird wie folgt die Spalte 'date' von dem Type Integer zu dem Typ Date
umgewandelt. Dabei brauchen wir die Funktionalitäten von
[Lubridate](https://lubridate.tidyverse.org/). Die Spalte 'status'
besitzt Enum-Werte. Diese Werte transformieren wir von A, B, C und D zu
den entsprechenden Bedeutungen auf English.

```{r}

df_loan <- df_raw_loan %>%
 mutate(date = ymd(date)) %>%
 mutate(status = case_when(status == "A" ~ "CONTRACT FINISHED PAYED",
                              status == "B" ~ "CONTRACT FINISHED UNPAID",
                              status == "C" ~ "CONTRACT OPEN OK",
                              status == "D" ~ "CONTRACT OPEN INDEBT",
                              TRUE ~ "")
 ) %>%
 select(loan_id, account_id, date, amount, duration, payments, status) %>%
 arrange(loan_id) 

rm(df_raw_loan)
```

### Setup Credit Card Data Frame

In diesem Schritt wird das Data Frame Credit Card vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_credit_card <- read.csv("../xselling_banking_data/card.csv", header = TRUE, sep = ";")

str(df_raw_credit_card)

```

Es wird wie folgt die Spalte 'issued' von dem Type Character zu dem Typ
Date umgewandelt. Dabei brauchen wir die Funktionalitäten von
[Lubridate](https://lubridate.tidyverse.org/). Die Werte der Spalte
'type' werden in Upper Case umgeschrieben für eine klarere Übersicht von
kategorialen Variablen über alle Data Frames.

```{r}

df_credit_card <- df_raw_credit_card %>%
 mutate(issued  = ymd(as.integer(substr(issued, 0, 6)))) %>%
 mutate(type = case_when(type == "junior" ~ "JUNIOR",
                              type == "classic" ~ "CLASSIC",
                              type == "gold" ~ "GOLD",
                              TRUE ~ "")
 ) %>%
 select(card_id, disp_id, type, issued) %>%
 arrange(card_id) 

rm(df_raw_credit_card)
```

### Setup District Data Frame

In diesem Schritt wird das Data Frame District vorbereitet und der
'Transform'-Schritt wird durchgeführt.

```{r}
df_raw_district <- read.csv("../xselling_banking_data/district.csv", header = TRUE, sep = ";")

str(df_raw_district)

```

In dem Date Frame 'district' müssen wir alle Spalten neu benennnen, da
die einzelnen Spalten aus der Datenquelle keine Aussage über die Daten
drinhat. Daher geben wir jeder Spalte einen passenden Namen.

```{r}

df_district <- df_raw_district %>%
 mutate(district_id  = A1) %>%
 mutate(name = A2) %>%
 mutate(region = A3) %>%
 mutate(inhabitants = A4) %>%
 mutate(municipalities_under_499_inhabitants = A5) %>%
 mutate(municipalities_500_to_1999_inhabitants = A6) %>%
 mutate(municipalities_2000_to_9999_inhabitants = A7) %>%
 mutate(municipalities_over_10000_inhabitants = A7) %>%
 mutate(cities = A9) %>%
 mutate(ratio_urban_inhabitants = A10) %>%
 mutate(average_salary = A11) %>%
 mutate(unemployment_rate_95 = A12) %>%
 mutate(unemployment_rate_96 = A13) %>%
 mutate(enterpreneurs_per_1000_inhabitants = A14) %>%
 mutate(commited_crimes_95 = A15) %>%
 mutate(commited_crimes_96 = A16) %>%
 select(district_id, name, region, inhabitants, municipalities_under_499_inhabitants, municipalities_500_to_1999_inhabitants, municipalities_2000_to_9999_inhabitants, municipalities_over_10000_inhabitants, cities, ratio_urban_inhabitants, average_salary, unemployment_rate_95, unemployment_rate_96, enterpreneurs_per_1000_inhabitants, commited_crimes_95, commited_crimes_96) %>%
 arrange(district_id) 

rm(df_raw_district)
```

### ERD Ist-Zustand

In dem nachfolgend Enitity Relation Diagramm sieht man die Elemente der
transformierten Daten.

![ERD Daten IST-Zustand](../Ressources/SOLL-Zustand.png)

## Tabellen zusammenführen[^3]

[^3]: Erstellt von Léonie Bécheiraz

### Tabellen vorbereiten[^4]

[^4]: Erstellt von Léonie Bécheiraz

Die einzelnen Tabellen werden vor dem Zusammenführen so vorbereitet,
dass pro Account nur eine Zeile vorhanden ist.

### Data Frame "Permanent Order"[^5]

[^5]: Erstellt von Léonie Bécheiraz

```{r}

summary(df_perm_order)

```

```{r}
str(df_perm_order)

```

Neuorganisation der Werte aus "payment_type" in Spalten mit der Summe
der Beträge "amount" und ergänzenden Spalten mit der Information,
wieviele Aufträge des gleichen Typs vorhanden sind. Die Spalten
"order_id", "bank_to" und "account_to" werden weggelassen, da diese für
die zukünftigen Analysen nicht benötigt werden.

```{r}
# summe der Beträge
df_perm_order_mod <- df_perm_order %>% 
  group_by(
    account_id,
    payment_type
  ) %>% 
  mutate(amount_sum = sum(amount)) %>% 
  group_by(
    account_id,
    payment_type,
    amount_sum
  ) %>% 
  count() %>% 
  rename(payment_type_num = n) %>% 
  pivot_wider(names_from = payment_type, values_from = c(amount_sum, payment_type_num)) %>% 
  na.replace(., 0) %>% 
  ungroup()

# str(df_perm_order_mod)

if (!grepl("order_", names(df_perm_order_mod)[2])) {
names(df_perm_order_mod) <- paste0("order_", names(df_perm_order_mod))
}

```

Überprüfung der bisher nicht beachteten Spalten "bank_to" und
"account_to"

```{r}
df_perm_order %>% 
  group_by(
    bank_to, 
    account_to
  ) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  ungroup() %>% 
  head()

```

```{r}
df_perm_order %>% 
  filter(
    account_to == 79838293
  )

```

Es gibt Überweisungen, welche von verschiedenen Konten (maximal 2) auf
dasselbe Ziel-Konto einzahlen. Für die Analysen, welche geplant sind,
ist dieser Umstand nicht relevant. Deshalb werden diese Informationen
vorerst weggelassen. Falls nötig, können sie zu einem späteren Zeitpunkt
immer noch dazu genommen werden.

### Data Frame "Account"[^6]

[^6]: Erstellt von Léonie Bécheiraz

Das Data Frame Account steht im Zentrum und beinhaltet die
Schlüsselfelder zu fast allen weiteren Tabellen. Deshalb beginnen wir
mit dem Account.

```{r}
summary(df_account)

```

Die Werte der Spalte "frequency" werden in Faktoren umgewandelt. Zudem
werden zusätzliche Spalten für die Kontoeröffnungsdaten erstellt (-\>
Eröffnungsjahr als "opening_year", Eröffnungsmonat als "opening_month")
und die Spalte "date" in "opening_date" geändert. Anschliessend wird
wieder allen Spalten das Präfix "account." erteilt.

```{r}
df_account_mod <- df_account %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(opening_year = year(date)) %>%
  mutate(opening_month = month(date)) %>%
  rename("opening_date" = "date")



if (!grepl("account_", names(df_account_mod)[2])) {
names(df_account_mod) <- paste0("account_", names(df_account_mod))
}

```

#### Erstes Zusammenführen[^7]

[^7]: Erstellt von Léonie Bécheiraz

Erstes zusammenfügen der modifizierten Data Frames "df_account_mod" und
"df_perm_order_mod" zum neuen Data Frame "df_mod".

```{r}

df_mod <- left_join(df_account_mod, df_perm_order_mod, by = c( "account_account_id" = "order_account_id"))

summary(df_mod)

```

Die NA's in den Spalten von "order." bedeuten, dass bei diesen Konten
keine Daueraufträge hinderlegt sind. Die Zahl 0 (Null) bedeutet, dass
zwar Daueraufträge hinterlegt sind, aber nicht zu diesem Themenbereich.

Nun können die nicht mehr benötigten Tabellen aus dem Global Environment
entfernt werden.

```{r}
rm(df_account, df_account_mod, df_perm_order, df_perm_order_mod)

```

### Data Frame "Loan"[^8]

[^8]: Erstellt von Léonie Bécheiraz

Im weiteren Schritt wird das Data Frame "Loan" vorbereitet. Übersicht
über das Data Frame

```{r}
glimpse(df_loan)

```

Folgendes soll angepasst werden: - die Spalte "status" wird in Faktor
umgewandelt.

-   Umbenennen der Spalten:
    -   "duration" zu "duration_in_month"
    -   "date" zu "start_date"
    -   "amount" zu "total_amount"
    -   "payments" zu "redemption_amount"
-   Zusätzliche Spalte:
    -   "duration_in_years" generiert aus "duration_in_month" mit den
        Ganzzahlen für

        -   12 = 1,

        -   24 = 2,

        -   36 = 3,

        -   48 = 4,

        -   60 = 5

    -   "end_date" gerechnet aus "start_date" plus "duration_in_years"

    -   "in_dept" generiert aus der Spalte "status" für

        "CONTRACT FINISHED PAYED" und "CONTRACT OPEN OK" = "NO"

        "CONTRACT FINISHED UNPAID" und "CONTRACT OPEN INDEBT" = "YES"

```{r}
df_loan_mod <- df_loan %>%
  rename(
    "duration_in_month" = "duration",
    "start_date" = "date",
    "total_amount" = "amount",
    "redemption_amount" = "payments"
    ) %>%
  mutate(
    duration_in_years = case_when(duration_in_month == 12 ~ 1,
                                  duration_in_month == 24 ~ 2,
                                  duration_in_month == 36 ~ 3,
                                  duration_in_month == 48 ~ 4,
                                  duration_in_month == 60 ~ 5
  )) %>%
  mutate(end_date = start_date + years(duration_in_years)) %>%
  mutate(in_dept = if_else(c(status == "CONTRACT FINISHED PAYED" |
                             status == "CONTRACT OPEN OK"), FALSE, TRUE)) %>%
  mutate(across(where(is.character), as.factor)) %>%
  relocate(end_date, .after = start_date) %>%
  relocate(starts_with("duration"), .after = end_date)

  levels(df_loan_mod$status)

```

Überprüfung, ob ein Account mehrere Darlehen hat.

```{r}
df_loan_mod %>%
  group_by(account_id) %>%
  count() %>%
  arrange(desc(n)) %>%
  ungroup() %>% 
  head(3)

```

Da es pro Account nur jeweils 1 Darlehensvertrag gibt, braucht es für
diese Tabelle keine weiteren Anpassungen. Es wird nur noch das Präfix
"loan." hizugefügt, bevor ein Anfügen an die Gesamttabelle erfolgt.

```{r}
if (!grepl("loan_", names(df_loan_mod)[2])) {
names(df_loan_mod) <- paste0("loan_", names(df_loan_mod))
}

```

#### Zweites Zusammenführen[^9]

[^9]: Erstellt von Léonie Bécheiraz

Loan wird zum Data Frame "df_mod" hinzugefügt.

```{r include=FALSE}
df_mod <- left_join(df_mod, df_loan_mod, by = c("account_account_id" = "loan_account_id"))
 
summary(df_mod)
 
```

#### Bedeutung der NA's[^10]

[^10]: Erstellt von Léonie Bécheiraz

Die NA's in den Spalten von "loan\_" bedeuten, dass bei diesen Konten
keine Darlehen hinderlegt sind, analog den Informationen aus den Spalten
"order\_"

Entfernen der nicht mehr benötigten Tabellen aus dem Global Environment.

```{r}
rm(df_loan, df_loan_mod)

```

### Data Frame "disposition"[^11]

[^11]: Erstellt von Léonie Bécheiraz

Übersicht über das Data Frame

```{r}
glimpse(df_disposition)

```

#### Anpassungen[^12]

[^12]: Erstellt von Léonie Bécheiraz

-   Werte in der Spalte type umbenennen (Disponent zu User)

-   neue Spalte mit Anzahl Benutzer pro Konto (account_user_num)

-   Werte der Spalte type in neue Spalten aufteilen mit Bezeichnung und
    Werten aus client_id und disp_id

```{r}
df_disposition_mod <- df_disposition %>% 
   mutate(type = ifelse(c(type == "OWNER"), "OWNER", "USER")) %>% 
   pivot_wider(names_from = type, values_from = c(client_id, disp_id))

#Spalte mit Anzahl User pro Account
df_disposition_num_user <- df_disposition %>% 
  group_by(
    account_id
  ) %>% 
  count() %>% 
  rename(account_num_of_user = n) %>% 
  ungroup()

#Anfügen der neuen Spalte "account.num_of_user" an das df_disposition_mod
df_disposition_mod <- left_join(df_disposition_mod, df_disposition_num_user, by = "account_id")

summary(df_disposition_mod)
 
```

#### Bedeutung der NA's[^13]

[^13]: Erstellt von Léonie Bécheiraz

Die NA's in den Spalten mit den User-Daten kommen daher, dass bei diesen
Accounts nur 1 Benutzer (Owner) eingetragen ist.

Wiederum wird den Spalten ein Präfix hinzugefügt (disp.)

```{r}
if (!grepl("disp_", names(df_disposition_mod )[2])) {
names(df_disposition_mod) <- paste0("disp_", names(df_disposition_mod))
}

```

Drittes Zusammenführen

```{r}
df_mod <- left_join(df_mod, df_disposition_mod, by = c("account_account_id" = "disp_account_id"))

glimpse(df_mod)

```

Entfernen der nicht mehr benötigten Tabellen

```{r}
rm(df_disposition, df_disposition_mod, df_disposition_num_user)

```

### Data Frame "credit card"[^14]

[^14]: Erstellt von Léonie Bécheiraz

```{r}
glimpse(df_credit_card)

```

Hier braucht es nur eine Umformung der Spalte "type" in Faktor und das
Anfügen des Präfixes (card.)

```{r}
df_credit_card_mod <- df_credit_card %>% 
   mutate(across(where(is.character), as.factor))

if (!grepl("card_", names(df_credit_card_mod)[2])) {
names(df_credit_card_mod) <- paste0("card_", names(df_credit_card_mod))
}
    
glimpse(df_credit_card_mod)

```

Viertes Zusammenführen

```{r}
df_mod <- left_join(df_mod, df_credit_card_mod, by = c("disp_disp_id_OWNER" = "card_disp_id"))
 
glimpse(df_mod)
 
```

Überprüfen, ob alle Kreditkarten übernommen wurden

```{r}
summary(df_mod$card_type)

```

Gesamthaft wurden 892 Kreditkarten-Informationen übernommen.

Entfernen der nicht mehr benötigten Tabellen.

```{r}
rm(df_credit_card, df_credit_card_mod)

```

### Data Frame "client"[^15]

[^15]: Erstellt von Léonie Bécheiraz

```{r}
glimpse(df_client)

```

Bei dieser Tabelle wird das Geschlecht in Faktoren umgewandelt und eine
zusätzliche Spalte für das Alter bei der Kontoeröffnung erstellt. Diese
zusätzliche Spalte kann erst nach dem Zusammenfügen mit den
Account-Daten generiert werden. Danach können die Informationen in
df_mod eingefügt werden. Dazu werden zwei verschiedene Tabellen
erstellt, eine für Owner und eine für den User.

```{r}
df_client_mod <- df_client %>% 
 mutate(across(where(is.character), as.factor))
 
df_client_user <- df_client_mod
df_client_owner <- df_client_mod

if (!grepl("user_", names(df_client_user)[2])) {
names(df_client_user) <- paste0("user_", names(df_client_user))
}
 
if (!grepl("owner_", names(df_client_owner)[2])) {
names(df_client_owner) <- paste0("owner_", names(df_client_owner))
}
 
```

Fünftes Zusammenführen

```{r}
df_mod <- left_join(df_mod, df_client_owner, by = c("disp_client_id_OWNER" = "owner_client_id"))
df_mod <- left_join(df_mod, df_client_user, by = c("disp_client_id_USER" = "user_client_id"))

```

Entfernen der nicht mehr benötigten Tabellen "client"

```{r}
rm(df_client, df_client_mod, df_client_owner, df_client_user)

```

Spalten werden neu angeordnet und wo sinnvoll, umbenannt:

Umbenennen:

-   disp_client_id_OWNER wird zu owner_client_id

-   disp_client_id_USER wird zu user_client_id

-   disp_disp_id_OWNER wird zu owner_disp_id

-   disp_disp_id_USER wird zu user_disp_id

-   card_card_id wird zu card_id

-   loan_loan_id wird zu loan_id

-   account_account_id wird zu account_id

-   order_amount_sum_HOUSEHOLD wird zu owner_client_id

-   order_amount_sum_INSURRANCE wird zu order_amount_insurrance

-   order_amount_sum_LOAN wird zu order_amount_loan

-   order_amount_sum_UNKNOWN wird zu order_amount_unknown

-   order_amount_sum_LEASING wird zu order_amount_leasing

-   order_payment_type_num_HOUSEHOLD wird zu order_num_household

-   order_payment_type_num_INSURRANCE wird zu order_num_insurrance

-   order_payment_type_num_LOAN wird zu order_num_loan

-   order_payment_type_num_UNKNOWN wird zu order_num_unknown

-   order_payment_type_num_LEASING wird zu order_num_leasing

```{r}
# Spalten umbenennen und neu anordnen
df_mod  <- df_mod %>%
 rename(
   owner_client_id = disp_client_id_OWNER,
   user_client_id = disp_client_id_USER,
   owner_disp_id = disp_disp_id_OWNER,
   user_disp_id = disp_disp_id_USER,
   card_id = card_card_id,
   loan_id = loan_loan_id,
   account_id = account_account_id,
   account_num_of_user = disp_account_num_of_user,
   order_total_amount_household = order_amount_sum_HOUSEHOLD,
   order_total_amount_insurrance = order_amount_sum_INSURRANCE,
   order_total_amount_loan = order_amount_sum_LOAN,
   order_total_amount_unknown = order_amount_sum_UNKNOWN,
   order_total_amount_leasing = order_amount_sum_LEASING,
   order_num_household = order_payment_type_num_HOUSEHOLD,
   order_num_insurrance = order_payment_type_num_INSURRANCE,
   order_num_loan = order_payment_type_num_LOAN,
   order_num_unknown = order_payment_type_num_UNKNOWN,
   order_num_leasing = order_payment_type_num_LEASING
 ) 

#zusätzliche Spalte erstellen für das Alter der Owner bei der Kontoeröffnung.
df_mod <- df_mod %>% 
  mutate(owner_age_at_account_opening = trunc((owner_dateofbirth %--% account_opening_date) / years(1))) %>% 
  mutate(user_age_at_account_opening = trunc((user_dateofbirth %--% account_opening_date) / years(1)))

```

### Data Frame "District"[^16]

[^16]: Erstellt von Léonie Bécheiraz

Übersicht über das Data Frame.

```{r}
glimpse(df_district)

```

unemployment_rate_95 in dbl commited_crimes_95 in int anschliessend alle
chr in factor

```{r}
df_district <- df_district %>% 
  mutate(across(c(unemployment_rate_95), as.double),
         across(c(commited_crimes_95), as.integer),
         across(where(is.character), as.factor))

glimpse(df_district)

```

Erstellen des Data Frames für den Import in das "df_mod"

```{r}

df_district_mod <- df_district

if (!grepl("district_", names(df_district_mod )[2])) {
names(df_district_mod) <- paste0("district_", names(df_district_mod))
}

#Auswahl der Spalten für den Übertrag
df_district_select <- df_district_mod %>% 
  select(
    district_district_id,
    district_name,
    district_region,
    district_average_salary,
    district_inhabitants
  )

#Erstellen von zwei Data Frames für Account und Owner
df_district_account <- df_district_select
if (!grepl("account_", names(df_district_account )[2])) {
names(df_district_account) <- paste0("account_", names(df_district_account))
}

df_district_owner <- df_district_select
if (!grepl("owner_", names(df_district_owner )[2])) {
names(df_district_owner) <- paste0("owner_", names(df_district_owner))
}


```

Die vorbereiteten Observationen können nun dem df_mod hinzugefügt
werden.

```{r}
df_mod <- left_join(df_mod, df_district_account, by = c("account_district_id" = "account_district_district_id"))

df_mod <- left_join(df_mod, df_district_owner, by = c("account_district_id" = "owner_district_district_id"))

```

Entfernen der nicht mehr benötigten Tabellen.

```{r}
rm(df_district_account, df_district_owner, df_district_select)
#das df_district wird vorerst noch belassen, ev. wird es in einem späteren Schritt nochmals verwendet

```

Für das konsolidierte Data Frame werden die Spalten neu angeordnet.

```{r}
#dieser Code verwenden, um das df_cons zu erstellen
df_mod <- df_mod %>%
  relocate(starts_with("account_")) %>% 
  relocate(starts_with("owner_"), .after = last_col()) %>%
  relocate(starts_with("user_"), .after = last_col()) %>%
  relocate(contains("id"), .after = last_col()) %>% 
  relocate(account_id)

glimpse(df_mod)

```

#### Erste Analysen[^17]

[^17]: Erstellt von Léonie Bécheiraz

Sonderstellung: Bedeutung des Account Owner

Wie wir bei der Datenbeschreibung bereits gelesen haben, enthält
disposition_type die Information über die Rechte der Konten. Deshalb
wurde der Eintrag beim Aufbereiten des df_disposition von "disponent" in
"user" geändert. Denn nur der "owner" hat die nötigen Berechtigungen, um
Daueraufträge zu erteilen und Darlehen zu beantragen. So wird die
Auswertung übersichtlicher.

Auf Duplikate überprüfen

```{r}
n_distinct(df_mod)

```

Es sind keine Duplikate vorhanden.

### Data Frame "transaction"[^18]

[^18]: Erstellt von Léonie Bécheiraz

Das Data Frame Transaction wird vorerst separat aufbereitet und ersten
Analysen unterzogen. Aus den folgenden Analysen werden neue Spalten
generiert, welche dann in einem weiteren Schritt in den konsolidierten
Datensatz df_cons übernommen werden können. Auch wird während den
Analysen entschieden, ob zusätzlich zum konsolidierten Datensatz noch
ein Datensatz mit Transaktionsdaten bestehen bleibt, oder ob alles in
df_cons zusammengeführt wird.

Übersicht über die Tabelle df_transaction.

```{r}

glimpse(df_transaction)

```

#### Dateitypen anpassen[^19]

[^19]: Erstellt von Léonie Bécheiraz

Characters in Faktoren ändern.

```{r}

df_transaction_mod <- df_transaction %>% 
  mutate(across(where(is.character), as.factor))

summary(df_transaction_mod)
glimpse(df_transaction_mod)
rm(df_transaction)

```

#### Spalten umbenennen[^20]

[^20]: Erstellt von Léonie Bécheiraz

-   bank wird zu bank_name

-   account wird zu account_nr

-   type wird zu cashflow

```{r}

df_transaction_mod <- df_transaction_mod %>% 
  rename(
    bank_name = bank,
    account_nr = account,
    cashflow = type
  )

```

#### Untersuchen der NA's[^21]

[^21]: Erstellt von Léonie Bécheiraz

Als erstes beginnen wir mit der neu benannten Spalte cashflow

```{r}

df_transaction_mod %>% 
  filter(is.na(cashflow)) %>% 
  summary()

```

Die NA's in "cashflow" und "characterization" sind Geldausgänge und
können deshalb als Werte in die beiden Spalten imputiert werden. Bei der
Spalte "bank_name" fällt auf, dass die Werte leer sind. Deshalb wird
dort mit NA's ergänzt. Es könnte sich bei diesen Geldbezügen um Bezüge
an den Automaten handeln. Dies kann aber erst überprüft werden, wenn
diese Informationen mit den Beobachtungen aus der Tabelle mit den
Kreditkarten-Informationen abgeglichen werden kann. Diese Analyse kann
zu einem späteren Zeitpunkt vorgenommen werden.

#### Imputieren[^22]

[^22]: Erstellt von Léonie Bécheiraz

```{r}
#Liste für die gezielte Imputation in "characterization" mit "CASH WIDTHDRAWAL"
list_na_characterization_for_cashwidthrawal <- df_transaction_mod %>% 
  filter(is.na(cashflow)) %>% 
  select(trans_id)

cashwidthrawals <- df_transaction_mod %>% 
  filter(trans_id %in% list_na_characterization_for_cashwidthrawal$trans_id)
  
cashwidthrawals$characterization <- replace_na("CASH WIDTHDRAWAL")
head(cashwidthrawals)
rm(cashwidthrawals)

```

#### Cashflow mit "IN" und "OUT" mutieren[^23]

[^23]: Erstellt von Léonie Bécheiraz

Nebst dem mutieren werden die NA's mit "OUT" imputiert. Dies geht aus
der vorgängigen Analyse hervor.

```{r}
df_transaction_mod <- df_transaction_mod %>% 
  mutate(cashflow = case_when(cashflow == "WITHDRAWAL" ~ "OUT",
                              cashflow == "CREDIT" ~ "IN",
                              TRUE ~ "OUT")) %>%
  mutate(across(where(is.character), as.factor))

head(df_transaction_mod)

```

#### Entfernen der nicht mehr benötigten data frames.[^24]

[^24]: Erstellt von Léonie Bécheiraz

```{r}

rm(list_na_characterization_for_cashwidthrawal, list_transid_for_imputation)

```

#### Vobereitung des Datum-Attributes {Year}\_Q{Quarter} per transaction[^25]

[^25]: Erstellt von Léonie Bécheiraz

```{r}

df_transaction_mod <- df_transaction_mod %>% 
  mutate(quarter = zoo::as.yearqtr(date))

```

#### Bilanz Ende Jahr[^26]

[^26]: Erstellt von Léonie Bécheiraz

#### Erstellen zusätzlicher Spalten "year" und "month"[^27]

[^27]: Erstellt von Léonie Bécheiraz

Im Data Frame "df_transaction_mod" werden zwei zusätzliche Spalten für
das Jahr der Transaktion sowie für den Monat erstellt.

```{r}
df_transaction_mod <- df_transaction_mod %>% 
  mutate(
    year = year(date),
    month = month(date)
  )

head(df_transaction_mod)

```

#### durchschnittliche Bilanz[^28]

[^28]: Erstellt von Léonie Bécheiraz

```{r}
years_avg <- df_transaction_mod %>% 
  group_by(
    account_id,
    cashflow,
    year
  ) %>% 
  summarise(amount_mean = mean(amount)) %>% 
  pivot_wider(names_from = cashflow, values_from = amount_mean) %>% 
  mutate(balance_sheet = IN - OUT) %>% 
  ungroup()

balance_sheet <- years_avg %>% 
    select(
      account_id,
      year,
      balance_sheet
    ) %>% 
    arrange(year) %>% 
    pivot_wider(names_from = year, values_from = balance_sheet) %>% 
    arrange(account_id)
  
if (!grepl("balance_sheet_end_of.", names(balance_sheet)[2])) {
names(balance_sheet) <- paste0("balance_sheet_end_of.", names(balance_sheet))
}

head(years_avg)
head(balance_sheet)

```

Für die Analysen werden noch die jeweiligen mittleren Werte der
Kontostände benötigt. Dazu wird ein zusätzliches Data Frame mit den
Mittelwerten erstellt.

```{r}
transaction_cashflow_per_month_and_year_mean <- df_transaction_mod %>%
  group_by(
    year,
    month,
    account_id,
    cashflow,
    ) %>%
  arrange(year, month) %>%
  summarise(amount_mean = mean(amount)) %>%
  pivot_wider(names_from = cashflow, values_from = amount_mean) %>% 
  mutate(IN = replace_na(IN, 0)) %>% 
  mutate(OUT = replace_na(OUT, 0)) %>% 
  mutate(balance = IN - OUT) 

balance_per_month_mean <- transaction_cashflow_per_month_and_year_mean %>% 
  select(
    account_id,
    year,
    month,
    balance
  ) %>% 
  pivot_wider(names_from = c(year,month), values_from = balance)

head(balance_per_month_mean)

```

#### Wichtige Erkenntnis[^29]

[^29]: Erstellt von Léonie Bécheiraz

Eine Überprüfung der Werte hat ergeben, dass dies so nicht gerechnet
werden Kann. Es entstehen dabei Rechnungsfehler, da zum Beispiel bei
einem Eingang mit mehreren Werten der Durchschnitt berechnet wird und
wenn dann ein Ausgang mit nur einem Wert vorhanden ist, dieser abgezogen
wird, stimmt das Verhältnis der Beträge nicht mehr. Daher wird nur die
Berechnung mit den totalen verwendet und damit weiter gearbeitet!

Balance Data Frames entfernen

```{r}
rm(balance_per_month_mean, balance_per_month_total_lag, balance_sheet_per_years_total, transaction_cashflow_per_month_and_year_mean, transaction_cashflow_per_month_and_year_total)

```

#### Kontostand Ende Monat[^30]

[^30]: Erstellt von Léonie Bécheiraz

Als erstes werden die Kontostände per Ende jeden Monats berechnet. Dazu
müssen die entstehenden NA's mit der Zahl Null ersetzt werden, da ja bei
diesen Kontoständen sowie Geldein-/ausgängen 0 CZK vorhanden sind.

```{r}
transaction_cashflow_per_month_and_year_total <- df_transaction_mod %>%
  group_by(
    year,
    month,
    account_id,
    cashflow,
    ) %>%
  arrange(year, month) %>%
  summarise(amount_total = sum(amount)) %>%
  pivot_wider(names_from = cashflow, values_from = amount_total) %>%
  mutate(IN = replace_na(IN, 0)) %>%
  mutate(OUT = replace_na(OUT, 0)) %>%
  mutate(balance_sheet = IN - OUT) %>% 
  ungroup()

head(transaction_cashflow_per_month_and_year_total)

```

Leider ist kein Erfolg zu verzeichnen.

#### lead und lag[^31]

[^31]: Erstellt von Léonie Bécheiraz

Weiterer Versuch mit lead() und lag() den Kontostand Ende Monat
auszurechnen:

```{r}
balance_per_month_total_lead <- transaction_cashflow_per_month_and_year_total %>% 
  arrange(account_id) %>% 
  mutate(account_id_lead = dplyr::lead(account_id)) %>% 
  mutate(account_id_lead = replace_na(account_id_lead, 0)) %>% 
  mutate(balance_lead = dplyr::lead(balance_sheet)) %>% 
  mutate(balance_lead = replace_na(balance_lead, 0)) %>%
  mutate(balance_per_month = ifelse(c(account_id == account_id_lead), balance_sheet + balance_lead, balance_sheet)) %>% 
  relocate(account_id_lead)
  

balance_per_month_total_lag <- transaction_cashflow_per_month_and_year_total %>% 
  arrange(account_id) %>% 
  mutate(account_id_lag = dplyr::lag(account_id)) %>% 
  mutate(account_id_lag = replace_na(account_id_lag, 0)) %>% 
  relocate(account_id_lag) %>% 
  mutate(row_num = 1: nrow(.)) %>%
  mutate(row_num_lag = dplyr::lag(row_num)) %>% 
  mutate(balance_per_month = ifelse(c(account_id != account_id_lag), balance_sheet, 0)) %>%   mutate(balance_per_month = ifelse(c(account_id == account_id_lag), balance_per_month[row_num_lag] + balance_sheet, balance_per_month))

head(balance_per_month_total_lead)
head(balance_per_month_total_lag)

```

Auch dies führt nicht zum gewünschten Ergebnis.

#### Suche nach einer anderen Möglichkeit für die monatlichen Kontoauszügen[^32]

[^32]: Erstellt von Léonie Bécheiraz

Im ursprünglichen Datensatz "df_transaction_mod" sind die Kontostände
nach jeder Transaktion vorhanden. Es sollte möglich sein, anhand des
letzten Datums herauszufinden, welches die letzte Transaktion war und
somit welches der Kontostand Ende Monat ist. Dazu wird ein
Zufallsgenerator erstellt, um verschiedene Konten genauer zu
untersuchen.

```{r}
#Zufallsnummer
n = runif(1, min = 0, max = nrow(df_transaction_mod))

df_transaction_mod %>%
  arrange(date) %>%
  filter(
    account_id == account_id[n],
    year == 1995,
    month == 3
  )

rm(n)

```

Es fällt auf, dass die letzte Transaktion immer der Betrag 14.6 ist. Es
ist immer ein OUT. Diese Hypothese wird nun nochmals überprüft.

```{r}
df_transaction_mod %>% 
  filter(
    amount == 14.6
  )
  
```

#### Kontogebühren[^33]

[^33]: Erstellt von Léonie Bécheiraz

Es handelt sich hier vermutlich um Kontogebühren, welche als letzte
Transaktion getätigt werden. Nun wird noch nach dem Wert "STATEMENT
PAYMENT" gefiltert.

```{r, results='hide'}
df_transaction_mod %>%
  filter(
    characterization == "STATEMENT PAYMENT"
  ) %>%
  arrange(desc(amount))

```

Die Beträge sind nicht immer gleich hoch. Dies soll genauer untersucht
werden. Damit die verschiedenen vorkommenden Beträge aufgelistet werden
können, wird eine zusätzliche Spalte generiert, in der die Werte zu
Faktoren umgewandelt werden. Anschliessend können die Levels angezeigt
werden. Die Hypothese ist, dass die Höhe er Beträge Aussagen macht, ob
es sich dabei um Privat- oder Geschäftskunden handelt.

```{r, results='hide'}
df_statement_payment_levels <- df_transaction_mod %>% 
  filter(
    characterization == "STATEMENT PAYMENT"
  ) %>% 
  mutate(amount_levels = as.factor(amount))

levels(df_statement_payment_levels$amount_levels)

```

Es gibt gesamthahft 3 verschieden hohe Gebühren für die Konten: 14.60,
30, 100.

Entfernen des df_statement_payment_levels

```{r}

rm(df_statement_payment_levels)

```

Bei einer späteren Analyse kann versucht werden, die Gebührenhöhe zu
erklären. Dabei können folgende Fragen beantwortet werden:

-   Handelt es sich bei den Konten mit der Gebühr 100 um
    Geschäftskonten?

-   Sind diese Konten in einer bestimmten Filiale oder einem bestimmten
    District?

-   Wurden die Kontogebühren über die Jahre erhöht?

Es wird nun aber weiter am Datensatz für die monatlichen Gebühren
gearbeitet. Dafür muss überprüft werden, ob immer Ende Monat eine
Kontogebühr abgebucht wurde.

#### Erstellen des Datensatzes für die monatlichen Kontostände[^34]

[^34]: Erstellt von Léonie Bécheiraz

statement_payment

```{r}
statement_payment <- df_transaction_mod %>%
  filter(
    characterization == "STATEMENT PAYMENT"
  ) %>%
  mutate(
    statement_payment = date
  ) %>%
  select(
    trans_id,
    statement_payment
  )

head(statement_payment)

```

balance_per_month

```{r}

balance_per_month <- df_transaction_mod %>%
  select(
    trans_id
  )

balance_per_month <- left_join(balance_per_month, statement_payment, by = "trans_id")

rm(statement_payment)
head(balance_per_month)

```

Test für die Darstellung eines zufälligen Accounts in dem
'df_transaction_mod' DF.

```{r , results='hide'}
#Zufallsnummer
n = runif(1, min = 0, max = nrow(df_transaction_mod))

df_transaction_mod %>%
  filter(
    account_id == account_id[n]
  ) %>%
  arrange(date)

rm(n)

```

Es gibt Monate, in denen keine Kontogebühren verrechnet wurden. Die
Hypothese dazu ist, dass ein Neukunde die ersten drei Monate keine
Gebühren zahlt. Dies soll überprüft werden.

#### letzter Tag im Monat[^35]

[^35]: Erstellt von Léonie Bécheiraz

last_day_in_month

```{r}
last_day_in_month <- df_transaction_mod %>% 
  group_by(
    account_id,
    year,
    month
  ) %>% 
  mutate(last_day = max(date)) %>% 
  ungroup()

head(last_day_in_month)

```

```{r}
last_day_in_month <- last_day_in_month %>% 
  filter(
    date == last_day
  ) %>% 
  arrange(
    account_id,
    date
  )
last_day_in_month

```

Bei der Kontoeröffnung ist der Amount gleich hoch wie die Balance. Diese
Information kann in "characterization" imputiert werden.

#### Kontoeröffnung[^36]

[^36]: Erstellt von Léonie Bécheiraz

account_opening

```{r}

account_opening <- df_transaction_mod %>%
  filter(
    amount == balance,
    cashflow == "IN"
  ) %>%
  mutate(
    account_opening = date
  )

head(account_opening)

```

Die Erkenntnisse aus den Kontoeröffnungen werden nun dem Data Frame
"balance_per_month" angefügt.

```{r}
foo <- account_opening %>%
  select(
    trans_id,
    account_opening
  )

balance_per_month <- left_join(balance_per_month, foo, by = "trans_id")

rm(foo)
head(balance_per_month)

```

```{r}
foo <- last_day_in_month %>%
  select(
    trans_id,
    last_day
  )

balance_per_month <- left_join(balance_per_month, foo, by = "trans_id")
rm(foo)
head(balance_per_month)

```

```{r}
balance_per_month <- left_join(balance_per_month, df_transaction_mod, by = "trans_id")
head(balance_per_month)

```

auf Duplikate überprüfen

```{r}
num <- balance_per_month %>%
  filter(
    !is.na(last_day),
    is.na(statement_payment),
    is.na(account_opening)
    ) %>%
  group_by(
    account_id,
    year,
    month
  ) %>%
  ungroup()

nrow(num)

n_distinct <- num %>% select(account_id, date) %>% n_distinct()

n_distinct

```

Es gibt einige Daten, an denen mehrere Zahlungen am selben Tag
erfolgten.

#### Einzelzahlungen am letzten Tag des Monats[^37]

[^37]: Erstellt von Léonie Bécheiraz

Alle Kontostände pro Monatsende mit nur einer Transaktion können
entsprechend ergänzt werden.

balance_per_month

```{r}
foo <- balance_per_month %>%
  filter(
    !is.na(last_day),
    is.na(statement_payment),
    is.na(account_opening)
    ) %>%
  group_by(
    account_id,
    year,
    month
  ) %>%
  count() %>%
  ungroup() %>%
  filter(
    n == 1
  ) %>%
  rename(is_unique = n)

balance_per_month <- left_join(balance_per_month, foo, by = c("account_id", "year", "month"))

rm(foo)

head(balance_per_month)

```

#### mehrere Transaktionen am selben Tag[^38]

[^38]: Erstellt von Léonie Bécheiraz

Nun werden alle Zeilen gekennzeichnet, welche mehrere Transaktionen am
Ende des Monats haben und noch nicht zugeordnet werden konnten.

```{r}
foo <- balance_per_month %>%
  filter(
    !is.na(last_day),
    is.na(statement_payment),
    is.na(account_opening)
    ) %>%
  group_by(
    account_id,
    year,
    month
  ) %>%
  count() %>%
  ungroup() %>%
  filter(
    n > 1
  ) %>%
  rename(is_not_unique = n)

balance_per_month <- left_join(balance_per_month, foo, by = c("account_id", "year", "month"))

rm(foo)

head(balance_per_month)

```

```{r, results='hide'}
balance_per_month %>%
  filter(
    !is.na(is_not_unique),
    !is.na(last_day),
    is.na(statement_payment),
    is.na(account_opening)
  ) %>%
  arrange(
    account_id,
    date
  ) %>%
  arrange(desc(is_not_unique))

```

Alle diese Versuche führen nicht zum Ziel.

Entfernen der nicht mehr benötigten Tabelle

```{r}
rm(account_opening, balance_per_month, balance_per_month_total_lag, balance_per_month_total_lead, balance_sheet, last_day_in_month, num, years_avg, n_distinct, n_row_na, transaction_cashflow_per_month_and_year_total)

```

#### Weiterer Versuch, den Kontoendstand pro Monat zu eruieren.

[^39] Dazu wird der jeweilige Kontoendstand des Vormonats genommen und
von diesem alle Geldein- sowie Ausgänge dazu gerechnet beziehungsweise
abgezogen. Wir erstellen ein Hilf-Data-Frame für die Geldein- und
Ausgänge, in diesem Date Frame werden nach der zuweisung der Werte
jeglich NA's zu einem numeric values 0 umformatiert. Nachfolgend wir
eine Balance für jeden Monat erstellt.

[^39]: Erstellt von Léonie Bécheiraz

```{r}

transaction_cashflow_per_month_and_year <- df_transaction_mod %>%
  group_by(
    account_id,
    cashflow,
    year,
    month
  ) %>%
  summarise(amount_sum = sum(amount)) %>%
  # arrange(year, month) %>%
  pivot_wider(names_from = c(cashflow,year,month), values_from = amount_sum)

head(transaction_cashflow_per_month_and_year)

transaction_cashflow_per_month_and_year_modified <- transaction_cashflow_per_month_and_year %>%
  replace(is.na(transaction_cashflow_per_month_and_year), 0) 

head(transaction_cashflow_per_month_and_year_modified)

transaction_mod_balance_per_month <- transaction_cashflow_per_month_and_year_modified %>%
  mutate(account_id = account_id) %>%
  mutate(balance_1993_1 = IN_1993_1 - OUT_1993_1) %>%
  mutate(balance_1993_2 = balance_1993_1 + (IN_1993_2 - OUT_1993_2)) %>%
  mutate(balance_1993_3 = balance_1993_2 + (IN_1993_3 - OUT_1993_3)) %>%
  mutate(balance_1993_4 = balance_1993_3 + (IN_1993_4 - OUT_1993_4)) %>%
  mutate(balance_1993_5 = balance_1993_4 + (IN_1993_5 - OUT_1993_5)) %>%
  mutate(balance_1993_6 = balance_1993_5 + (IN_1993_6 - OUT_1993_6)) %>%
  mutate(balance_1993_7 = balance_1993_6 + (IN_1993_7 - OUT_1993_7)) %>%
  mutate(balance_1993_8 = balance_1993_7 + (IN_1993_8 - OUT_1993_8)) %>%
  mutate(balance_1993_9 = balance_1993_8 + (IN_1993_9 - OUT_1993_9)) %>%
  mutate(balance_1993_10 = balance_1993_9 + (IN_1993_10 - OUT_1993_10)) %>%
  mutate(balance_1993_11 = balance_1993_10 + (IN_1993_11 - OUT_1993_11)) %>%
  mutate(balance_1993_12 = balance_1993_11 + (IN_1993_12 - OUT_1993_12)) %>%
  mutate(balance_1994_1 = balance_1993_12 + (IN_1994_1 - OUT_1994_1)) %>%
  mutate(balance_1994_2 = balance_1994_1 + (IN_1994_2 - OUT_1994_2)) %>%
  mutate(balance_1994_3 = balance_1994_2 + (IN_1994_3 - OUT_1994_3)) %>%
  mutate(balance_1994_4 = balance_1994_3 + (IN_1994_4 - OUT_1994_4)) %>%
  mutate(balance_1994_5 = balance_1994_4 + (IN_1994_5 - OUT_1994_5)) %>%
  mutate(balance_1994_6 = balance_1994_5 + (IN_1994_6 - OUT_1994_6)) %>%
  mutate(balance_1994_7 = balance_1994_6 + (IN_1994_7 - OUT_1994_7)) %>%
  mutate(balance_1994_8 = balance_1994_7 + (IN_1994_8 - OUT_1994_8)) %>%
  mutate(balance_1994_9 = balance_1994_8 + (IN_1994_9 - OUT_1994_9)) %>%
  mutate(balance_1994_10 = balance_1994_9 + (IN_1994_10 - OUT_1994_10)) %>%
  mutate(balance_1994_11 = balance_1994_10 + (IN_1994_11 - OUT_1994_11)) %>%
  mutate(balance_1994_12 = balance_1994_11 + (IN_1994_12 - OUT_1994_12)) %>%
  mutate(balance_1995_1 = balance_1994_12 + (IN_1995_1 - OUT_1995_1)) %>%
  mutate(balance_1995_2 = balance_1995_1 + (IN_1995_2 - OUT_1995_2)) %>%
  mutate(balance_1995_3 = balance_1995_2 + (IN_1995_3 - OUT_1995_3)) %>%
  mutate(balance_1995_4 = balance_1995_3 + (IN_1995_4 - OUT_1995_4)) %>%
  mutate(balance_1995_5 = balance_1995_4 + (IN_1995_5 - OUT_1995_5)) %>%
  mutate(balance_1995_6 = balance_1995_5 + (IN_1995_6 - OUT_1995_6)) %>%
  mutate(balance_1995_7 = balance_1995_6 + (IN_1995_7 - OUT_1995_7)) %>%
  mutate(balance_1995_8 = balance_1995_7 + (IN_1995_8 - OUT_1995_8)) %>%
  mutate(balance_1995_9 = balance_1995_8 + (IN_1995_9 - OUT_1995_9)) %>%
  mutate(balance_1995_10 = balance_1995_9 + (IN_1995_10 - OUT_1995_10)) %>%
  mutate(balance_1995_11 = balance_1995_10 + (IN_1995_11 - OUT_1995_11)) %>%
  mutate(balance_1995_12 = balance_1995_11 + (IN_1995_12 - OUT_1995_12)) %>%
  mutate(balance_1996_1 = balance_1995_12 + (IN_1996_1 - OUT_1996_1)) %>%
  mutate(balance_1996_2 = balance_1996_1 + (IN_1996_2 - OUT_1996_2)) %>%
  mutate(balance_1996_3 = balance_1996_2 + (IN_1996_3 - OUT_1996_3)) %>%
  mutate(balance_1996_4 = balance_1996_3 + (IN_1996_4 - OUT_1996_4)) %>%
  mutate(balance_1996_5 = balance_1996_4 + (IN_1996_5 - OUT_1996_5)) %>%
  mutate(balance_1996_6 = balance_1996_5 + (IN_1996_6 - OUT_1996_6)) %>%
  mutate(balance_1996_7 = balance_1996_6 + (IN_1996_7 - OUT_1996_7)) %>%
  mutate(balance_1996_8 = balance_1996_7 + (IN_1996_8 - OUT_1996_8)) %>%
  mutate(balance_1996_9 = balance_1996_8 + (IN_1996_9 - OUT_1996_9)) %>%
  mutate(balance_1996_10 = balance_1996_9 + (IN_1996_10 - OUT_1996_10)) %>%
  mutate(balance_1996_11 = balance_1996_10 + (IN_1996_11 - OUT_1996_11)) %>%
  mutate(balance_1996_12 = balance_1996_11 + (IN_1996_12 - OUT_1996_12)) %>%
  mutate(balance_1997_1 = balance_1996_12 + (IN_1997_1 - OUT_1997_1)) %>%
  mutate(balance_1997_2 = balance_1997_1 + (IN_1997_2 - OUT_1997_2)) %>%
  mutate(balance_1997_3 = balance_1997_2 + (IN_1997_3 - OUT_1997_3)) %>%
  mutate(balance_1997_4 = balance_1997_3 + (IN_1997_4 - OUT_1997_4)) %>%
  mutate(balance_1997_5 = balance_1997_4 + (IN_1997_5 - OUT_1997_5)) %>%
  mutate(balance_1997_6 = balance_1997_5 + (IN_1997_6 - OUT_1997_6)) %>%
  mutate(balance_1997_7 = balance_1997_6 + (IN_1997_7 - OUT_1997_7)) %>%
  mutate(balance_1997_8 = balance_1997_7 + (IN_1997_8 - OUT_1997_8)) %>%
  mutate(balance_1997_9 = balance_1997_8 + (IN_1997_9 - OUT_1997_9)) %>%
  mutate(balance_1997_10 = balance_1997_9 + (IN_1997_10 - OUT_1997_10)) %>%
  mutate(balance_1997_11 = balance_1997_10 + (IN_1997_11 - OUT_1997_11)) %>%
  mutate(balance_1997_12 = balance_1997_11 + (IN_1997_12 - OUT_1997_12)) %>%
  mutate(balance_1998_1 = balance_1997_12 + (IN_1998_1 - OUT_1998_1)) %>%
  mutate(balance_1998_2 = balance_1998_1 + (IN_1998_2 - OUT_1998_2)) %>%
  mutate(balance_1998_3 = balance_1998_2 + (IN_1998_3 - OUT_1998_3)) %>%
  mutate(balance_1998_4 = balance_1998_3 + (IN_1998_4 - OUT_1998_4)) %>%
  mutate(balance_1998_5 = balance_1998_4 + (IN_1998_5 - OUT_1998_5)) %>%
  mutate(balance_1998_6 = balance_1998_5 + (IN_1998_6 - OUT_1998_6)) %>%
  mutate(balance_1998_7 = balance_1998_6 + (IN_1998_7 - OUT_1998_7)) %>%
  mutate(balance_1998_8 = balance_1998_7 + (IN_1998_8 - OUT_1998_8)) %>%
  mutate(balance_1998_9 = balance_1998_8 + (IN_1998_9 - OUT_1998_9)) %>%
  mutate(balance_1998_10 = balance_1998_9 + (IN_1998_10 - OUT_1998_10)) %>%
  mutate(balance_1998_11 = balance_1998_10 + (IN_1998_11 - OUT_1998_11)) %>%
  mutate(balance_1998_12 = balance_1998_11 + (IN_1998_12 - OUT_1998_12)) %>%
  select(account_id, balance_1993_1, balance_1993_2,balance_1993_3, balance_1993_4, balance_1993_5, balance_1993_6, balance_1993_7, balance_1993_8, balance_1993_9, balance_1993_10, balance_1993_11, balance_1993_12, balance_1994_1, balance_1994_2, balance_1994_3, balance_1994_4, balance_1994_5, balance_1994_6, balance_1994_7, balance_1994_8, balance_1994_9, balance_1994_10, balance_1994_11, balance_1994_12, balance_1995_1, balance_1995_2, balance_1995_3, balance_1995_4, balance_1995_5, balance_1995_6, balance_1995_7, balance_1995_8, balance_1995_9, balance_1995_10,balance_1995_11,balance_1995_12, balance_1996_1, balance_1996_2, balance_1996_3, balance_1996_4, balance_1996_5, balance_1996_6, balance_1996_7, balance_1996_8, balance_1996_9, balance_1996_10, balance_1996_11, balance_1996_12, balance_1997_1, balance_1997_2, balance_1997_3, balance_1997_4, balance_1997_5, balance_1997_6, balance_1997_7, balance_1997_8, balance_1997_9, balance_1997_10, balance_1997_11, balance_1997_12,balance_1998_1, balance_1998_2, balance_1998_3, balance_1998_4, balance_1998_5, balance_1998_6, balance_1998_7, balance_1998_8, balance_1998_9, balance_1998_10, balance_1998_11, balance_1998_12)

# str(transaction_cashflow_per_month_and_year)
# 
# 
# df_mod <- left_join(df_mod, transaction_mod_balance_per_month, by = c("account_id" = "account_id"))

```

#### Überprüfen, ob die Überlegung so stimmt[^40]

[^40]: Erstellt von Léonie Bécheiraz

[^41] Für den jeweiligen Kontostand Ende Monat wird eine Datumsangabe
ohne Lücken benötigt. Somit kann jederzeit auch den Kontostand am Ende
jeden Tages ausgeben werden. Überprüfen, ob die Datumsangaben lückenlos
sind.

[^41]: Erstellt von Léonie Bécheiraz

```{r}
df_transaction_mod %>% 
  filter(
    year == 1995,
    account_id == 18
    ) %>% 
  group_by(date) %>% 
  count() %>% 
  nrow()

```

Am Beispiel des Accounts Nr. 18 ist klar zu erkennen, dass das Datum
(mit dem dazugehörenden Kontostand) nur erfasst wurde, wenn auch eine
Zahlung getätigt wurde.

Nun wird nochmals dieselbe Kontrolle mit dem Account Nr. 18 gemacht wie
vor der Anreicherung und mit dem Code von Aaron verglichen.

```{r}
# Überprüfen, ob der Code von Aaron stimmt:
transaction_mod_balance_per_month %>% 
  filter(
    account_id == 18
  ) %>% 
  select(
    balance_1993_5,
    balance_1993_6,
    balance_1993_7,
    balance_1993_8
  )

df_transaction_mod %>% 
  filter(
    account_id == 18
  ) %>% 
  arrange(date)

```

Das Resultat des Codes sieht korrekt aus. Es wird versucht, den Code
selber umzuschreiben um dies später im Rahmen von grossen Daten anwenden
zu können.

Entfernen der nicht mehr benötigten Tabellen

```{r}

rm(transaction_cashflow_per_month_and_year, transaction_mod_balance_per_month, transaction_cashflow_per_month_and_year_modified)

```

#### Vierteljähriges Einkommen und Ausgaben per Jahr[^42]

[^42]: Erstellt von Léonie Bécheiraz

```{r}

transaction_cashflow_per_quarter_and_year <- df_transaction_mod %>%
  group_by(
    account_id,
    cashflow,
    quarter
  ) %>%
  summarise(amount_sum = sum(amount)) %>%
  # arrange(year, month) %>%
  pivot_wider(names_from = c(cashflow, quarter), values_from = amount_sum)

str(transaction_cashflow_per_quarter_and_year)

transaction_cashflow_per_quarter_and_year_modified <- transaction_cashflow_per_quarter_and_year %>%
  replace(is.na(transaction_cashflow_per_quarter_and_year), 0) 

transaction_cashflow_per_quarter_and_year_modified %>%
  mutate(account_id = account_id) %>%
  mutate('1993_Q1_Expenses' = 'OUT_1993 Q1') %>%
  mutate('1993_Q2_Expenses' = 'OUT_1993 Q2') %>%
  mutate('1993_Q3_Expenses' = 'OUT_1993 Q3') %>%
  mutate('1993_Q4_Expenses' = 'OUT_1993 Q4') %>%
  mutate('1994_Q1_Expenses' = 'OUT_1994 Q1') %>%
  mutate('1994_Q2_Expenses' = 'OUT_1994 Q2') %>%
  mutate('1994_Q3_Expenses' = 'OUT_1994 Q3') %>%
  mutate('1994_Q4_Expenses' = 'OUT_1994 Q4') %>%
  mutate('1995_Q1_Expenses' = 'OUT_1995 Q1') %>%
  mutate('1995_Q2_Expenses' = 'OUT_1995 Q2') %>%
  mutate('1995_Q3_Expenses' = 'OUT_1995 Q3') %>%
  mutate('1995_Q4_Expenses' = 'OUT_1995 Q4') %>%
  mutate('1996_Q1_Expenses' = 'OUT_1996 Q1') %>%
  mutate('1996_Q2_Expenses' = 'OUT_1996 Q2') %>%
  mutate('1996_Q3_Expenses' = 'OUT_1996 Q3') %>%
  mutate('1996_Q4_Expenses' = 'OUT_1996 Q4') %>%
  mutate('1997_Q1_Expenses' = 'OUT_1997 Q1') %>%
  mutate('1997_Q2_Expenses' = 'OUT_1997 Q2') %>%
  mutate('1997_Q3_Expenses' = 'OUT_1997 Q3') %>%
  mutate('1997_Q4_Expenses' = 'OUT_1997 Q4') %>%
  mutate('1998_Q1_Expenses' = 'OUT_1998 Q1') %>%
  mutate('1998_Q2_Expenses' = 'OUT_1998 Q2') %>%
  mutate('1998_Q3_Expenses' = 'OUT_1998 Q3') %>%
  mutate('1998_Q4_Expenses' = 'OUT_1998 Q4') %>%
  mutate('1993_Q1_Income' = 'IN_1993 Q1') %>%
  mutate('1993_Q2_Income' = 'IN_1993 Q2') %>%
  mutate('1993_Q3_Income' = 'IN_1993 Q3') %>%
  mutate('1993_Q4_Income' = 'IN_1993 Q4') %>%
  mutate('1994_Q1_Income' = 'IN_1994 Q1') %>%
  mutate('1994_Q2_Income' = 'IN_1994 Q2') %>%
  mutate('1994_Q3_Income' = 'IN_1994 Q3') %>%
  mutate('1994_Q4_Income' = 'IN_1994 Q4') %>%
  mutate('1995_Q1_Income' = 'IN_1995 Q1') %>%
  mutate('1995_Q2_Income' = 'IN_1995 Q2') %>%
  mutate('1995_Q3_Income' = 'IN_1995 Q3') %>%
  mutate('1995_Q4_Income' = 'IN_1995 Q4') %>%
  mutate('1996_Q1_Income' = 'IN_1996 Q1') %>%
  mutate('1996_Q2_Income' = 'IN_1996 Q2') %>%
  mutate('1996_Q3_Income' = 'IN_1996 Q3') %>%
  mutate('1996_Q4_Income' = 'IN_1996 Q4') %>%
  mutate('1997_Q1_Income' = 'IN_1997 Q1') %>%
  mutate('1997_Q2_Income' = 'IN_1997 Q2') %>%
  mutate('1997_Q3_Income' = 'IN_1997 Q3') %>%
  mutate('1997_Q4_Income' = 'IN_1997 Q4') %>%
  mutate('1998_Q1_Income' = 'IN_1998 Q1') %>%
  mutate('1998_Q2_Income' = 'IN_1998 Q2') %>%
  mutate('1998_Q3_Income' = 'IN_1998 Q3') %>%
  mutate('1998_Q4_Income' = 'IN_1998 Q4') %>%
  select(account_id, '1993_Q1_Expenses', '1993_Q2_Expenses', '1993_Q3_Expenses', '1993_Q4_Expenses', '1994_Q1_Expenses', '1994_Q2_Expenses', '1994_Q3_Expenses', '1994_Q4_Expenses', '1995_Q1_Expenses', '1995_Q2_Expenses', '1995_Q3_Expenses', '1995_Q4_Expenses', '1996_Q1_Expenses', '1996_Q2_Expenses', '1996_Q3_Expenses', '1996_Q4_Expenses', '1997_Q1_Expenses', '1997_Q2_Expenses', '1997_Q3_Expenses', '1997_Q4_Expenses', '1998_Q1_Expenses', '1998_Q2_Expenses', '1998_Q3_Expenses', '1998_Q4_Expenses', '1993_Q1_Income', '1993_Q2_Income', '1993_Q3_Income', '1993_Q4_Income', '1994_Q1_Income', '1994_Q2_Income', '1994_Q3_Income', '1994_Q4_Income', '1995_Q1_Income', '1995_Q2_Income', '1995_Q3_Income', '1995_Q4_Income', '1996_Q1_Income', '1996_Q2_Income', '1996_Q3_Income', '1996_Q4_Income', '1997_Q1_Income', '1997_Q2_Income', '1997_Q3_Income', '1997_Q4_Income', '1998_Q1_Income', '1998_Q2_Income', '1998_Q3_Income', '1998_Q4_Income')

# head(transaction_cashflow_per_quarter_and_year_modified)
# 
# df_mod <- left_join(df_mod, transaction_cashflow_per_quarter_and_year_modified, by = c("account_id" = "account_id"))

```

[^43]Entfernen der nicht mehr benötigten Tabellen

[^43]: Erstellt von Léonie Bécheiraz

```{r}

rm(transaction_cashflow_per_quarter_and_year, transaction_cashflow_per_quarter_and_year_modified)

```

#### Kontostand am Ende des Tages[^44]

[^44]: Erstellt von Léonie Bécheiraz

Überblick über die Anzahl Transaktionen am selben Tag über alle
Observationen

```{r}

df_transaction_mod %>%
  group_by(
    account_id,
    date
    ) %>%
  count() %>%
  arrange(desc(n)) %>%
  ungroup() %>% 
  head()

```

Es gibt mehrere Tage und unterschiedliche Konten, welche mehr als eine
Transaktion pro Tag verzeichnet hat. Oft sind diese Tage am Ende eines
Monats. Im vorliegenden Datensatz sind es maximal 7 Transaktionen pro
Tag. Die Überlegung ist nun folgende: da es sich beim vorliegenden
Datensatz bei der Balance um den Betrag nach der Transaktion handelt,
kann in der Umkehr der Saldo vor der Transaktion ausgerechnet werden.
Dieser ausgerechnete Saldo kann im Anschluss mit dem Saldo des
bestehenden Datensatzes abgeglichen werden. Somit ist schnell klar,
welche Transaktion die Letzte des Tage ist und welchen Saldo das Konto
am Ende des Tages aufweist.

Dazu werden zwei Data Frames erstellt. Eines, so wie es in den Daten
bereits vorhanden ist und das zweite mit gerechneten Kontoständen, um
die Reihenfolge zu eruieren. Im gleichen Zug werden noch Spalten für
Soll ("outgoes") und Haben ("credit") erstellt.

```{r}
#Erstellen der neuen Spalten outgoes und incomes
df_transaction_mod <- df_transaction_mod %>%
  mutate(outgoes = ifelse(cashflow == "OUT", amount, 0)) %>%
  mutate(incomes = ifelse(cashflow == "IN", amount, 0)) %>%
  mutate(balance_before_transaction = if_else(cashflow == "IN", balance - amount, balance + amount)) %>% 
  mutate(across(c(outgoes, incomes), as.integer))
  
  head(df_transaction_mod)

```

#### Test am Account 1274[^45]

[^45]: Erstellt von Léonie Bécheiraz

Der Account 1274 weist am 1998-11-30 sieben Zahlungen auf. Nun soll
mittels Code die letzte Zahlung eruiert werden und somit auch der
Kontostand am Ende des Tages.

```{r}
account1274 <- df_transaction_mod %>% 
  filter(
    account_id == 1274,
    date == "1998-11-30"
  ) %>% 
  arrange(date)

account1274

```

Um einen Kontrollwert zu erhalten, werden die Kontobewegungen von Hand
ausgerechnet. Somit dient das Ergebnis als Referenzwert für die spätere
Codekontrolle.

```{r}
account1274_helper <- account1274 %>% 
  mutate(balance_helper = if_else(cashflow == "IN", balance - amount, balance + amount)) %>% 
  select(
    trans_id,
    account_id,
    date,
    outgoes,
    incomes,
    balance_helper
  ) %>% 
  rename(balance = balance_helper) %>% 
  arrange(balance)

account1274_first <- account1274 %>% 
  select(
    trans_id,
    account_id,
    date,
    outgoes,
    incomes,
    balance
  ) %>% 
  arrange(balance)

account1274_first
account1274_helper

```

Die letzte Transaktion an diesem Tag ist die Transaktions ID 374342 mit
einer Abbuchung von 30 CZK und dem Kontoendstand von 94088.0 CZK. Dies
wird nun versucht mittels Code zu erreichen.

```{r}

account1274_first %>% 
  anti_join(account1274_helper, by = c("account_id", "date", "balance"))

```

Die Balance wird nun gerundet um Nachkommastellen zu eliminieren.

```{r}

account1274_round <- account1274 %>% 
  mutate(balance = round(balance)) %>% 
  mutate(balance_before_transaction_round = round(balance_before_transaction)) %>% 
  mutate(amount_round = round(amount)) %>% 
  relocate(balance,
           balance_before_transaction,
           balance_before_transaction_round,
           amount,
           amount_round,
           date,
           cashflow)
```

#### Erkenntnis zur Rundung von amount und balance[^46]

[^46]: Erstellt von Léonie Bécheiraz

Wenn die Rundung der beiden Spalten schon vor dem Rechnen ausgeführt
wird, werden falsche Endbeträge ausgegeben. Das Runden darf erst am
Schluss geschehen. Beim Runden vor dem Ausrechnen der Saldi weisen die
ausgerechneten Saldi Rundungsfehler auf.

#### Erstellen zusätzlicher Spalten für die Saldo-Berechnung[^47]

[^47]: Erstellt von Léonie Bécheiraz

Um diesen Rundungsfehler zu umgehen, werden zwei zusätzliche Spalten
erstellt mit den berechneten Saldi vor und nach der Transaktion.

```{r}
df_transaction_mod <- df_transaction_mod %>% 
  mutate(balance_before_transaction = ifelse(cashflow == "IN", balance - amount, balance + amount)) %>% 
  mutate(balance = balance) %>% 
  relocate(balance,
           balance,
           balance_before_transaction)

```

Die neu berechneten Saldi werden auf das Beispiel mit dem Account 1274
angewendet und zum Schluss gerundet.

```{r}
rm(account1274_first, account1274_helper)

account1274_helper <- account1274 %>% 
  select(
    account_id,
    date,
    balance_before_transaction
  ) %>% 
  rename(balance = balance_before_transaction) %>% 
  mutate(balance = round(balance)) %>% 
  arrange(balance)

account1274_first <- account1274 %>% 
   select(
    account_id,
    date,
    balance
  ) %>% 
  rename(balance = balance) %>% 
  mutate(balance = round(balance)) %>% 
  arrange(balance)

account1274_first
account1274_helper
```

Entfernen der nicht mehr benötigeten Tabellen

```{r}
rm(account1274, account1274_first, account1274_helper)
```

zweite Überprüfung mit dem Konto 1274 ohne Datumseinschränkung

```{r}
# Ergänzen des bestehenden Datensatzes mit der zusätzlichen Spalte balance_end_day (Saldo nach Transaktion) und Filtern des Accounts auf die Nr. 1274
account1274_round	<- df_transaction_mod %>% 
  filter(account_id == 1274) %>% 
  select(
    trans_id,
    account_id,
    date,
    balance
  ) %>% 
  mutate(balance = round(balance))

# Erstellen des Hilfsdatensatzes für die Funktion anti_join()
account1274_helper_round <- df_transaction_mod %>% 
  filter(account_id == 1274) %>% 
  select(
    account_id,
    date,
    balance_before_transaction
  ) %>% 
  mutate(balance = round(balance_before_transaction))

# Erstellen des ersten Datensatzes ohne die Inhalte des Zweiten.
account1274_result_round   <- account1274_round %>% 
  anti_join(account1274_helper_round, by = c("account_id", "date", "balance"))

# Zählen, wieviele Transkationen an einem Tag vorkommen
account1274_result_round %>% 
  group_by(date) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  head()
  
```

Dies scheint gut funktioniert zu haben.

Entfernen der nicht mehr benötigten Tabellen aus dem Global Environment

```{r}
# Entfernen der vorher generierten Datensätzen
rm(account1247_round, account1274_helper_round, account1274_result, account1274_result_round, account1274_round)
```

Anwenden auf das gesamte Data Frame df_transaction_mod

```{r}
# Überprüfung auf mehrfache Transaktionen am gleichen Tag pro Account
df_transaction_mod %>% 
  group_by(
    account_id,
    date
  ) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  head()

```

```{r}
# Erstellen der ersten Tabelle für den Vergleich
transaction_first <- df_transaction_mod %>% 
  mutate(balance_round = round(balance))

# Erstellen der Vergleichstabelle
transaction_helper <- df_transaction_mod %>% 
  mutate(balance_round = round(balance_before_transaction)) %>% 
  select(
    account_id,
    date,
    balance_round
  )

```

#### Funktion anti_join()[^48]

[^48]: Erstellt von Léonie Bécheiraz

Nun können die beiden Tabellen verglichen werden. Der jeweilige Betrag
im Data Frame transaction_first welcher nicht auch im transaction_helper
vorkommt, ist der Tagesendstand. Dies wird mit der Funkton anti_join
gebildet.

```{r}
transaction_result <- transaction_first %>%
  anti_join(transaction_helper, by = c("account_id", "date", "balance_round"))

```

#### Überprüfung[^49]

[^49]: Erstellt von Léonie Bécheiraz

Für die erste Kontrolle werden wiederum die Account_id und das Datum
gruppiert und gezählt, wieviele Transaktionen pro Tag in der Tabelle
enthalten sind.

```{r}
transaction_result %>%
  group_by(
    account_id,
    date
    ) %>%
  count() %>%
  arrange(desc(n)) %>% 
  ungroup()

```

Es sind immer noch mehrere Transaktionen pro Tag vorhanden. Es könnte
sich hier um Fehlerhafte Daten der ursprungs Information handeln. Dies
wird nun genauer untersucht.

#### Untersuchen der Abweichung[^50]

[^50]: Erstellt von Léonie Bécheiraz

Dafür wird der Datensatz df_transaction_mod auf die account id 9814 und
das Datum 1998-11-30 gefiltert.

```{r}
# Überprüfen der Daten im df_trans_mod
df_transaction_mod %>% 
  filter(
    account_id == 9814,
    date == "1998-11-30"
  )

```

#### Überprüfen auf Rundungs- oder Rechenfehler[^51]

[^51]: Erstellt von Léonie Bécheiraz

![Vergleich der Saldi per Hand](../Ressources/account%20id%209814.png)

```{r}
#Überprüfen der Daten nach dem Vergleich
transaction_result %>% 
  filter(
    account_id == 9814,
    date == "1998-11-30"
  )

```

Es bleiben wegen fehlerhaften Ursprungsdaten Transaktionen übrig. Aus
früheren Analysen wissen wir, dass jeweils die Zahlung mit dem Eintrag
"STATEMENT PAYMENT" in der Spalte "characterization" die letzte Zahlung
ist (Kontogebühren).

Diese Erkenntnis wird nun eingesetzt. Als erstes werden die letzten
Transaktionen gekennzeichnet.

```{r}
# Zählen, wieviele Transaktionen pro Tag vorhanden sind und filtern nach den Daten mit nur einer Transaktion
transaction_count <- transaction_result %>% 
  group_by(
    account_id,
    date
  ) %>% 
  count() %>% 
  ungroup() %>% 
  filter(n == 1)

# Erstellen des Data Frame mit den letzten Transaktionen am Tag
last_transaction <- transaction_result %>% 
  semi_join(transaction_count, by = c("account_id", "date"))
```

```{r}
# Filtern nach Daten mit mehr als einer Transaktion pro Tag.
more_than_one_count <- transaction_result %>% 
  group_by(
    account_id,
    date
  ) %>% 
  count() %>% 
  ungroup() %>% 
  filter(n > 1)

# Erstellen des Datensatzes mit mehr als einer Transaktion, welche fehlerhafte Grunddaten haben
more_than_one <- transaction_result %>% 
  semi_join(more_than_one_count, by = c("account_id", "date"))

# Filtern nach Zahlungen der Kontogebühren (dies sind die letzten Zahlungen am Tag)
only_statement_payment <- more_than_one %>%
  filter(characterization == "STATEMENT PAYMENT")

```

```{r}
# Kontogebühren dem bestehenden Data Frame last_transaction anfügen

last_transaction <- last_transaction %>% 
  bind_rows(only_statement_payment)

```

Nun müssen noch die letzten Daten mit Mehrfachzahlungen untersucht
werden.

```{r}

more_than_one_count_rest <- more_than_one_count %>% 
  anti_join(only_statement_payment, by = c("account_id", "date"))

more_than_one_rest <- more_than_one %>% 
  semi_join(more_than_one_count_rest, by = c("account_id", "date"))

# wie verhält es sich, wenn die Beträge gerundet werden?
ceiling_balance <- more_than_one_rest %>% 
  mutate(before_ceiling = ceiling(balance_before_transaction)) %>% 
  mutate(after_ceiling = ceiling(balance))

ceilingA <- ceiling_balance %>% 
  mutate(balance_match = after_ceiling)

ceilingB <- ceiling_balance %>% 
  mutate(balance_match = before_ceiling)

ceiling_result <- ceilingA %>% 
  anti_join(ceilingB, by = c("account_id", "date", "balance_match"))

ceiling_result_count <- ceiling_result %>% 
  group_by(
    account_id,
    date
  ) %>% 
  count() %>% 
  ungroup()
  
ceiling_one_count <- ceiling_result_count %>% 
  filter(n == 1)

ceiling_more_count <- ceiling_result_count %>% 
  filter(n > 1)

ceiling_one <- ceiling_result %>% 
  semi_join(ceiling_one_count, by = c("account_id", "date"))

# Observationen aus ceiling_one an last_transaction anfügen
last_transaction <- last_transaction %>% 
  bind_rows(ceiling_one)

```

```{r}
ceiling_more <- ceiling_result %>% 
  semi_join(ceiling_more_count, by = c("account_id", "date"))
head(ceiling_more)

```

Bei den letzten Zahlungen ist keine Reihenfolge mehr ersichtlich. Um
dies zu klären werden alle Zahlungen zu den jeweiligen Konten und Tagen
genommen und damit nochmals ein komplettes ceiling und anti_join()
durchgeführt.

```{r}


ceiling_more <- df_transaction_mod %>% 
  semi_join(ceiling_more_count, by = c("account_id", "date"))


ceiling_more %>% 
  group_by(
    account_id,
    date
  )%>% 
  count() %>% 
  ungroup()

```

```{r}
ceiling_more_A <- ceiling_more %>% 
  mutate(ceil = ceiling(balance)) 

ceiling_more_B <- ceiling_more %>% 
  mutate(ceil = ceiling(balance_before_transaction))

ceiling_last_result <- ceiling_more_A %>% 
  anti_join(ceiling_more_B, by = c("account_id", "date", "ceil"))

ceiling_last_result %>% 
  group_by(
    account_id,
    date
  )%>% 
  count() %>% 
  ungroup() %>% 
  arrange(desc(n))

```

```{r}
rm(ceiling_balance, ceiling_more, ceiling_more_A, ceiling_more_B, ceiling_more_count, ceiling_one, ceiling_one_count, ceiling_result, ceiling_result_count, ceilingA,ceilingB)

```

```{r}
# Observationen aus ceiling_one an last_transaction anfügen
last_transaction <- last_transaction %>% 
  bind_rows(ceiling_last_result)

last_transaction %>% 
  group_by(
    account_id,
    date
  )%>% 
  count() %>% 
  ungroup() %>% 
  arrange(desc(n))

```

#### Überprüfung der Daten[^52]

[^52]: Erstellt von Léonie Bécheiraz

Das Datum wird nun überprüft, ob nichts verloren ging

```{r}
control <- df_transaction_mod %>% 
  anti_join(last_transaction, by = c("account_id", "date"))

control %>% 
  arrange(account_id, date)

```

```{r}
check_balance <- control %>% 
  mutate(balance_A = ceiling(balance)) %>% 
  mutate(balance_B = ceiling(balance_before_transaction)) %>% 
  select(
    account_id,
    date,
    balance_A,
    balance_B
  ) %>% 
  arrange(account_id, date)

head(check_balance)

```

```{r}
rm(check_balance)

controlA <- control %>% 
  mutate(balance = ceiling(balance))

controlB <- control %>% 
  mutate(balance = ceiling(balance_before_transaction))

control_result <- controlA %>% 
  anti_join(controlB, by = c("account_id", "date", "balance"))

control_result_count <- control_result %>% 
  group_by(
    account_id,
    date
  )%>% 
  count() %>% 
  ungroup() %>% 
  arrange(desc(n))

head(control_result_count)

```

Filtern und Anfügen der Zahlungen

```{r}
control_result_one_count <- control_result_count %>%
  filter(n == 1)
# 
control_result_one <- control_result %>%
  semi_join(control_result_one_count, by = c("account_id", "date"))
# 
# Observationen aus control_result_one an last_transaction anfügen
last_transaction <- last_transaction %>%
  bind_rows(control_result_one)

last_transaction %>%
  group_by(
    account_id,
    date
  )%>%
  count() %>%
  ungroup() %>%
  arrange(desc(n)) %>% 
  head()

```

```{r}
control_result_more_count <- control_result_count %>%
  filter(n > 1)
# 
control_result_more <- control_result %>%
  semi_join(control_result_more_count, by = c("account_id", "date"))
# 
control_result_last <- control_result_more %>%
  filter(trans_id == 3670868)
# 
# Observationen aus control_result_last an last_transaction anfügen
last_transaction <- last_transaction %>%
  bind_rows(control_result_last)

```

```{r}
rm(control, control_result, control_result_count, control_result_more, control_result_more_count, control_result_last, control_result_one, control_result_one_count, controlA, controlB)

```

```{r}
rm(transaction_helper, transaction_result, transaction_first, transaction_count)

```

```{r}
rm(more_than_one, more_than_one_count, more_than_one_count_rest, more_than_one_rest, only_statement_payment)

```

Tage mit mehr als einer Transaktion pro Tag: Überprüfung

```{r}
control <- df_transaction_mod %>% 
  anti_join(last_transaction, by = c("account_id", "date")) %>% 
  arrange(account_id, date)

# head(control)
control

```

```{r}
controlA <- control 

controlB <- control %>% 
  mutate(balance = balance_before_transaction)

control_result <- controlA %>% 
  anti_join(controlB, by = c("account_id", "date", "balance"))

control_result_count <- control_result %>% 
  group_by(
    account_id,
    date
  )%>% 
  count() %>% 
  ungroup() %>% 
  arrange(desc(n))

head(control_result_count)
```

```{r}
control_result_one_count <- control_result_count %>%
  filter(n == 1)
# 
control_result_one <- control_result %>%
  semi_join(control_result_one_count, by = c("account_id", "date"))
# 
# Observationen aus control_result_one an last_transaction anfügen
last_transaction <- last_transaction %>%
  bind_rows(control_result_one)

last_transaction %>%
  group_by(
    account_id,
    date
  )%>%
  count() %>%
  ungroup() %>%
  arrange(desc(n)) %>% 
  head()

```

```{r}
control_result_more_count <- control_result_count %>%
  filter(n > 1)
# 
control_result_more <- control_result %>%
  semi_join(control_result_more_count, by = c("account_id", "date")) %>% 
  arrange(account_id, date)

```

```{r}
# Filtern nach Zahlungen der Kontogebühren (dies sind die letzten Zahlungen am Tag)
only_statement_payment <- control_result_more %>%
  filter(characterization == "STATEMENT PAYMENT")

```

```{r}
# Kontogebühren dem bestehenden Data Frame last_transaction anfügen

last_transaction <- last_transaction %>% 
  bind_rows(only_statement_payment)
```

```{r}
rm(control, control_result, control_result_count, control_result_more, control_result_more_count, control_result_one, control_result_one_count, controlA, controlB, only_statement_payment)

```

```{r}
control <- df_transaction_mod %>% 
  anti_join(last_transaction, by = c("account_id", "date")) %>% 
  arrange(account_id, date)

# head(control)
control

```

outgoes und incomes summiert auf den Tag

```{r}
outgoes_incomes_sum <- control %>% 
  select(
    account_id,
    date, 
    cashflow,
    amount
  ) %>%
  group_by(
    account_id,
    date,
    cashflow
  ) %>%
  summarise(amount_sum = sum(amount)) %>% 
  pivot_wider(names_from = cashflow, values_from = amount_sum) %>% 
  na.replace(., 0) %>% 
  rename(outgoes = OUT,
         incomes = IN)
  
 head(outgoes_incomes_sum)
 
 # rm(control)
```

Bei den meisten Transaktionen handelt es sich um Zahlungen in jeweils
gleicher Höhe, sodass zu Beginn des Tages und am Ende des Tages wieder
derselbe Kontostand wie am Vortag herrscht. Es gibt aber auch Tage, an
denen IN und OUT nicht gleich hoch sind. Diese werden genauer
untersucht.

Unterschiedliches IN und OUT

```{r}
outgoes_incomes_not_equal <- outgoes_incomes_sum %>% 
  filter(outgoes != incomes)
 
head(outgoes_incomes_not_equal)

# rm(outgoes_incomes_sum)
```

```{r}
amount_not_equal <- df_transaction_mod %>%
  semi_join(outgoes_incomes_not_equal, by = c("account_id", "date")) %>% 
  arrange(account_id, date)

head(amount_not_equal)

```

Die letzten Zahlungen können von Hand gefiltert werden und dann dem
gesamten DF angefügt werden. ev. kommt mir noch eine bessere Idee

```{r}
amount_not_equal

```

#### Hilfe in Excel[^53]

[^53]: Erstellt von Léonie Bécheiraz

DF in Excel rausschreiben lassen und dort die trans_id rauslesen

```{r}
write.csv(amount_not_equal, file = "foo.csv")
foo <- read.csv("foo2.csv")

```

```{r}
transid <- df_transaction_mod %>% 
  semi_join(foo, by = "trans_id")

transid

```

```{r}
last_transaction %>% 
  group_by(account_id, date) %>% 
  count() %>% 
  arrange(desc(n))

```

```{r}
last_transaction <- last_transaction %>% 
  mutate(balance_end_day = balance) %>% 
  select(
    trans_id,
    balance_end_day
  )

last_transaction_all <- df_transaction_mod %>% 
  left_join(last_transaction, by = "trans_id") %>% 
  select(
    trans_id,
    balance_end_day
  ) 

summary(last_transaction_all)

```

Die NA's in balance_end_day entstanden bei den Transaktionen, welche an
Tagen mit Mehrfachzahlungen vor der letzten Zahlung getätigt wurden oder
an Tagen, bei denen der Kontostand am Vortag gleich hoch (outgoes und
Kredit gleich hoch).

Für die Tage mit gleich hohem outgoes und Kredit wird eine entsprechende
Spalte hinzugefügt. Dies aber erst, wenn die Kontoendstände dem gesamten
df_transaction_mod angefügt wurde.

Anfügen der Tagessaldi an das bestehende df_transaction_mod

```{r}
# unnötige Spalen entfernen und neue Informationen anfügen 
df_transaction_mod <- df_transaction_mod %>% 
  select(balance:account_nr) %>% 
  select(-c(balance_before_transaction)) %>% 
  left_join(last_transaction_all, by = "trans_id") %>% 
  arrange(account_id, date) %>% 
  relocate(starts_with("balance"), .after = date)
  
```

Entfernen nicht mehr benötigter Data Frames aus dem Global Environment

```{r}
rm(amount_not_equal, ceiling_last_result, control, outgoes_incomes_not_equal, outgoes_incomes_sum, foo, last_transaction, last_transaction_all, transid)

```

#### Neue Spalten:[^54]

[^54]: Erstellt von Léonie Bécheiraz

outgoes und incomes pro Tag

Die vorangegangenen Analysen haben gezeigt, dass es Tage gibt, an denen
outgoes und incomes gleich hoch sind. Um die Umsätze eines Kontos zu
sehen werden nun zwei zusätzliche Spalten erstellt mit der outgoes- und
incomes-summe des jeweiligen Tages. Dieses Ergebnis wird dann auch
wieder dem df_transaction_mod angefügt.

```{r}

outgoes_incomes_sum <- df_transaction_mod %>% 
  select(
    account_id,
    date, 
    cashflow,
    amount
  ) %>%
  group_by(
    account_id,
    date,
    cashflow
  ) %>%
  summarise(amount_sum = sum(amount)) %>% 
  pivot_wider(names_from = cashflow, values_from = amount_sum) %>% 
  na.replace(., 0) %>% 
  rename(outgoes = OUT,
         incomes = IN)
  
 head(outgoes_incomes_sum)

```

Gleich hohe incomes und outgoes:

Um die gleich hohen Beträge in outgoes und Kredit am selben Tag für das
gleiche Konto schnell zu finden, wird eine zusätzliche Spalte erstellt.

```{r}
outgoes_incomes_sum  <- outgoes_incomes_sum %>% 
  mutate(outgoes_incomes_equal = ifelse(outgoes == incomes, TRUE, FALSE))

head(outgoes_incomes_sum)

```

Überprüfen, wieviele Tage gleich hohe outgoes und Kredit haben.

```{r}
outgoes_incomes_sum %>% 
  filter(outgoes_incomes_equal == TRUE) %>% 
  head()

```

Dies stimmt mit den vorangegangenen Analysen überein. Nun werden die
neuen Informationen an das gesamte Data Frame Transaction angefügt.

```{r}
df_transaction_mod <- df_transaction_mod %>% 
  left_join(outgoes_incomes_sum, by = c("account_id", "date")) %>% 
  arrange(account_id, date)

df_transaction_mod %>% 
  filter(outgoes_incomes_equal == TRUE) %>% 
  head()

head(df_transaction_mod)

```

Bei den beiden Transaktionen 2344 und 151858 darf kein Betrag in der
Spalte balance_end_day enthalten sein, da ja die Balance gleich hoch wie
am Vortag ist. Deshalb werden diese beiden Beträge aus der Spalte
gelöscht und mit NA ersetzt.

```{r}
df_transaction_mod <- df_transaction_mod %>% 
  mutate(balance_end_day = ifelse(trans_id == 2344, NA, balance_end_day)) %>% 
  mutate(balance_end_day = ifelse(trans_id == 151858, NA, balance_end_day))

df_transaction_mod %>% 
  filter(outgoes_incomes_equal == TRUE) %>% 
  head()

rm(outgoes_incomes_sum)

```

```{r}
# save(df_transaction_mod, file = "df_transaction_mod.RData")

```

Damit nicht immer alles neu geladen werden muss...

```{r}
# load("df_transaction_mod.RData")

```

#### Datumslücken beheben

Da nach wie vor nur das Datum mit einer Transaktion im
df_transaction_mod vorhanden ist und somit der Zeitverlauf lückenhaft,
wird nun das Datum ergänzt. So wird jeder Tag ersichtlich sein, auch
wenn keine Transaktion stattgefunden hat. Die Account ID und der
Kontostand pro Tag werden auch ergänzt.

```{r}
# load("df_transaction_mod.RData")
date_complete <- df_transaction_mod %>%
  arrange(
    account_id,
    date, 
    balance_end_day
  ) %>% 
  group_by(account_id) %>% 
  mutate(first_transaction = min(date)) %>%
  mutate(last_transaction = max(date)) %>%
  # complete(date = seq.Date(min(date), as.Date("1998/12/31"), by = "day")) %>%
  complete(date = seq.Date(as.Date("1993/01/01"), as.Date("1998/12/31"), by = "day")) %>%
  fill(balance_end_day, first_transaction, last_transaction) %>% 
  ungroup()

# date_complete$balance <- na.replace(date_complete$balance, 0)
date_complete[, c("balance", "balance_end_day", "outgoes", "incomes", "amount")] <- na.replace(date_complete[, c("balance", "balance_end_day", "outgoes", "incomes", "amount")], 0)

firstlasttrans <- date_complete %>% 
  select(
    account_id,
    first_transaction,
    last_transaction
  ) %>% 
  drop_na() %>% 
  group_by(account_id) %>% 
  slice_head(n = 1) %>% 
  mutate(duration = (last_transaction - first_transaction)) %>% 
  arrange(duration)

date_complete <- date_complete %>% 
  select(-c(first_transaction, last_transaction)) %>% 
  left_join(firstlasttrans, by = "account_id")

rm(firstlasttrans)

```

```{r}

df_transaction_complete <- date_complete

head(date_complete)

rm(df_transaction_mod)

```

Die NA's in den restlichen Spalten entstehen, da an diesen Tagen keine
Transaktionen stattgefunden haben. Dies wird so belassen und wenn nötig
zu einem späteren Zeitpunkt angepasst.

#### Kontrolle am Account Nr. 18[^55]

[^55]: Erstellt von Léonie Bécheiraz

```{r}
df_transaction_complete %>%
  filter(account_id == 18,
         year(date) == 1993) %>%
  arrange(date) %>% 
  group_by(month(date)) %>% 
  slice_tail(n = 1) %>% 
  ungroup() %>% 
  head()

# save(df_transaction_complete, file = "df_transaction_complete.RData")

```

```{r}
df_transaction_complete %>% 
  filter(account_id == 18) %>%
  arrange(date) %>% 
  select(
    account_id, 
    date, 
    trans_id,
    balance,
    balance_end_day
  ) %>% 
  drop_na() %>% 
  head()


```

#### Balance per month[^56]

[^56]: Erstellt von Léonie Bécheiraz

Neues Data Frame erstellen mit den monatlichen Kontoständen

```{r}
balance_per_month <- df_transaction_complete %>%
  group_by(
    account_id,
    year(date),
    month(date)
  ) %>%
  slice_tail(n = 1) %>%
  ungroup() %>% 
  arrange(date)

balance_per_month <- balance_per_month %>% 
  select(
    account_id,
    date,
    balance_end_day
  ) %>%
  pivot_wider(names_from = date, values_from = balance_end_day) %>% 
  arrange(account_id)


balance_per_month %>% 
  filter(
    account_id == 18
  )

# save(balance_per_month, file = "balance_per_month.RData")


df_mod <- df_mod %>% 
  select(-starts_with("balance_"),
         -starts_with("IN_"),
         -starts_with("OUT_"))


```

#### Anfügen der monatliche Kontostände an das df_mod[^57]

[^57]: Erstellt von Léonie Bécheiraz

Ergänzen der Kolonnen im balance_per_month mit dem Präfix balance\_ für
die spätere Übersicht im konsolidierten Datensatz. Anschliessend wird
die monatlichen Kontostände dem df_mod mit left_join hinzugefügt.

```{r}
# Kolonnen werden mit dem Präfix ergänzt
if (!grepl("balance_", names(balance_per_month)[2])) {
names(balance_per_month) <- paste0("balance_", names(balance_per_month))
}
df_mod <- df_mod %>% 
  left_join(balance_per_month, by = c("account_id" = "balance_account_id"))

```

#### Quartalsweise outgoes und incomes[^58]

[^58]: Erstellt von Léonie Bécheiraz

Für die spätere Berechnung der Umsätze und Bilanzen werden die outgoes
und incomes monatlich zusammengefasst.

```{r}

date_complete <- date_complete %>% 
  mutate(quarter = quarter(date, type = "year.quarter")) %>% 
  mutate(semester = semester(date, with_year = TRUE)) %>% 
  mutate(year = year(date)) %>% 
  mutate(month = month(date))
  
outgoes_incomes_quarterly <- date_complete %>% 
  select(
    account_id,
    quarter, 
    cashflow,
    amount
  ) %>%
  group_by(
    account_id,
    quarter,
    cashflow
  ) %>%
  summarise(amount_sum = sum(amount)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = cashflow, values_from = amount_sum) %>% 
  rename(incomes_quarterly = IN,
         outgoes_quarterly = OUT) %>%
  na_replace(., 0) %>% 
  select(
    account_id,
    quarter,
    incomes_quarterly,
    outgoes_quarterly
  ) %>% 
  arrange(quarter) %>% 
  pivot_wider(names_from = "quarter", values_from = c("incomes_quarterly", "outgoes_quarterly")) %>% 
  arrange(account_id)

  
 head(outgoes_incomes_quarterly)
 # save(outgoes_incomes_quarterly, file = "outgoes_incomes_quarterly.RData")

```

```{r}
df_mod <- df_mod %>% 
  left_join(outgoes_incomes_quarterly, by = "account_id")

```

#### Jährliche Einkünfte und Ausgaben[^59]

[^59]: Erstellt von Léonie Bécheiraz

```{r}
outgoes_incomes_yearly <- date_complete %>% 
  select(
    account_id,
    year, 
    cashflow,
    amount
  ) %>%
  group_by(
    account_id,
    year,
    cashflow
  ) %>%
  summarise(amount_sum = sum(amount)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = cashflow, values_from = amount_sum) %>% 
  rename(incomes_yearly = IN,
         outgoes_yearly = OUT) %>%
  na_replace(., 0) %>% 
  select(
    account_id,
    year,
    incomes_yearly,
    outgoes_yearly
  ) %>% 
  arrange(year) %>% 
  pivot_wider(names_from = "year", values_from = c("incomes_yearly", "outgoes_yearly")) %>% 
  arrange(account_id)

  
 head(outgoes_incomes_yearly)
 # save(outgoes_incomes_yearly, file = "outgoes_incomes_yearly.RData")
 # save(date_complete, file = "date_complete.RData")
 
```

```{r}
df_mod <- df_mod %>% 
  left_join(outgoes_incomes_yearly, by = "account_id")

# save(balance_per_month, file = "balance_per_month.RData")
# save(date_complete, file = "date_complete.RData")
rm(outgoes_incomes_quarterly, outgoes_incomes_yearly, balance_per_month)
rm(date_complete)

```

neues DF mit den ein und ausgängen pro Monat (Umsatz) ev. zusätzliche
Spalte mit Info ob der Account im Minus ist oder nicht

Accountgruppen erstellen, wie lange der Account aktiv war (z.B. halbes
Jahr, Jahr, etc.)

## Erstellen des konsolidierten Data Frames[^60]

[^60]: Erstellt von Léonie Bécheiraz

Das konsolidierte Data Frame wird und dem Namen **df_cons** gespeichert.

```{r}
df_cons <- df_mod
# save(df_cons, file = "df_cons.RData")
# save(df_mod, file = "df_mod.RData")


```

Übersicht über die Struktur des konsolidierten Datensatzes.

```{r include=FALSE}
glimpse(df_cons)

```

## Datengrundlage[^61]

[^61]: Erstellt von Luca Gisler

Die uns zu Grunde liegenden Daten lassen sich als von der Bank sowie als
exogen erhoben unterscheiden.

a\. Wie können die Daten noch weiter gruppiert und angeordnet werden, um
eine optimale Grundlage für die Analyse zu bilden?

Die Daten können je nach Typ und Struktur noch weiter gruppiert werden
um für folgende Analysen eine optimale Grundlage zu schaffen.
Gruppierungen sind von Interesse, da sie eine Systematischen Vorteil
liefern können.

Das war unsere Ausgangslage: ![an image caption Source: ERD
Ausgangslage.](CrossSellingInBanking%5CRessources%5CSOLL-Zustand.png)

Ein paar Beispiele für solche weitere Gruppierungen sind:

-   Einkommen pro Monat
-   Einkommen Quartalsweise
-   Einkommen Jährlich
-   Ausgaben pro Monat
-   Ausgaben Quartalsweise
-   Ausgaben Jährlich
-   Kontostand pro Monat
-   Kontostand Quartalsweise
-   Kontostand Jährlich

Mit diesen sind die Daten in einer für uns und die Bank in einer
nützlichen Form. Diese Erkenntnisse sind dann in den Konsolidierten
Datensatz eingeflossen. Diese Gruppierten Daten sind für uns von
Interesse, da wir mit Ihnen effizient, klar und strukturiert arbeiten
können. Beim Erstellen des **df_cons** sind unsere Gedanken und
Änderungen eingeflossen.

```{r include=FALSE}
glimpse(df_cons)
```

b\. Wie umfassend sind die Stichproben der Daten der Bank? Und trifft
dies für alle einzelnen Datensätze zu?

Weshalb eine Überprüfung der Stichprobengrösse? - Ein zu kleiner
Stichprobenumfang kann dazu führen, dass nicht die gewünschte  Tiefe des
eigentlich angestrebten erreicht wird. - Ein zu großer Stichprobenumfang
kann dazu führen, dass unnötig Ressourcen  verschwendet werden.

Wir bemühen uns, genügend Proben zu haben, um einen Effekt vernünftig zu
erkennen, wenn er wirklich vorhanden ist, ohne begrenzte Ressourcen für
zu viele Proben zu verschwenden.

Deshalb die "Sample Size Calculation"

Bevölkerung in Tschechien:

1993: 10.33 Mio 1994: 10.33 Mio 1995: 10.33 Mio 1996: 10.32 Mio 1997:
10.30 Mio 1998: 10.29 Mio 1999: 10.28 Mio

Quelle:
(<https://www.laenderdaten.info/Europa/Tschechien/bevoelkerungswachstum.php>)

Sind Durchschnittlich: 10.3114 Mio Confidence Level: 95% Margin of
Error: 3 %

Berechnung: (Z-Score)2 x StdDev x (1-StdDev)/(margin of error)2

Ideale Sample Grösse: 1067

Der zur Verfügung gestellte Anzahl Accounts hat eine Grösse von 4500 Zeilen,
was in ungefähr dem vierfachen der berechneten optimalen
Stichprobengrösse entspricht. Dies bedeutet, dass wir von mehr Beobachtungen als
nötig sprechen.

relation account (4500 objects in the file ACCOUNT.ASC) -\> Wie im
Beispiel oben behandelt relation client (5369 objects in the file
CLIENT.ASC) -\> Gleicher Fall von einer Ausreichender Stichprobengrösse.
relation disposition (5369 objects in the file DISP.ASC) -\> Gleicher
Fall von einer Ausreichender Stichprobengrösse. relation permanent order
(6471 objects in the file ORDER.ASC) -\> Gleicher Fall von einer
Ausreichender Stichprobengrösse. relation transaction (1056320 objects
in the file TRANS.ASC) -\> Da die Transaktionen unregelmässig und
mehrmals möglich sind haben wir hier eine sehr hohe Anzahl
Observationen. relation loan (682 objects in the file LOAN.ASC) -\> Um
eine Aussage über die Richtige Anzahl Kredite machen zu können, bräuchte
man die gesamte Anzahl von Krediten von 1993-1999. relation credit card
(892 objects in the file CARD.ASC) -\> Um eine Aussage über die
Richtige Anzahl Kreditkarten machen zu können, bräuchte man die gesamte
Anzahl von Kreditkarten von 1993-1999. relation demographic data (77
objects in the file DISTRICT.ASC) -\> Die Distrikte werden nicht in
Stichproben erfasst, also werden alle Distrikte so wiedergegeben wie sie
in Wirklichkeit sind.

### Zudem wird die Distribution der Datensätze und deren Qualität überprüft.

Zur Überprüfung der Qualität gehört: - Zuverlässigkeit - Relevanz -
Verständlichkeit - Korrektheit - Aktualität

Zuverlässigkeit: Da dies Eine Challenge ist die bereits dutzende male
erarbeitet wurde, und von Fachhoschulen, Unis und weiteren Institutionen
verwendet wird, haben wir eine Zuverlässige Quelle.
Relevanz: Diese Daten sind für uns relevant, da diese Daten unseren Informationsbedarf
abdecken. 
Verständlichkeit: Durch die Transformation der Daten ins
Englische kam die Verständlichkeit. Denn Tschechisch wird bei uns in der
Gruppe nicht gesprochen.
Aktualität: Diese Daten stammen aus den Jahren 1993-1999 und sind für die heutige Zeit nicht mehr aktuell, da sich dieses Gebiet stark digitalisiert hat und somit nicht mehr das selbe ist wie dazumal

Da wir mit den zur Verfügung gestellten Daten arbeiten, und keinen
Einfluss auf die Qualitätansprüche bei der Erhebung haben können wir
Falsche oder Fehlende Daten verändern oder entfernen.

c\. Die Datenattribute werden auf ihre Verteilung sowie ihre Veränderung
über die Zeit analysiert. Dabei werden technische Mittel der
explorativen Datenanalyse angewendet.

Eine Überprüfung ist die Veränderung des Alters bei der Eröffnung eines
Kontos über die Zeit:

```{r}
ggplot(df_cons, aes(x = account_opening_year, y = as.numeric(owner_age_at_account_opening)))+
  geom_jitter()+
  geom_smooth()+
  labs(title = "Veränderung des Alters bei Eröffnung über die Zeit",
              subtitle = "1993-1997")+
  xlab("Jahr")+
  ylab("Alter bei Kontoeröffnung in Jahren")

```

Als erstes kann man bei den minimalen Werten einen Trend ablesen, Das
minimale Alter bei der Eröffnung wurde wurde über die Jahre konstant
höher. 1993 hatten noch Kinder ab 10 Jahren bereits ein Konto, im Jahr
1997 lagen die jüngsten Kontoeröffner bei rund 15 Jahren. Dieser Trend
lässt sich auch an der Alters Obergrenze entnehmen. Bei den älteren
Menschen kann das ein Zeichen davon sein, dass die Älteren Menschen
immer älter werden. auch gab es in den Jahren 1993 und 1995 vermehrte
Kontoeröffnungen.

Kann man einen Trend bezüglich des Geschlechts der Kontoinhaber
feststellen?

```{r}
ggplot(df_cons, aes(x = account_opening_year, fill = owner_sex))+
  geom_bar()
```

Wir können keinen Trend bezüglich den Geschlechtern und der Veränderung
über die Zeit erkennen. Wir erkennen das es eine in etwa gleiche
Verteilung der Konten über beide Geschlechter gibt.

i\. Jegliche Datenattribute werden innerhalb des eigenen Datenrahmens
analysiert.

Diese Analyse und Transformation wurde beim Sichten der Daten bereits
erledigt, somit konnten bereits zu Beginn die Richtigen Datentypen und
Formate gewählt werden. Des Weiteren wurden für den Konsolidierten
Datensatz noch weitere Attribute erstellt, gruppiert und transformiert.
Dies wurde gemacht um eine optimale Grundlage für die weiteren Analysen
zu haben.

## Ausführliche Analysen

```{r}
# load("df_cons.RData")
# load("date_complete.RData")
# load("df_transaction_mod.RData")
```

### Zusätzliche Spalten[^62]

[^62]: Erstellt von Léonie Bécheiraz

Für die weiteren Analysen werden zusätzliche Spalten benötigt.

#### Spalte aktuelles Alter des Kontoinhabers (owner_current_age)[^63]

[^63]: Erstellt von Léonie Bécheiraz

Neue Spalte "owner_current_age" für das aktuelle Alter des Kunden am
01.01.1999 Eine Spalte für die Altersgruppen: "0-17" "18-30" "31-40"
"41-50" "51-60" "61-70" "70+"

```{r}
# aktuelles Alter der Kunden und Altersgruppen
df_cons <- df_cons %>% 
  mutate(owner_current_age = trunc((owner_dateofbirth %--% as.Date("1999-01-01")) / years(1))) %>%
  mutate(age_groups = case_when(
    owner_current_age < 18 ~ "0-17",
    owner_current_age >= 18 & owner_current_age <= 30 ~ "18-30",
    owner_current_age > 30 & owner_current_age <= 40 ~ "31-40",
    owner_current_age > 40 & owner_current_age <= 50 ~ "41-50",
    owner_current_age > 50 & owner_current_age <= 60 ~ "51-60",
    owner_current_age > 30 & owner_current_age <= 70 ~ "61-70",
    owner_current_age > 70  ~ "70+"
  )) %>% 
  mutate(age_groups = as.factor(age_groups))

```

#### Spalte Kreditkarte (has_creditcard)[^64]

[^64]: Erstellt von Léonie Bécheiraz

Erstellen einer neuen Spalte "has_creditcard" mit dem logischen Wert
TRUE wenn ein Konto mit einer Kreditkarte verbunden ist.

```{r}
df_cons <- df_cons %>% 
  mutate(has_creditcard = ifelse(is.na(card_id), FALSE, TRUE))

```

#### Spalte Girokonto (is_checking_account)[^65]

[^65]: Erstellt von Léonie Bécheiraz

Die uns zugrunde liegenden Daten sagen leider nichts über die Kontoart
aus. Deshalb muss dies mittels Analyse bestimmt werden. Folgende
Gedanken dazu: ein Girokonto hat regelmässige Transaktionen. Es gibt im
Durchschnitt mindestens je eine Transaktion (in und out) pro Monat.

Erstellen einer neuen Spalte "is_checking_account" mit dem logischen
Wert TRUE wenn es sich beim Konto um ein Girokonto handelt.

```{r}
# Spalte für die Information, ob es Girokonto (is_checking_account) ist oder nicht
checking_account <- df_transaction_complete %>% 
  drop_na(trans_id) %>% 
  group_by(
    account_id,
    year(date),
    cashflow
  ) %>% 
    count() %>% 
  group_by(
    account_id,
    cashflow
  ) %>% 
  summarise(mean_n = round(mean(n), digits = 0)) %>% 
  pivot_wider(names_from = cashflow, values_from = mean_n) %>% 
  mutate(is_checking_account = ifelse(IN > 12 & OUT > 12, TRUE, FALSE)) %>% 
  select(account_id, is_checking_account) %>% 
  ungroup()

set.seed(256)
slice_sample(checking_account, n = 5)


# Anfügen der neuen Spalte an des konsolidierte Data Frame
df_cons <- df_cons %>% 
  left_join(checking_account, by = "account_id")



# df_cons speichern für ein späteres laden
# save(df_cons, file = "df_cons.RData")
rm(checking_account)

df_cons %>% 
  select(account_id, is_checking_account) %>% 
  head(5)
  
```

#### Spalte durchschnittliche Ausgaben (outgoes_avg)[^66]

[^66]: Erstellt von Léonie Bécheiraz

Um einem Kunden ein Cross Selling Angebot machen zu können, welches auch
dem Kunden einen Mehrwert bietet, muss ein regelmässiges Einkommen
vorhanden sein.

Regelmässiges Einkommen

```{r}
# Durchschnittliche Ausgaben berechnen
outperyear <- df_cons %>% 
  select(
    account_id,
    starts_with("outgoes_yearly_")
  ) %>% 
  pivot_longer(starts_with("outgoes_yearly_"), names_to = "outgoes_per_year", values_to = "amount", values_drop_na = FALSE) %>% 
  filter(amount != 0) %>% 
  group_by(account_id) %>% 
  summarise(outgoes_avg = round(mean(amount), digits = 0))

# Anfügen der neuen Spalte an das df_cons
df_cons <- df_cons %>% 
  left_join(outperyear, by = "account_id")
  
rm(outperyear)

```

#### Spalte Durchschnittseinkommen (income_avg)[^67]

[^67]: Erstellt von Léonie Bécheiraz

Um einem Kunden ein Cross Selling Angebot machen zu können, welches auch
dem Kunden einen Mehrwert bietet, muss ein regelmässiges Einkommen
vorhanden sein.

Regelmässiges Einkommen

```{r}
# Durchschnittliches Einkommen berechnen
inperyear <- df_cons %>% 
  select(
    account_id,
    starts_with("incomes_yearly_")
  ) %>% 
  pivot_longer(starts_with("incomes_yearly_"), names_to = "income_per_year", values_to = "amount", values_drop_na = FALSE) %>% 
  filter(amount != 0) %>% 
  group_by(account_id) %>% 
  summarise(income_avg = round(mean(amount), digits = 0))

# Anfügen der neuen Spalte an das df_cons
df_cons <- df_cons %>% 
  left_join(inperyear, by = "account_id")


```

#### Spalte für regelmässiges Einkommen (is_regular_income)[^68]

[^68]: Erstellt von Léonie Bécheiraz

Erstellen einer neuen Spalte mit der Information, ob das Konto über
regelmässige, monatliche Lohnzahlungen verfügt. Deshalb ist eine
Bedingung, dass es sich dabei um ein Girokont handelt.

```{r}
df_cons <- df_cons %>% 
  mutate(is_regular_income = is_checking_account)

```

#### Spalte regelmässiges Einkommen mind. 80% (is_regular_income_80)[^69]

[^69]: Erstellt von Léonie Bécheiraz

Um die Kreditkartenausgaben oder Darlehen decken zu können braucht der
Kunde ein regelmässiges Einkommen, welches über dem ortsüblichen
Einkommen liegt.

Erstellen einer neuen Spalte "regular_income" mit dem logischen Wert
TRUE wenn auf dem Konto regelmässig Beträge über dem Existenzminimum
vorhanden sind. Für diese Information werden alle Konten mit
regelmässigem Einkommen und einem Betrag von 10% unter dem ortsüblichen
Einkommensdurchschnitt ermittelt.

Datenbeschrieb - is_regular_income_80 für durchschnittliche Einkommen
mind. 80% vom ortüblichen Durchschnitt

```{r}
# neue Spalte für regelmässiges Einkommen von mind. 80% des ortsüblichen Durchschnitts
df_cons <- df_cons %>% 
  mutate(is_regular_income_80 = ifelse(((income_avg * 0.2) >= owner_district_average_salary & is_regular_income == TRUE), TRUE, FALSE)) 

# Anzahl der Accounts mit regelmässigen monatlichen Einkommen von mind. 80%
foo80 <- df_cons %>% 
  filter(is_regular_income_80 == TRUE) %>% 
  nrow()

paste("Es gibt", foo80, "Accounts mit einem regelmässigen Einkommen von mindestens 80% des ortsüblichen Durchschnittsalärs", sep = " ")
rm(foo80)

```

#### Spalte Beratung vor Ort (consultation_on_site)

Erstellen einer neuen Spalte "consultation_on_site" mit dem logischen
Wert TRUE wenn das Konto eine positive Vermögensentwicklung über die
gesamte Laufzeit aufweist.

```{r}
# erstellen der neuen Spalte
df_cons <- df_cons %>% 
  mutate(consultation_on_site = ifelse(owner_district_name == account_district_name, TRUE, FALSE))

```

### Einkommensentwicklung und -verteilung[^70]

[^70]: Erstellt von Léonie Bécheiraz

Das Augenmerk soll nun auf die Salärentwicklung und -verteilung
gerichtet werden.

Eine Übersicht der Einkommen ergibt sich aus dem summary() der Spalte
"incomes_per_year".

```{r}
# Übersicht über die Verteilung der Jahreseinkommen
summary(df_cons$income_avg)

```

Vom Mindestbetrag bis zum Höchstbetrag sind grosse Unterschiede zu
erkennen. Die Verteilung der Beträge wird in einem Density-Plot
deutlich.

```{r}
df_cons %>% 
  ggplot(aes(income_avg)) +
  geom_histogram(aes(y = ..density..)) +
  geom_density(fill = "cyan", alpha = 0.3) +
  theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Yearly income average") +
  labs(
    x = "Amount [CZK]",
    # y = "",
    subtitle = "Time span: 1993 - 1998, across all accounts"
  ) +
  scale_x_continuous(labels = comma, limits = c(0, 1000000)) +
  scale_y_continuous(labels = comma)

```

Die meisten Accounts weisen ein Durchschnittseinkommen um 100k CZK auf.
Die Stufe bei 250k CZK deutet auf eine grössere Anzahl Accounts hin,
welche um diesen Bereich ihr Einkommen haben. Danach nimmt die Anzahl
Accounts mit hohen bis sehr hohen Beträgen deutlich ab. Die Verteilung
ist hier rechtsschief.

```{r}
# library(tidyquant)
skew_incomes <- df_cons %>% 
  summarise(skew_builtin = skewness(income_avg))

skew_incomes
rm(skew_incomes)

```

Die Kennzahl (skewness) ist 1.08 und somit grösser als 0. Dies heisst,
dass die Verteilung der Einkommen eine positive Schiefe (rechtsschief)
aufweist, was im Plot sehr gut zu erkennen ist.

#### Entwicklung Jahreseinkommen[^71]

[^71]: Erstellt von Léonie Bécheiraz

Mittels Visualisierung mit einem Boxplot wird die Entwicklung des
Jahreseinkommens deutlich.

```{r}
# Jahreseinkommen für Visualisierung umformen
inperyear <- df_cons %>% 
  select(
    account_id,
    starts_with("incomes_yearly_")
  ) %>% 
  pivot_longer(starts_with("incomes_yearly_"), names_to = "income_per_year", values_to = "amount", values_drop_na = FALSE)

# Visualisierung
inperyear %>% 
  filter(amount > 0) %>% 
ggplot(aes(x = income_per_year, y = amount, fill = as.factor(income_per_year))) +
  geom_boxplot() +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Incomes average") +
  labs(
    x = "",
    y = "Amount per year [CZK]",
    subtitle = "Time span: 1993 - 1998, across all accounts"
  ) +
  scale_x_discrete(labels = c("incomes_yearly_1993" = "1993",
                                                 "incomes_yearly_1994" = "1994",
                                                 "incomes_yearly_1995" = "1995",
                                                 "incomes_yearly_1996" = "1996",
                                                 "incomes_yearly_1997" = "1997",
                                                 "incomes_yearly_1998" = "1998"))

```

Wie beim Density-Plot (Verteilung) kommt deutlich zum Ausdruck, dass die
meisten Konten Einkommen um 125'000 CZK aufweisen. Die
Einkommensentwicklung ist nicht so leicht zu erkennen. Ein geringer
Anstieg über die beobachteten fünf Jahre lässt sich ausmachen mit
Ausnahme des Jahres 1996.

```{r}
inperyear %>% 
  filter(amount > 0) %>% 
  summary()

```

Für die nächste Analyse werden alle Einkommen unter einem Betrag von
100'000 CZK weggelassen.

```{r}
# Visualisierung alle Einkommen unter 100000 CZK
inperyear %>% 
  filter(amount > 0,
         amount < 100000) %>% 
ggplot(aes(x = income_per_year, y = amount, fill = as.factor(income_per_year))) +
  geom_boxplot() +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Incomes average") +
  labs(
    x = "",
    y = "Amount per year [CZK]",
    subtitle = "Amount under 100,000 CZK, across all accounts"
  ) +
  scale_x_discrete(labels = c("incomes_yearly_1993" = "1993",
                                                 "incomes_yearly_1994" = "1994",
                                                 "incomes_yearly_1995" = "1995",
                                                 "incomes_yearly_1996" = "1996",
                                                 "incomes_yearly_1997" = "1997",
                                                 "incomes_yearly_1998" = "1998")) +
  scale_y_continuous(labels = comma)

```

Der grösste Anteil der Konten weist ein Einkommen zwischen 50-80K auf.

```{r}
# Visualisierung alle Einkommen zwischen 100000 - 320000 CZK
inperyear %>% 
  filter(amount > 100000,
         amount < 320000) %>% 
ggplot(aes(x = income_per_year, y = amount, fill = as.factor(income_per_year))) +
  geom_boxplot() +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Incomes average") +
  labs(
    x = "",
    y = "Amount per year [CZK]",
    subtitle = "Amount between 100,000 & 320,000 CZK, across all accounts"
  ) +
  scale_x_discrete(labels = c("incomes_yearly_1993" = "1993",
                                                 "incomes_yearly_1994" = "1994",
                                                 "incomes_yearly_1995" = "1995",
                                                 "incomes_yearly_1996" = "1996",
                                                 "incomes_yearly_1997" = "1997",
                                                 "incomes_yearly_1998" = "1998")) +
  scale_y_continuous(labels = comma)

rm(inperyear)

```

Auch hier ist wieder dieselbe Entwicklung zu erkennen wie schon bei den
vorangeganenen Visualisierungen.

#### Spalte Salärgruppen (salary_groups)[^72]

[^72]: Erstellt von Luca Gisler

Folgende Gruppen können nun in einer neuen Spalte "salary_groups"
erstellt werden: - lower_income für ein Jahreseinkommen bis 60K -
lower_middle_income für ein Jahreseinkommen von 60K bis 110K -
middle_income für ein Jahreseinkommen von 110K bis 145K -
upper_middle_income für ein Jahreseinkommen von 145K bis 220K -
upper_income für ein Jahreseinkommen von 220K bis 320K - high_income für
ein Jahreseinkommen über 320K

```{r}

# Einkommensgruppen erstellen
foo <- df_cons %>% 
  select(account_id, is_checking_account, income_avg) %>% 
  filter(is_checking_account == TRUE) %>% 
  mutate(salary_groups = case_when(
    income_avg < 60000 ~ "lower-income",
    income_avg >= 60000 & income_avg < 120000 ~ "lower-middle-income",
    income_avg >= 120000 & income_avg < 180000 ~ "middle-income",
    income_avg >= 180000 & income_avg < 240000 ~ "upper-middle-income",
    income_avg >= 240000 & income_avg < 300000 ~ "upper-income",
    income_avg >= 300000 ~ "high-income"
  )) %>% 
  select(account_id, salary_groups)

# An das df_cons anfügen
df_cons <- df_cons %>% 
  left_join(foo, by = "account_id") %>% 
  mutate(salary_groups = as.factor(salary_groups))

# Reihenfolge der Levels festlegen
df_cons$salary_groups <- factor(df_cons$salary_groups, levels = c("lower-income", "lower-middle-income", "middle-income", "upper-middle-income", "upper-income", "high-income"))

summary(df_cons$salary_groups) 

# Visualisierung
df_cons %>% 
  filter(!is.na(salary_groups)) %>% 
  ggplot(aes(salary_groups, fill = salary_groups)) +
  geom_bar() +
  scale_fill_viridis_d(alpha = 0.6, option = "L") +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15),
      axis.text.x = element_text(size = 8)
    ) +
  labs(
    title = "Number of Accounts per Salary Groups",
    x = ""
  ) 
rm(foo)

```

Auffällig ist die hohe Anzahl Konten der höchsten Einkommen

#### Spalte für Vermögensentwicklung (assets_dev)[^73]

[^73]: Erstellt von Léonie Bécheiraz

Aus Bankensicht ist es auch relevant, wie sich das Vermögen entwickelt.
Dazu wurde der Kontostand Ende 1998 in der Spalte "assets_dev"
gespeichert.

```{r}
# erstellen der beiden Spalten 
df_cons <- df_cons %>% 
  mutate(assets_dev = `balance_1998-12-31`) 

```

Inspizieren der Spalte mit dem Betrag der Vermögensentwicklung

```{r}

summary(df_cons$assets_dev)

```

#### durchschnittliche Vermögensentwicklung (pro Jahr)[^74]

[^74]: Erstellt von Léonie Bécheiraz

Die jährliche Vermögensentwicklung bewegt sich in den Jahren 1993-1998
zwischen -25821 und 138317.

Die meisten Accounts weisen im Jahresdurchschnitt eine positive
Vermögensentwicklung auf.

#### Spalte Gruppe der Vermögensentwicklung (assets_dev_groups)[^75]

[^75]: Erstellt von Léonie Bécheiraz

Es wird eine zusätzliche Spalte erstellt für die Information, ob das
Konto eine positive, neutrale oder negative Entwicklung über die
Laufzeit erfährt.

```{r}

df_cons <- df_cons %>% 
  mutate(assets_dev_groups = case_when(
    assets_dev < 0 ~ "negative", 
    assets_dev == 0 ~ "neutral", 
    assets_dev > 0 ~ "positive")) %>% 
  mutate(assets_dev_groups = as.factor(assets_dev_groups))

df_cons %>% 
  select(account_id, assets_dev_groups) %>% 
  head(., 3)

```

#### Vermögensentwicklung über die Jahre[^76]

[^76]: Erstellt von Léonie Bécheiraz

```{r}
# erstellen des Dataframes um die Verteilung über die Jahre aufzuzeigen
 df <- df_cons %>% 
  select(account_id, assets_dev_groups,
    starts_with("balance")) %>% 
  select(account_id, assets_dev_groups, contains("-12-")) %>%
  rename("1993" = "balance_1993-12-31", 
         "1994" = "balance_1994-12-31",
         "1995" = "balance_1995-12-31",
         "1996" = "balance_1996-12-31",
         "1997" = "balance_1997-12-31",
         "1998" = "balance_1998-12-31") %>% 
  pivot_longer(starts_with("199"), names_to = "year", values_to = "amount", values_drop_na = FALSE) %>%
  filter(amount != 0) 

# Visualisierung über alle Accounts, Jahre und Beträge
df %>% 
  ggplot(aes(x = year, y = amount, fill = as.factor(year))) +
  geom_boxplot() +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Assets development") +
  labs(
    x = "",
    y = "amount [CZK]",
    subtitle = "Time span: 1993 - 1998, across all accounts with assets dev between -25k and 60k CZK"
  ) +
  scale_y_continuous(labels = comma)

# Ausreisser beseitigen Mithilfe der Interquartilsabstandsmethode 
df_no_outliers <- subset(df, df$amount > (quantile(df$amount, .25) - 1.5*IQR(df$amount)) & df$amount < (quantile(df$amount, .75) + 1.5*IQR(df$amount)))

# Visualisierung mit eingeschränktem Betrag
df_no_outliers %>% 
  filter(amount < 60000) %>% 
  ggplot(aes(x = year, y = amount, fill = as.factor(year))) +
  geom_boxplot() +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Assets development") +
  labs(
    x = "",
    y = "amount [CZK]",
    subtitle = "Time span: 1993 - 1998, across all accounts without outliers"
  ) +
  scale_y_continuous(labels = comma)

rm(df_no_outliers)

```

Nach entfernen der Outliers ist deutlich zu erkennen, dass die
Vermögensentwicklung leicht zu nimmt im positiven Bereich aber auch
deutlich abnimmt im negativen Bereich. Durch die negative Entwicklung
sind im negativen Bereich Outliers entstanden.

#### Geschichtliches Intermezzo

Im Jahr 1993 gab es die meisten positiven Vermögensentwicklungen. Danach
gehen die Vermögen zurück analog der Einkommensentwicklung. Diese
Entwicklung könnte auch einen geschichtlichen Zusammenhang haben. Am 1.
Januar 1993 wurde die heutige Tschechische Republik gegründet. Der noch
junge souveräne Staat könnte wirtschaftlich in der Findungsphase gewesen
sein, denn auch die Währung wurde mit der Tschechischen Krone am 8.
Februar 1993 neu eingeführt. Gemäss geschichtlichen Überlieferungen
verlief die Umstellung der Währung von der Tschechoslowakischen Krone
auf die Tschechische Krone reibungsfrei. Der Bankencrash 1997 war das
Ende des wirtschaftlichen Aufschwungs. 12 Finanzinstitute mussten
Insolvenz anmelden. Unsere Bank scheint nicht von der Insolvenz
betroffen zu sein, denn die vorliegenden Daten reichen bis Ende 1998.
Die darauf folgende Rezession der tschechischen Wirtschaft könnte eine
Erklärung für die rückläufige Vermögensentwicklung in den Jahren 1997
und 1998 sein.

#### Vermögensentwicklung auf die einzelnen Jahre

```{r}
# Visualisierung auf 
df %>% 
  ggplot(aes(x = amount, fill = as.factor(assets_dev_groups))) +
  geom_histogram(position = "fill", alpha = 0.4) +
  facet_wrap(~ year, 
             scales = "free_y") +
  theme(
      legend.title = element_blank(),
      plot.title = element_text(size = 15), 
      axis.text.x = element_text(angle = 30, hjust = 1)
    ) +
    ggtitle("Assets development") +
  labs(
    x = "amount [CZK]",
    y = "percent",
    fill = "Assets development",
    subtitle = "across all accounts per year"
  ) +
  scale_x_continuous(labels = comma)

rm(df)

```

Erstaundlich ist, dass trotz Rezession sehr viele Accounts eine positive
Entwicklung verzeichnen. Die negative Entwicklung ist vor allem in den
Jahren 1997 und 1998, als die Rezession begann, zu sehen.

Durchschnittseinkommen auf die Vermögensentwicklung aufgeteilt

```{r}
ggplot(df_cons, aes(x = income_avg, fill = as.factor(assets_dev_groups))) +
  geom_density(alpha = 0.3) +
  theme_minimal() +
    theme(
      plot.title = element_text(size = 15), 
    ) +
    ggtitle("Distribution of income among the assets development groups") +
  labs(
    x = "amount [CZK]",
    fill = "Assets development",
    subtitle = "Time span: 1993 - 1998, across all accounts",
    legend = "Assets development"
  ) +
  scale_x_continuous(labels = comma) +
  scale_y_continuous(labels = comma)

```

Das Einkommen mit dem Logarithmus angepasst.

```{r}
ggplot(df_cons, aes(x = income_avg, fill = as.factor(assets_dev_groups))) +
  geom_density(alpha = 0.3) +
  theme_minimal() +
    theme(
      plot.title = element_text(size = 15), 
    ) +
    ggtitle("Distribution of income among the assets development groups") +
  labs(
    x = "amount (log transformed) [CZK]",
    fill = "Assets development",
    subtitle = "Time span: 1993 - 1998, across all accounts",
    legend = "Assets development"
  ) +
  scale_x_log10()

```

Mit dem Logarithmus wurden Einkommen transformiert um die Verteilung der
Beträge besser ersichtlich zu machen. Die Dichte entspricht nun den
"neuen" Werten und es ist gut zu erkennen, dass die Accounts mit höheren
Einkommen häufiger negative Vermögensentwicklungen aufweisen. Die
Verteilung der negativen Vermögensentwicklung ist unimodal leicht
linksschief und die der positiven Vermögensentwicklung bimodal ebenfalls
mit einer leichten Tendez zu linksschief.

#### Vemögensentwicklung unterteilt auf die Einkommensgruppen[^78]

[^78]: Erstellt von Aaron Studer

```{r}

# df_cons$salary_groups <- factor(df_cons$salary_groups, levels = c("lower_income", "lower_middle_income", "middle_income", "upper_middle_income", "upper_income", "high_income"))

df_cons %>% 
  filter(!is.na(salary_groups)) %>% 
  ggplot(aes(x = assets_dev, fill = assets_dev_groups)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~ salary_groups) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 15),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    ggtitle("Assets development avg from 1993 - 1998") +
  labs(
    x = "amount [CZK]",
    fill = "Assets dev",
    subtitle = "across all accounts with assets dev from 60k down to -25k CZK",
    legend = "Assets development"
  ) +
  scale_y_continuous(labels = comma) +
  scale_x_continuous(labels = comma)
  
```

Auffällig ist das mittlere Einkommen: sehr viele Konten weisen negative
Vermögensentwilcklung auf

### Verteilung der Konten auf die Kunden[^79]

[^79]: Erstellt von Aaron Studer

Ein Kunde kann mehrere Konten benutzen. Für die Entwicklung von
Kundengruppen ist es wichtig, die bis dahin gewonnenen Erkenntnisse auf
die einzelnen Kunden anzuwenden.

```{r}
# Zählen, wieviele Konten pro Owner registriert sind.
owner_num_accounts <- df_cons %>% 
  select(
    account_id,
    owner_client_id
  ) %>% 
  group_by(owner_client_id) %>% 
  count()

# Ausgeben der Kunden mit den meisten verbundenen Konten
owner_num_accounts %>% 
  arrange(desc(n)) %>% 
  head()

```

Jeder Owner hat nur ein Konto auf sich registriert. Nun wird geschaut,
ob der User mehrere Konten auf sich registriert hat.

```{r}
# Zählen, wieviele Konten pro User registriert sind.
user_num_accounts <- df_cons %>% 
  select(
    account_id,
    user_client_id
  ) %>% 
  group_by(user_client_id) %>% 
  count()

# Ausgeben der Kunden mit den meisten verbundenen Konten
user_num_accounts %>% 
  arrange(desc(n)) %>% 
  head()

```

Auch jeder User hat nur ein Konto zu Mitbenützung. Die NA's sind bei den
Accounts, die nur einen Owner haben aber keinen zusätzlichen User.

Nun stellt sich die Frage, ob es Benutzer gibt, die Owner und User sind.

```{r}
# Überprüfen, ob ein Owner auch bei einem anderen Konto User ist
df_cons %>% 
  filter(owner_client_id %in% user_client_id) %>% 
  nrow()

```

Es gibt keine Owner, welche bei einem anderen Account als User
eingetragen sind. Wie sieht es bei den Usern aus?

```{r}
# Überprüfen, ob ein User auch bei einem anderen Konto Owner ist
df_cons %>% 
  filter(user_client_id %in% owner_client_id) %>% 
  nrow()

rm(owner_num_accounts, user_num_accounts)
```

Es sind auch keine User bei einem anderen Konto als Owner eingetragen.

### Kontoarten[^80]

[^80]: Erstellt von Aaron Studer

Wir haben in vorhergehenden Analysen gesehen, dass es Konten gibt,
welche nicht dem Girokonto zugeordnet werden können. Diese Konten haben
keine häufigen und regelmässigen Transaktionen. Es könnte sich hierbei
um Sparkonten handeln. Diese Konten wollen wir nun genauer anschauen.

#### Sparkonten[^81]

[^81]: Erstellt von Léonie Bécheiraz

Die Sparkonten haben die Eigenschaft, dass sie mit keinen Daueraufträgen
oder Darlehen verbunden sind.

Inspizieren der Konten, welche keine Girokontos sind und daher
Sparkonten sein könnten.

```{r include=FALSE}
# Filtern nach Accounts, welche nicht als Girokonte identifiziert wurden
savings_account <- df_cons %>% 
  filter(is_checking_account == FALSE) 

#Überblick über die relevanten Spalten
savings_account %>% 
  select(-contains(c("id", 
                     "yearly", 
                     "quarterly", 
                     "_num_", 
                     "district", 
                     "user", 
                     "balance",
                     "regular",
                     "salary",
                     "checking"
                     ))) %>% 
  summary()
rm(savings_account)

```

Die meisten Konten wurden um 1996 eröffnet. Für Sparkonto spricht, dass
bis auf ein Konto alle eine positive Vermögensentwicklung aufweisen.
Dagegen spricht aber wieder, dass bei einigen Konten Daueraufträge
eingerichtet oder mit einem Darlehen verbunden sind. Folgehypothese: es
sind einerseits Sparkonten (solche ohne Daueraufträge oder Darlehen) und
die restlichen Darlehenskonten, verbunden mit Daueraufträgen und oder
Darlehen.

#### Spalte Sparkonto (is_savings_account)[^82]

[^82]: Erstellt von Aaron Studer

```{r}
df_cons <- df_cons %>% 
  mutate(is_savings_account = ifelse(is_checking_account == FALSE & is.na(loan_id) & is.na(order_num_household), TRUE, FALSE))

summary(df_cons$is_savings_account)
  
```

#### Spalte Darlehenskonto (is_loan_account)[^83]

[^83]: Erstellt von Aaron Studer

```{r}
df_cons <- df_cons %>% 
  mutate(is_loan_account = ifelse(is_checking_account == FALSE & is_savings_account == FALSE, TRUE, FALSE))

summary(df_cons$is_loan_account)
  
```

#### Vermögensentwicklung bei Konten mit hohem Eikommen[^84]

[^84]: Erstellt von Aaron Studer

```{r}

df_cons %>% 
  filter(salary_groups == "high-income") %>% 
  top_n(3, assets_dev)



```

Die Top 3 Accounts werden von Personen betrieben, welche alle in der
Region Böhmen gemeldet sind. Das Alter der Konto-owner ist von 28 bis 46
jährig.

#### Altesverteilung der Kontoinhaber aufgeteilt auf den Einkommensklassen[^85]

[^85]: Erstellt von Aaron Studer

```{r}
df_cons %>% 
  group_by(
    !is.na(salary_groups)
  ) %>% 
  summarise(owner_age_median = median(owner_age_at_account_opening)) %>% 
  arrange(owner_age_median)

```

Bei den hohen Einkommen ist der Altersdurchschnitt am tiefsten. Dies
widerspricht der allgemeinen Annahme, dass eine Person mit zunehmenden
Alter auch mehr Einkommen hat.

### Bargeldbezüge ohne Angabe des Verwendungszwecks[^86]

[^86]: Erstellt von Aaron Studer

Vorbereiten des Datensatzes.

```{r}

owner_district <- df_cons %>% 
  select(
    account_id,
    owner_district_id,
    account_district_id, 
    owner_district_name,
    owner_district_region,
    account_district_name, 
    account_district_region
  )

# trans_correlation <- date_complete %>% 
#   left_join(owner_district, by = "account_id")

trans_correlation <- df_transaction_complete %>% 
  left_join(owner_district, by = "account_id")

head(owner_district, 3)
head(trans_correlation, 3)
rm(owner_district)

```

#### Varialbelbeschreibung (Levels)[^87]

[^87]: Erstellt von Aaron Studer

Folgende Levels sind vorhanden:

-   "CASH CREDIT" -\> Bargeldeinzahlung
-   "CASH WIDTHDRAWAL" -\> Bargeldbezug
-   "COLLECTION OTHER BANK" -\> Abbuchung einer Fremdbank
-   "CREDIT CARD WITHDRAWAL" -\> Kreditkartenbezug
-   "REMITTANCE OTHER BANK" -\> Überweisung an/von einer Fremdbank

Abfrage der Levels in der Spalte "operation"

```{r}
levels(trans_correlation$operation)

```

Datensatz filtern nach Bargeldbezügen.

```{r}
cashwidthdrawals <- trans_correlation %>% 
  filter(operation == "CASH WIDTHDRAWAL")

rm(trans_correlation)

set.seed(26345)
slice_sample(cashwidthdrawals, n = 5)

```

Die Beträge mit "STATEMENT PAYMENT" aus der Spalte "characterization"
sind Gebühren und werden aus der Analyse ausgeschlossen.

```{r}
cashwidthdrawals <- cashwidthdrawals %>% 
  filter(characterization != "STATEMENT PAYMENT")
  

set.seed(26345)
slice_sample(cashwidthdrawals, n = 5)

```

Ebenso verhält es sich bei "SANCTION INTEREST". Auch diese Beobachtungen
werden ausgeschlossen.

```{r}
cashwidthdrawals <- cashwidthdrawals %>% 
  filter(characterization != "SANCTION INTEREST")

set.seed(26345)
slice_sample(cashwidthdrawals, n = 5)

```

Überblick über die Bargeldbezüge "CASH WIDTHDRAWAL"

```{r}
summary(cashwidthdrawals)

```

Die Bargeldbezüge mit der Bezeichnung "CASH WIDTHDRAWAL" haben alle eine
zugewiesene Verwendung. Entweder für das Wohnen (Household) oder die
Versicherung (Insurrance Payment). Es handelt sich hierbei um 2834
Transaktionen. Dies ist auf den gesamten Datensatz gesehen sehr wenig.
Trotzdem werden diese Zahlungen genauer untersucht.

```{r}
cashwidthdrawals %>% 
  group_by(account_id,
           characterization) %>% 
  mutate(amount = mean(amount)) %>% 
ggplot(aes(x = date, y = amount, color = characterization)) +
  geom_point(position = "jitter") +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Distribution of cash widthrawals") +
  labs(
    color = "Purpose",
    x = "",
    y = "Amount per purchase [CZK]",
    subtitle = "Time span: 1993 - 1998, across all accounts"
    )

```

Die Beträge für Versicherungszwecke sind alle auf einem sehr tiefen
Niveau. Die höheren Beträge (ab 10'000 CZK) werden nun genauer
untersucht.

#### Bargeldbezüge über 10'000 CZK[^88]

[^88]: Erstellt von Léonie Bécheiraz

Anzahl Bezüge mit anteilmässiger Verteilung auf die Regionen.

```{r}
# Filtern auf Beträge über 10k
cashwidthdrawals_10 <- cashwidthdrawals %>%
  filter(amount >= 10000) %>%
  mutate(Region = as.factor(owner_district_region))

#Visualisierung in einer Heatmap
cashwidthdrawals_10 %>% 
  mutate(year = year(date)) %>% 
  group_by(year, Region) %>% 
  summarise(amount = round(mean(amount), digits = 0)) %>%
  ggplot(aes(year, Region, fill = amount)) +
  geom_tile() +
  scale_fill_gradient(
    low = "white", 
    high = "blue") +
  theme(legend.position = "none") +
  labs(
    title = "Cashwithdrawals mean Amount [CZK]",
    subtitle = "Distribution per year and region",
    x = "",
    y = ""
    ) +
  geom_text(aes(label = comma(amount)), size = 3, hjust = 0.5)

rm(cashwidthdrawals, cashwidthdrawals_10)

```

Die hohen Bezüge sind über das ganze Land verteilt. Die Region West
Böhmen weist am häufigsten, Nord und Zentral Böhmen am wenigsten hohe
Bargeldbezüge aus.

#### Das Gebiet Moravia (Mähren)[^89]

[^89]: Erstellt von Léonie Bécheiraz

In der Region Moravia sind einige wichtige Wirtschaftszentren
angesiedelt. Auch die Landwirtschaft spielt eine wichtige Rolle vor
allem der Weinbau. Über 90% der Weinberge befinden sich im Gebiet
Mähren. Das Gebiet verfügt weiter über reichlich Braunkohle und Erdöl.
Auch die Automobil- und die tschechische Feuerwaffenindustrie haben ihre
Produktionsstätten in dieser Region. Das Gebiet um Zlín ist für
Flugzeughersteller bekannt. Mehrere Firmen haben dort ihren Sitz.

### Kreditkarten[^90]

[^90]: Erstellt von Léonie Bécheiraz

Wieviele Accounts haben eine Kreditkarte?

```{r}
df_cons %>% 
  filter(!is.na(card_id)) %>% 
  count()

```

Nur 892 Accounts von gesamthaft 4500 sind mit einer Kreditkarte
verbunden.

```{r}
df_cons %>% 
  ggplot(aes(x = has_creditcard, fill = has_creditcard)) +
  geom_bar() +
  theme_minimal() +
  theme(
    legend.position = "none", 
    axis.text.x = element_text(size = 12),
    plot.title = element_text(size = 15)
  ) +
  labs(
    title = "Num of existing accounts linked to a credit card",
    x = "",
    y = ""
  ) +
  scale_x_discrete(labels = c("FALSE" = "no creditcard",
                              "TRUE" = "with creditcard")) +
  geom_text(stat = 'count', aes(label =..count..), vjust = 3, size = 5)

```

#### Analysen zur Kreditkarte[^91]

[^91]: Erstellt von Léonie Bécheiraz

Wieviele Kreditkarten werden benutzt?

```{r}
# Accounts mit Kreditkarten
cc <- df_cons %>% 
  filter(has_creditcard == TRUE)

# filtern nach Accounts mit Kreditkarten
cc_trans <- df_transaction_complete %>% 
  filter(account_id %in% cc$account_id,
         operation == "CREDIT CARD WITHDRAWAL") %>% 
  group_by(account_id) %>% 
  count() %>% 
  rename(cardwidthdrawals_num = n)

# Ausgabe der Anzahl Accounts
cc_trans %>% 
  nrow()

# Anfügen der neuen Spalte an das df_cons
df_cons <- df_cons %>% 
  left_join(cc_trans, by = "account_id")

```

807 Accounts von 892 benutzen ihre Kreditkarte.

Konten mit Kreditkarte, welche aber die Kreditkarte noch nicht
eingesetzt haben.

```{r}
cc_without_trans <- cc %>% 
  anti_join(cc_trans, by = "account_id")

dim(cc_without_trans)

```

Erster Einsatz der Kreditkarten.

```{r}
foo <- df_cons %>% 
  select(account_id, account_opening_year)

# Erstellen neuer Spalten für die Differenz zwischen Accounteröffnung und erstem Einsatz der Kreditkarte
cc_first <- df_transaction_complete %>%
  left_join(foo, by = "account_id") %>%  
  filter(account_id %in% cc$account_id,
         operation == "CREDIT CARD WITHDRAWAL") %>% 
  group_by(account_id) %>% 
  arrange(date) %>% 
  slice_head(n = 1) %>% 
  mutate(first_trans = year(date)) %>% 
  select(account_id,
         amount, 
         first_trans,
         account_opening_year) %>% 
  mutate(diff_year = first_trans - account_opening_year)

rm(foo)

# Zählen, in welchem Jahr wieviele Kreditkarten das erste Mal eingesetzt wurden.
cc_first %>% 
  group_by(first_trans) %>% 
  count() %>% 
  arrange(desc(n))

# Visualisierung erste Bezüge mit der Karte
cc_first %>% 
  ggplot(aes(first_trans, fill = as.factor(first_trans))) +
  geom_bar()
  
```

An der Verteilung auf die Jahre ist sehr gut zu erkennen, dass die
Kreditkarte immer mehr an Beliebtheit gewonnen hat. Nun ist der richtige
Zeitpunkt gekommen, um die Kreditkarte bei der breiten Masse der
Kundschaft beliebt zu machen.

Wieviele Jahre sind verstrichen nach Kontoeröffnung bis zum ersten
Einsatz der Kreditkarte?

```{r}
cc_first %>% 
  group_by(diff_year) %>% 
  count() %>% 
  arrange(desc(diff_year))

# Entfernen der nicht mehr benötigten Data Frames
rm(cc, cc_first, cc_trans, cc_without_trans)

```

Es sind nicht nur Neukunden, welche eine Kreditkarte besitzen.

Überblick über die Höhe der jeweiligen Bezüge.

```{r}
# nach Kreditkartenbezügen filtern und neue Spalte für Durchschnittsbetrag 
cardwidthdrawals <- df_transaction_complete %>% 
  filter(operation == "CREDIT CARD WITHDRAWAL") %>% 
  group_by(account_id) %>% 
  summarise(cardwidthdrawals_amount_mean = mean(amount))

# neue Info an df_cons anfügen
df_cons <- df_cons %>% 
  left_join(cardwidthdrawals, by = "account_id") 

df_cons %>% 
  select(cardwidthdrawals_amount_mean) %>% 
  summary()

```

Die entstandenen NA's im df_cons sind in der Spalte
"cardwidthdrawals_amount_mean" überall dort entstanden wo keine
Kreditkartenbezüge registriert sind.

Um den Konten, welche zwar mit einer Kreditkarte verbunden sind aber
noch keine Bezüge gemacht haben, werden die NA-Werte durch 0 ersetzt.
Somit weist die Spalte nur noch NA's auf, wenn keine Kreditkarte
verbunden ist.

```{r}
# Filtern der Kreditkartenbezüge für die Imputation mit 0
foo <- df_cons %>% 
  filter(!is.na(card_id),
         is.na(cardwidthdrawals_amount_mean))

# Wert in der neuen Spalte anpassen
df_cons <- df_cons %>% 
  mutate(cardwidthdrawals_amount_mean = ifelse(account_id %in% foo$account_id, 0, cardwidthdrawals_amount_mean)) 

# Übersicht über die Kreditkartenbezüge
df_cons %>% 
  ggplot(aes(cardwidthdrawals_amount_mean, fill = owner_district_region)) +
  geom_boxplot()

df_cons %>% 
  ggplot(aes(cardwidthdrawals_amount_mean, fill = "red")) +
  geom_histogram(binwidth = 25)

rm(foo)  

```

Der durchschnittliche Betrag liegt bei 2200 CZK, der höchste bei 8000
CZK. Der Höchste Betrag ist vermutlich im Zusammenhang mit der
Kreditkartenlimite. In unseren Daten sind gesamthaft 8036
Kreditkartenbezüge verzeichnet. Auch hier werden wiederum die höheren
Bezüge ab einem Betrag von 4'000 CZK genauer untersucht.

```{r}
df_cons %>% 
  filter(cardwidthdrawals_amount_mean  > 4000) %>% 
  # mutate(Region = as.factor(owner_district_region)) %>% 
  ggplot(., aes(x = cardwidthdrawals_amount_mean, fill = "blue")) +
    geom_histogram(binwidth = 25) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 15),
      legend.position = "none"
    ) +
    ggtitle("Creditcard widthrawals") +
  labs(
    x = "Amount per purchase [CZK]",
    y = "count",
    subtitle = "Time span: 1993 - 1998, across all accounts"
    )

```

Die Bezüge über 4000 CZK sind vereinzelt und knapp über 7000 CZK
verteilt.

Verteilung aller Kreditkartenbesitzern auf die Regionen.

```{r}
# Visualisierung Verteilung auf die Regionen
df_cons %>% 
  mutate(Region = as.factor(owner_district_region))%>% 
  filter(!is.na(card_id)) %>% 
  ggplot(., aes(Region, fill = Region)) +
  geom_bar()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 15),
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    ) +
    ggtitle("Creditcard holder per regions") +
  labs(
    x = "",
    subtitle = "Time span: 1993 - 1998"
    )
  
```

Die Kreditkartenbesitzer sind über das ganze Land verteilt. Die Regionen
Moravia und Prag fallen durch die meisten und south Bohemia durch die
wenigsten Besitzer auf.

Verteilung der Kreditkartenbesitzer auf die jeweiligen Regionen, mit
Fokus auf die Bezüge über 4k CZK

```{r}
df_cons %>% 
  mutate(Region = as.factor(owner_district_region))%>% 
  filter(cardwidthdrawals_amount_mean  > 4000) %>% 
  ggplot(., aes(Region, fill = Region)) +
  geom_bar()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 15),
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    ) +
    ggtitle("card holders per region") +
  labs(
    x = "",
    subtitle = "Time span: 1993 - 1998, cardwidthdrawals with amounts over 4k CZK"
    )
  
```

Hier fällt wiederum die Region Moravia mit den meisten hohen
Kreditkartenbezügen auf.

#### Top 3 der höchsten Kreditkartenbezüge[^92]

[^92]: Erstellt von Léonie Bécheiraz

```{r}
df_cons %>% 
  top_n(3, cardwidthdrawals_amount_mean) %>% 
  select(
    owner_dateofbirth,
    owner_sex, 
    owner_district_region,
    cardwidthdrawals_amount_mean,
    card_type,
    
  )

```

Hier fällt auf, dass alle Top 3 die Kreditkarte Gold besitzen.

Verteilung der Kreditkartenbezüge über das Jahr gesehen.

```{r}
df_transaction_complete %>%
  filter(operation == "CREDIT CARD WITHDRAWAL") %>%
  ggplot(mapping = aes(x = date, fill = "green")) +
  geom_histogram(binwidth = 10) + #binwidth = 5
  # facet_wrap(~ operation, ncol = 2, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Distribution of Cardwithdrawals from 1993 to 1999 ", 
       subtitle = "existing clientele",
       x = "Years",
       y = "Count"
       ) +
  scale_x_date(date_labels="%y",date_breaks ="1 year", date_minor_breaks = "1 month") +
  theme(axis.text.x = element_text(size = 8, angle=90,vjust =0.2))

```

Deutlich zu sehen ist hier die Häufung der Verwendung der Kreditkarte
jeweils um den Jahreswechsel. Diese Erkenntnis kann für Angebote im
Zusammenhang mit Kreditkartenzahlungen verwendet werden.

Entfernen der nicht mehr benötigten Data Frames.

```{r}
rm(cardwidthdrawals, cardwidthdrawals_4, cashwidthdrawals, cashwidthdrawals_10, date_complete, trans_correlation, owner_district)

```

### CrossSelling Produkt Kreditkarte[^93]

[^93]: Erstellt von Léonie Bécheiraz

#### Ziel[^94]

[^94]: Erstellt von Léonie Bécheiraz

Wenn ein Kunde bereits ein Girokonto hat aber noch nicht mit einer
Kreditkarte verbunden ist, ein Angebot für die Kreditkarte unterbreiten.
Bei Neueröffnung eines Girokontos die Kreditkarte gleich mitanbieten.

#### Voraussetzung an Konto/Kunde[^95]

[^95]: Erstellt von Léonie Bécheiraz

Das Angebot einer Kreditkarte sollte für den Kunden sowie für die Bank
einen Mehrwert bedeuten. Darum ist es sehr wichtig, die Kriterien,
welche einen "guten" Kreditkartenkunde ausmacht, festzulegen. Die
bestehende Kundschaft wird dann auf diese Kriterien hin geprüft und im
Anschluss können gezielt Angebote an die Kundschaft getragen werden. Für
Neukunden werden diese Beurteilungskriterien soweit als möglich
angewendet.

Kriterien an den Kunden für das Angebot einer Kreditkarte:

Folgende Punkte müssen erfüllt sein:

-   -Kontoart: Girokonto

-   regelmässiges "normales" Einkommen

-   positive Vermögensentwicklung

#### Vermögensentwicklung[^96]

[^96]: Erstellt von Léonie Bécheiraz

Die Vermögensentwicklung darf nicht negativ sein, da ansonsten die
Kredite nicht mehr abbezahlt werden können. Die Spalte mit den
Informationen zur Vermögensentwicklung wurde bereits erstellt.

#### Kundengruppe Kreditkartenangebote[^97]

[^97]: Erstellt von Léonie Bécheiraz

Wir rekapitulieren nochmals die Voraussetzungen für diese Kundengruppe:
Erfüllt müssen sein: - Kontoart: Girokonto - regelmässiges "normales"
Einkommen - Vermögensentwicklung nicht im Minus

Zusammenstellen der Kundengruppe für Kreditkartenangebote

```{r}


# List of customers for credit card offers over 80% average salary
cust_cc_offer_lst_80 <- df_cons %>% 
 filter(
    is_checking_account == TRUE,
    is_regular_income_80 == TRUE,
    assets_dev > 0,
    # assets_dev_groups == "positive",
    has_creditcard == FALSE
  )

foo80 <- nrow(cust_cc_offer_lst_80)


paste(foo80, "Accounts mit einem regelmässigen Einkommen von 80% des ortsüblichen Einkommens erfüllen die Anforderungen für ein Kreditkartenangebot", sep = " ")
rm(foo80)

```

#### Visualisierung der Kundengruppen "Kreditkartenangebot"[^98]

[^98]: Erstellt von Léonie Bécheiraz

Für die Kundengruppe mit mind. 80% ortsübliches Durchschnittseinkommen.

```{r}
# Altersverteilung
plt_age_cc_80 <- cust_cc_offer_lst_80 %>% 
  ggplot(aes(owner_current_age, fill = as.factor(owner_district_region))) +
  geom_boxplot(varwidth = TRUE) +
  scale_fill_viridis_d(alpha = 0.7, option = "A") +
    theme_minimal() +
    theme(
      legend.position = "none",
      axis.text.y = element_blank(),
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Clients age") +
  labs(
    x = "",
    fill = "Region")
```

```{r}
# Verteilung auf die Regionen
plt_region_cc_80 <- cust_cc_offer_lst_80 %>% 
  ggplot(aes(x = owner_district_region, fill = as.factor(owner_district_region))) +
  geom_bar()+
  scale_fill_viridis_d(alpha = 0.9, option = "A") +
    theme_gray() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15),
      axis.text.x = element_text(size = 5),
      axis.ticks.y = element_blank(),
      axis.text.y = element_blank()
    ) +
    ggtitle("Clients per Region") +
  labs(
    x = "",
    y = "",
    fill = "Region"
  ) + 
  scale_x_discrete("Region", labels = c("central Bohemia" = "c. Boh.",
                                        "west Bohemia" = "w. Boh.", 
                                        "east Bohemia" = "e. Boh.",
                                        "north Bohemia" = "n. Boh.",
                                        "Prague" = "Prague",
                                        "south Bohemia" = "s. Boh.",
                                        "north Moravia" = "n. Mor.",
                                        "south Moravia" = "s. Mor."))+
  geom_text(stat = 'count', aes(label =..count..), vjust = -0.3, size = 3) +
  scale_y_continuous(limits = c(0, 600), breaks = 0:600)

```

```{r}
# Einkommenshöhe
plt_income_cc_80 <- cust_cc_offer_lst_80 %>% 
 ggplot(aes(x = income_avg, y = owner_district_region, fill = as.factor(owner_district_region))) +
    geom_density_ridges(alpha=0.6,  stat="binline", bins=20) +
    theme_ridges() +
  scale_fill_viridis_d(alpha = 0.6, option = "A") +
    # theme_minimal() +
    theme(
      legend.position = "none",
      # axis.text.y = element_blank(),
      plot.title = element_text(size = 15),
      axis.text.x = element_text(size = 9),
      axis.text.y = element_text(size = 9),
      plot.subtitle = element_text(size = 9)
    ) +
  labs(
    title = "Clients average salary",
    x = "amount [CZK]",
    y = "",
    subtitle = "per year"
  )

```

```{r}
# Jahr der Kontoeröffung
plt_year_account_cc_80 <- cust_cc_offer_lst_80 %>% 
  ggplot(aes(year(account_opening_date), fill = as.factor(year(account_opening_date)))) +
  geom_bar() +
  scale_fill_viridis_d(alpha = 0.9, option = "H") +
    theme_minimal() +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),
      legend.position = "none",
      plot.title = element_text(size = 15),
      plot.subtitle = element_text(size = 10)
    ) +
    ggtitle("Account opening") +
  labs(
    x = "",
    y = "",
    # fill = "Region",
    subtitle = "Number of openings per year"
  ) +
  geom_text(stat = 'count', aes(label =..count..), vjust = -0.3, size = 3) +
  scale_y_continuous(limits = c(0, 950), breaks = 0:950)
  
```

#### Zusammenfassung der Gruppe "Kreditkartenangebote"[^99]

[^99]: Erstellt von Léonie Bécheiraz

Erstellen eines verschachtelten Plots.

```{r}
# Create multi-panel Plot with patchwork
((plt_year_account_cc_80|plt_region_cc_80)/(plt_income_cc_80|plt_age_cc_80)) +
  plot_annotation(title = "Existing clients for credit card offer [min. 80% salary]", 
                  theme = theme(plot.title = element_text(size = 15))) & theme(plot.title = element_text(hjust = 0.5),
                                                                               plot.subtitle = element_text(hjust = 0.5))
 

```

Entfernen der nicht mehr benötigten Plots aus dem Global Environment

```{r}
rm(plt_age_cc_80, plt_income_cc_80, plt_region_cc_80, plt_year_account_cc_80)

```

#### Art der Kontaktaufnahme mit dieser Kundengruppe[^100]

[^100]: Erstellt von Léonie Bécheiraz

Wir leben in einem Zeitalter, in dem die Kunden gerne persönlich in der
Filiale beraten werden. Diese persönliche Beratung bietet sich vor allem
dann an, wenn der Kunde im selben Distrikt wohnt wie seine Filiale
angesiedelt ist.

Die benötigte Information ist bereits in einer Spalte
"consultation_on_site" enthalten.

```{r}

# Spalten selektieren und Erstellen der Liste für Kunden 80%
cust_cc_offer_lst_80 <- df_cons %>% 
  filter(account_id %in% cust_cc_offer_lst_80$account_id) %>% 
  select(-contains("quarterly"),
         -starts_with("balance_"),
         -contains("yearly"))

# Zählen, wieviel vor Ort beraten werden
cust_cc_offer_lst_80 %>% 
  group_by(consultation_on_site) %>% 
  count()

```

#### Spalte für Gruppe Kreditkartenangebote (is_card_offer)

```{r}
# neue Spalte
df_cons <- df_cons %>% 
  mutate(is_card_offer = ifelse(account_id %in% cust_cc_offer_lst_80$account_id, TRUE, FALSE))

rm(cust_cc_offer_lst_80)

```

#### Resultat / Empfehlung[^101]

[^101]: Erstellt von Léonie Bécheiraz

Für die aquise neuer Kreditkartenkunden unter den bestehenden Kunden
diese persönlich zu einem Beratungsgespräch einladen. (Plot mit
Verteilung Wohnohrt und Filiale) Weiter den bestehenden
Kreditkartenkunden bereits in der Vorweihnachtszeit spezielle Angebote
für den Einsatz der Kreditkarte machen. Dies könnte sein: Spezialrabatte
wenn mit der Kreditkarte bezahlt wird oder Zinsen für einen Monat
aussetzen wenn in diesem Monat ab einem bestimmten Betrag mit der
Kreditkarte bezahlt wird.

### Entscheidungsbaum Kreditkarten[^102]

[^102]: Erstellt von Léonie Bécheiraz

Entscheidungsbaum für Cross Selling Angebote wie in diesem Fall zum
Thema Kreditkarte

```{r}
hascard <- df_cons %>% 
  filter(has_creditcard == TRUE)

nocard <- df_cons %>% 
  filter(has_creditcard == FALSE) %>% 
  slice_sample(n = 892)

df_tree <- hascard %>% 
  bind_rows(nocard)

rm(hascard, nocard)

```

```{r}
# relevante Spalten wählen
df_tree <- df_tree %>% 
  select(
    has_creditcard,
    assets_dev,
    owner_current_age,
    owner_sex, 
    income_avg
    ) %>%
  rename(
    card = has_creditcard,
    assets = assets_dev,
    age = owner_current_age,
    sex = owner_sex,
    income = income_avg,
    ) %>%
  mutate(across(where(is.logical), as.factor)) 

str(df_tree) 

```

Trainingsdatensatz erstellen und partitionieren

```{r}
# zufällig Spalten auswählen für den Traninigsdatensatz

set.seed(42) # Zufallszahlen festlegen
index_train <- sample(x = 1:4500,
               size = trunc(.75 * 4500))

tree_train <- df_tree %>%
filter(row_number() %in% index_train)

tree_test <- df_tree %>%
filter(!row_number() %in% index_train)

rm(index_train) # Das Objekt wieder löschen, da nicht mehr benötigt

head(tree_train)

```

```{r}
dim(tree_test)
# dim(mytree_test)

```

Datenbeschreibung:

-   card = has_creditcard mit den Werten "Yes", "No"

-   assets = assets_dev mit numerischen Werten

-   income = income_avg mit dem durchschnittlichen Einkommen

-   age = owner_current_age mit dem Alter des Kunden am 1.1.1999

-   sex = owner_sex Geschlecht des Kunden

Statistik über das Geschlecht erstellen

```{r}
table(tree_train$sex)

```

Proportionale Verteilung des Geschlechts

```{r}
prop.table(table(tree_train$sex))

```

Einfache Analysen erstellen

```{r}
summary(tree_train$age)

```

```{r}
table(tree_train$card)

```

```{r}
summary(tree_train$assets)

```

```{r}
summary(tree_train$income)

```

#### Modell trainieren[^103]

[^103]: Erstellt von Léonie Bécheiraz

```{r}
set.seed(123)
ct_tree <- rpart(card ~ . , data = tree_train, method = "class", control = rpart.control(cp = 0.003), parms = list(split = "gini"))

```

Modell analysieren

```{r}
ct_tree

```

Mit summary analysieren

```{r include=FALSE}
summary(ct_tree)

```

CP Statistik

Der Cp Wert ist ein Prozessfähigkeitsindex und berechnet das Verhältnis
zwischen der Streuung und der Toleranzbreite eines Prozesses. Der Cp
Wert dividiert den Bereich zwischen dem oberem und unterem Grenzwert des
Prozesses durch die Standardabweichung.

```{r}
printcp(ct_tree)

```

#### Ausdrucken des Cp Wertes[^104]

[^104]: Erstellt von Léonie Bécheiraz

```{r}
# Relativer Fehler der Kreuzvalidierung 
# Obere x-Achse zeigt hier Anzahl Blätter (upper = "size"), alternativ wählbar sind die Anzahl Splits (upper = "splits")
plotcp(ct_tree, upper = "size")

```

Fürs Pruning des Baumes wird versucht, den Wert so zu wählen, dass der
Baum nicht zu gross und nicht zu klein wird. Dazu kann man sich am
"Knick" des Ellbogens (Visualisierung oben) orientieren.

```{r}
rpart.plot(ct_tree)

```

Der gerade gezeigte Baum ist viel zu gross und wird so auch
unübersichtlich.

```{r}
tree_train %>%
count(card) %>%
mutate(prop = n / sum(n))

```

Erstellen eines "geschnittenen" Baumes

```{r}
set.seed(123)
ct_tree_pruned <- rpart(card ~ . , data = tree_train, method = "class", control = rpart.control(cp = 0.0036), parms = list(split = "gini"))
```

Visualisieren

```{r}
plotcp(ct_tree_pruned, upper = "size")
```

Nun ist der Baum viel übersichtlicher und brauchbar.

```{r}
rpart.plot(ct_tree_pruned)

```

Vorhersage des Modells

```{r}
ct_tree_predict_train <- predict(ct_tree_pruned, tree_train, type = "class")

confusion_matrix_train <- table(tree_train$card, ct_tree_predict_train)

accuracy_train <- sum(diag(confusion_matrix_train)) / sum(confusion_matrix_train)

confusion_matrix_train

```

```{r}
accuracy_train

```

Testen des Modells mit Testdaten

```{r}
ct_tree_predict_test <- predict(ct_tree_pruned, tree_test, type = "class")

confusion_matrix_test <- table(tree_test$card, ct_tree_predict_test)

accuracy_test <- sum(diag(confusion_matrix_test)) / sum(confusion_matrix_test)

accuracy_test

```

Mit den Testdaten sinkt die Accuracy von 0.78 auf 0.75.

```{r}
confusion_matrix_test

```

```{r}
rm(tree_train, tree_test)

```

### Cross-Selling Produkt Umkehrhypothek (HELOC)[^105]

[^105]: Erstellt von Léonie Bécheiraz

Eine weitere Möglichkeit für Cross Selling ist die Umkehrhypothek
(HELOC, home equity line of credit). Sie bietet Personen im Rentenalter
mehr finanzielle Flexibilität.

Durch eine erneute Erhöhung oder Neuaufnahme auf das eigene Wohnobjekt
kann der Kunde im Rentenalter Geld flüssig machen um z.B.
Instandhaltungsarbeiten am Wohnobjekt zu finanzieren.

Bedingung ist, dass der Kunde die Liegenschaft selbst bewohnt und sie
bereits abbezahlt ist oder nur noch mit einer geringen Hypothek behaftet
ist.

Die Umkehrhypothek muss erst zurückbezahlt werden, wenn der Kunde ablebt
oder die Liegenschaft verkauft wird.

Leider geben die vorliegenden Daten zu wenig genaue Informationen zu
diesen Voraussetzungen. Trotzdem habe ich versucht, anhand der zugrunde
liegenden Daten gezielt nach Hinweisen zu suchen.

Zum Beispiel habe ich die Informationen der Transaktionen für Household
oder auch die Observationen der Orders mit der Bezeichnung Household
verwendet, um Erkenntnisse über mögliche Hausbesitzer zu erhalten.

#### Annahme[^106]

[^106]: Erstellt von Léonie Bécheiraz

Die Information, wer diese mögliche Liegenschaft effektiv nutzt oder ob
es sich überhaupt um eine Liegenschaft handelt, enzieht sich unserer
Kenntnis. Die folgenden Analysen wurden in der Annahme gemacht, dass es
sich A um Liegenschaften handelt und B diese auch durch die Kunden
selbst genutzt werden.

#### Voraussetzung[^107]

[^107]: Erstellt von Léonie Bécheiraz

-   Kunde muss im Pensionsalter sein
-   Kunde hat bereits Wohneigentum und nutzt dieses auch selbst
-   das Wohneigentum ist abbezahlt oder die Hypthek nur noch sehr gering
-   das Konto darf keine negative Vermögensentwicklung aufweisen
-   der Kunde hat keine weiteren Darlehensverpflichtungen, welche nicht
    beglichen werden könnten

#### Rentenalter[^108]

[^108]: Erstellt von Léonie Bécheiraz

Das Rentenalter tritt ab dem 65 Lebensjahr ein. Dies für beide
Geschlechter gleich.

Erstellen einer neuen Spalte "is_retirement_age" mit dem logischen Wert
TRUE wenn der Kunde im Rentenalter ist.

```{r}
df_cons <- df_cons %>% 
  mutate(is_retirement_age = ifelse(owner_current_age >= 65, TRUE, FALSE))

foo <- df_cons %>% 
  filter(is_retirement_age == TRUE) %>% 
  nrow()

paste("Unter der Kundschaft befinden sich", foo, "Kunden mit Zeichnungsrecht im Rentenalter.")
rm(foo)

```

#### Wohneigentum[^109]

[^109]: Erstellt von Léonie Bécheiraz

Ob ein Kunde Wohneigentum hat, ist aus den vorliegenden Daten nicht
abschliessend festzustellen. Wir können aber annehmen, dass Kunden mit
dem Zahlungshinweis Household oder mit einem Darlehen für Household
Wohneigentum besitzen.

Erstellen einer neuen Spalte "has_res_prop" mit dem logischen Wert TRUE
wenn der Kunde Transaktionen für Household hat.

```{r}
hh_payment <- df_transaction_complete %>% 
  filter(characterization == "HOUSEHOLD",
         cashflow == "OUT") %>% 
  group_by(account_id) %>% 
  slice_head(n = 1)

df_cons_hh <- df_cons %>% 
  filter(!is.na(order_num_household)) %>% 
  mutate(has_res_prop = ifelse(account_id %in% hh_payment$account_id | order_num_household > 0, TRUE, FALSE)) %>% 
  na_replace(has_res_prop, FALSE) %>% 
  select(account_id, has_res_prop)

df_cons <- df_cons %>% 
  left_join(df_cons_hh) 

df_cons <- df_cons %>% 
  mutate(isNA = is.na(has_res_prop))

df_cons <- df_cons %>% 
  mutate(has_res_prop = ifelse(isNA == FALSE, has_res_prop, FALSE))
  
  
df_cons %>% 
  filter(is.na(has_res_prop)) %>% 
  nrow()

df_cons %>% 
  filter(has_res_prop == TRUE) %>% 
  nrow()

df_cons_hh %>% 
  filter(has_res_prop == TRUE) %>% 
  nrow()

df_cons <- df_cons %>% 
  select(-isNA)

rm(hh_payment, df_cons_hh)
  
```

#### Liste Kunden für Angebot der Umkehrhypothek[^110]

[^110]: Erstellt von Léonie Bécheiraz

Home Equity Line of Credit

Filtern nach den Voraussetzungen

-   Kunde muss im Pensionsalter sein
-   Kunde hat bereits Wohneigentum und nutzt dieses auch selbst
-   das Wohneigentum ist abbezahlt oder die Hypthek nur noch sehr gering
-   das Konto darf keine negative Vermögensentwicklung aufweisen
-   der Kunde hat keine weiteren Darlehensverpflichtungen, welche nicht
    beglichen werden könnten

```{r}
heloc_cust_list <- df_cons %>% 
  filter(
    is_retirement_age == TRUE, 
    has_res_prop == TRUE,
    loan_in_dept == FALSE | is.na(loan_in_dept),
    assets_dev_groups == "positive"
    )

foo <- heloc_cust_list %>% 
  nrow()

heloc_cust_list %>% 
  group_by(consultation_on_site) %>% 
  count()
```

#### Spalte Angebot Umkehrhypothek (heloc_offer)[^111]

[^111]: Erstellt von Léonie Bécheiraz

```{r}
# Spalte für Angebot Umkehrhypothek
df_cons <- df_cons %>% 
  mutate(heloc_offer = ifelse(account_id %in% heloc_cust_list$account_id, TRUE, FALSE))

```

```{r}
paste("Für das Angebot der Umkehrhypothek kommen", foo, "Kunden in Frage. Alle Kunden können persönlich vor Ort beraten werden.")

rm(heloc_cust_list)
rm(foo)

```

#### Weitere Cross-Selling Produkte[^112]

[^112]: Erstellt von Léonie Bécheiraz

Weitere Cross-Selling Produkte könnten sein: Darlehens- und
Leasingsangebote, Versicherungsangebote, Anlagepakete (Aktien,
Obligationen), Devisenhandel

#### Client Analytical Record[^113]

[^113]: Erstellt von Léonie Bécheiraz

Das Data Frame df_cons wurde während der verschiedenen Analysen immer
wieder mit relevanten Daten angereichert, somit sollte es als Client
Analytical Record dienen.

## Weitereführende Analysen

### Analyse von Kundenattributen

Wann hat die Bank neue Kunden gewonnen und wie sieht diese Verteilung
über die Zeit aus?[^114]

[^114]: Erstellt von Christian Heeb

##### Gesamtübersicht dern neu eröffneten Konten in den letzten Jahren

```{r}
ggplot(data = df_cons, aes(x = account_opening_date)) +
    geom_histogram(binwidth = 20, stat = "bin", fill = "#CD950C") +
    labs(title = "Opening of new bank Accounts", 
           subtitle = "From the Year 1993 to 1998 ", 
           caption = "Source: PKDD’99 Discovery Challenge",
           x = "Year", y = "Number of openings") +
    theme(legend.position = "none", axis.text.x = element_text(size = 6, angle = 60, vjust = 0.5)) +
    scale_x_date(breaks = scales::breaks_pretty(10))

```

Das Histogramm zeigt die Jährliche Übersicht der neu gewonnenen Kunden in den Jahren 1993 bis 1998


#### Detaillierten Jahresansicht

```{r}
# account_opening_date nach Jahr sortieren
df_cons %>%
      ggplot(df_cons, mapping = aes(as.Date(account_opening_date), fill = as.factor(account_opening_year))) +
      geom_histogram() +
      facet_wrap(~ account_opening_year, ncol = 3, scales = "free_x") +
      coord_cartesian(ylim = c(0, 80)) +
      theme(legend.position = "none") +
      labs(title = "Opening of new bank Accounts", 
           subtitle = "Subdivided by Year", 
           caption = "Source: PKDD’99 Discovery Challenge",
           x = "", y = "Number of openings") +
      theme(axis.text.x = element_text(size = 6, angle = 60, vjust = 0.5)) +
      scale_x_date(breaks = scales::breaks_pretty(10))

```

Detaillierte Überischt der Neukunden unterteilt nach Jahren.


#### Altersverteilung der Kunden[^115]

[^115]: Erstellt von Christian Heeb

```{r}
# Calculate age of Customers with Lubridate
# to keep a reasonable age of the cusomers, we calculated their age as of the following date: 31.12.1999
df_cons$age_dec1999 <- trunc((df_cons$owner_dateofbirth %--% "1999-12-31") / years(1))

#Relocate rows so new column "current_age" is next to dateofbirth
df_cons <- df_cons %>%
   relocate(age_dec1999, .after = owner_dateofbirth)
 
 
#Create Barplot with distrbution of age 
df_cons %>%
   group_by(account_id) %>%
   filter(row_number() == 1)

   ggplot(data = df_cons, aes(age_dec1999)) +
   geom_bar(fill = "#88B8AC") +
   labs(title = "Distribution of Customer Age as of 31. Dec 1999", 
        subtitle = "Male and Female combined",
        caption = "Source: PKDD’99 Discovery Challenge",
        x ="Age in Years",
        y = "Number of Customers") +
   scale_x_continuous(breaks = scales::breaks_pretty(10))
 
```

Der Barplot zeigt die die Verteilung der Kundenalters. Da eine Darstellung mit dem Kundenalter im Jahr 2023 nur bedingt aussagekräftig wäre, wurde als Stichtag der 31.12.1999 definiert. 


#### Altersverteilung beim eröffnen des Kontos

```{r}
   ggplot(data = df_cons, aes(owner_age_at_account_opening)) +
   geom_bar(fill = "#88B8AC") +
   labs(title = "Age of Customer at opening of Account ", 
        subtitle = "Male and Female combined",
        caption = "Source: PKDD’99 Discovery Challenge",
        x ="Age in Years",
        y = "Number of Customers") +
   scale_x_continuous(breaks = scales::breaks_pretty(10))
```

Der Barplot zeigt die die Verteilung der Kundenalters beim eröffnen des Kontos.


#### Verteilung der Kreditkartentypen [^116]

[^116]: Erstellt von Aaron Studer

```{r}

# Preparation for the visualization of the distribution of credit cards by the credit card type and the sex of the customer.
df_credit_card_by_type <- df_cons %>%
  filter(!is.na(card_id)) %>%
  select(card_type, owner_sex) %>%
  # group_by to get the count of each credit card by type and sex of the customer.
  group_by(owner_sex, card_type) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  #Prepare the frequency as a character to display the exact information in the graph.
  mutate(prop = paste0((round(freq, 3))," %")) %>%
  ungroup()

df_credit_card_by_type

#Display of the distribution of the credit cards by type and sex.
ggplot(df_credit_card_by_type, aes(fill = card_type, x = owner_sex, y = n)) +
  labs(title = "Distribution of Credit Card Type per Sex", subtitle = "The percentage displayed on the plot is the frequency of the type over the whole population.") +
  geom_col(position = "stack") + 
  geom_text(aes(label = prop), position = position_stack(vjust = 0.5)) +
  xlab("Sex") +
  ylab("Count") +
  labs(fill = "Card Type")

#Cleanup data frame.
rm(df_credit_card_by_type)

```
 In dieser Grafik sehen wir die relative Verteilung von Kreditkarten typen gruppiert nach den Geschlechtern. Dabei sehen wir das die grösste Menge der Kunden eine Kreditkarte vom Type 'Classic' haben. Wenn man genauer die Unterschiede zwischen den beiden Geschlechtern anschaut, sieht man, dass ein grössere Anteil der Männlichen Kundschaft eine Kreditkarte mit dem Typ 'Gold' besitzen. Jedoch gleicht sich das ganze aus, da die Weibliche Kundschaft einen grösseren relativen Anteil an Kreditkarten vom Type 'Junior' und 'Classic' haben. Wenn man die beiden Balken vergleicht wird festgestellt, dass mehr männliche Kunden einen Kreditkarte besitzen.

#### Clustering des Einkommens und der Ausgaben[^117]

[^117]: Erstellt von Aaron Studer

```{r}

df_cons_metrics <- df_cons %>%
  dplyr::select(starts_with(c("income", "outgoes")))

str(df_cons_metrics)

# Scale the data down
df_cons_metrics_scaled <- scale(df_cons_metrics)

# K-Means Clustering (Example with K = 20)
fitK <- kmeans(df_cons_metrics_scaled, 20)

str(fitK)
cluster_metrics <- plot(df_cons_metrics_scaled, col = fitK$cluster)

# let's find out the best value for k in the kmean function
k <- list()
for(i in 1:30){
  k[[i]] <- kmeans(df_cons_metrics_scaled, i)
}

# Calculate the squares in the clusters which will later be used to define the best value for k.
betweenss_totss <- list()
for(i in 1:30){
  betweenss_totss[[i]] <- k[[i]]$betweenss/k[[i]]$totss
}

# Display the calculated values that can be used to define a optimial value for k.
cluster_overview <- plot(1:30, betweenss_totss, type = "b",
     ylab = "Between SS / Total SS", xlab = "Clusters (k)")


```

Nach dem Graph sollten wir nun entweder nach der Elbow- oder
Silhouette-Methode definieren mit wie vielen Cluster, dass wir arbeiten
werden. Nach der Elbow-Methode habe wir Potenzial für k = 8, k = 15 und
k = 25. Wir bauen die Cluster Analyse nun mit 15 Clusters für eine
mittelmässig granulare Lösung.

Source
(<https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb>)

```{r}

#Distribution of the data points for the three custers with the different k-values. The data points are coloured by the cluster number.
for (i in c(8, 15, 25)){
  distributed_clusters_with_coloring <- plot(df_cons_metrics_scaled, col = k[[i]]$cluster)
  
  distributed_clusters_with_coloring
}

# Display of the cluster (k=8). with autoplot
fitK <- kmeans(df_cons_metrics_scaled, 8)
autoplot(fitK, df_cons_metrics_scaled, frame=TRUE)

#Display the centers of the clusters.
fitK$centers

# Display of the cluster (k=15). with autoplot
fitK <- kmeans(df_cons_metrics_scaled, 15)
autoplot(fitK, df_cons_metrics_scaled, frame=TRUE)

# Display of the cluster (k=25). with autoplot
fitK <- kmeans(df_cons_metrics_scaled, 25)
autoplot(fitK, df_cons_metrics_scaled, frame=TRUE)



```
Für die Cluster Analyse müssen wir die Clusters Vergleichen von verschiedenen k-Werten. Dazu haben wir die drei Werte 8, 15 und 25 benutzt. Die genauen Graphen sind nachfolgend aufgelistet:
1. Der Plot wurde dargestellt um die verschiedene Datenpunkte im Cluster darzustellen die Punkte sind nach den zugewiesen Cluster eingefärbt. Es wird mit einem k-Wert von 8 gearbeitet.
2. Der Plot wurde dargestellt um die verschiedene Datenpunkte im Cluster darzustellen die Punkte sind nach den zugewiesen Cluster eingefärbt. Es wird mit einem k-Wert von 15 gearbeitet.
3. Der Plot wurde dargestellt um die verschiedene Datenpunkte im Cluster darzustellen die Punkte sind nach den zugewiesen Cluster eingefärbt. Es wird mit einem k-Wert von 25 gearbeitet.

Nach der Analyse werden die Clusters mithilfe von Autplot visuell noch weiter dargestellt.

4. Der Autplot zeigt die verschiedene Cluster 2 dimensional an und bildet eine Areal um die einzelnen Datenpunkte von einem Cluster. Diese Clusteriung wurde mit 8 Clustern aufgebaut.
5. Der Autplot zeigt die verschiedene Cluster 2 dimensional an und bildet eine Areal um die einzelnen Datenpunkte von einem Cluster. Diese Clusteriung wurde mit 15 Clustern aufgebaut.
6. Der Autplot zeigt die verschiedene Cluster 2 dimensional an und bildet eine Areal um die einzelnen Datenpunkte von einem Cluster. Diese Clusteriung wurde mit 25 Clustern aufgebaut.

Wir sehen klar das die Datenpunkte in den Clusters überlappend sind, daher kann man erkenne, dass die Funktion mit kmeans Probleme hat bei der Bildung von Clusters oder das die Daten in einer Komplexität herkommen, wodurch sie von dem Algoritmus nicht korrekt zugewiesen werden können.

Clustering with the yearly income avg and outcome avg of the customer

```{r}

#Select the income and outgoes for the clustering
df_cons_metrics <- df_cons %>%
  dplyr::select(starts_with(c("income_avg", "outgoes_avg")))

str(df_cons_metrics)

#Scale the metrics down for smaller margins between the data points.
df_cons_metrics_scaled <- scale(df_cons_metrics)

# K-Means Clustering (Example with K = 10)
fitK <- kmeans(df_cons_metrics_scaled, 10)

str(fitK)
cluster_metrics <- plot(df_cons_metrics_scaled, col = fitK$cluster)

# let's find out the best value for k in the kmean function
k <- list()
for(i in 1:30){
  k[[i]] <- kmeans(df_cons_metrics_scaled, i)
}

betweenss_totss <- list()
for(i in 1:30){
  betweenss_totss[[i]] <- k[[i]]$betweenss/k[[i]]$totss
}

cluster_overview <- plot(1:30, betweenss_totss, type = "b",
     ylab = "Between SS / Total SS", xlab = "Clusters (k) for avg income/outgoes")

autoplot(fitK, df_cons_metrics_scaled, frame=TRUE)

fitK$centers

```
Wir sehen hier eine weiteres Clustering Verfahren, dabei versuchen wir Clusters aufzubauen nur mit den jährlichen Einkommen und Ausgaben von Kunden. Der Scatter-plot zeigt eine saubere Auftrennung der Datenpunkte in den verschiedenen CLusters.

Für die Bestimmung der Clusters wird wieder die Elbow-Methode gebraucht in dem zweiten Graphen sind man dazu zwei Möglichkeiten nämlich mit dem Wert K = 5 und K = 10.

In dem dritten Graphen sieht man eine klare, aber eng beieinandere Verteilung der Datenpunkte in den einzelnen Cluster. Die Clusters könnten nun weiterhin gebraucht werden für eine Analyse der einzelnen Datenpunkte (Kunden) in den Clusters. Man kann weitere Angebote analysieren, die diese Kunden brauchen und den Kunden empfehlen, die sich in dem selben Cluster befinden, die jedoch dieses Produkt noch nicht brauchen.

#### Beliebtester Modus einer Transaktion?[^118]

[^118]: Erstellt von Aaron Studer

```{r}
# df_transaction_type_count <- df_transaction_complete %>%
#   filter(!is.na(trans_id)) %>%
#   group_by(characterization, quarter) %>%
#   mutate(count = sum(n())) %>%
#   select(count, characterization, quarter) %>%
#   distinct()

#Load the data frame 'df_transaction_complete' for the following visualization.
save(df_transaction_complete, file = "df_transaction_complete.RData")
load("df_transaction_complete.RData")

#add the quarter attribute to generate a overview by the quarters in each year.
df_transaction_complete <- df_transaction_complete %>% 
  mutate(quarter = quarter(date, type = "year.quarter"))

# Filter empty transaction, group the data frame by the charachterization and the quarter to get the count of each transaction type in each quarter. 
df_transaction_type_count <- df_transaction_complete %>%
  filter(!is.na(trans_id)) %>%
  group_by(characterization, quarter) %>%
  mutate(count = sum(n())) %>%
  select(count, characterization, quarter) %>%
  distinct()

df_transaction_type_count

#Display of the transaction type data
ggplot(df_transaction_type_count, aes(fill = characterization, x = quarter, y = count)) +
  labs(title = "Distribution of transaction types per quarters (1993 Q1 - 1998 Q4)", subtitle = "") +
  geom_bar(position="stack", stat="identity") +
  # geom_text(aes(label = frequency), position = position_stack(vjust = 0.5), size = 2) +
  xlab("Quarter") +
  ylab("Count") +
  labs(fill = "Transaction Type") +
  facet_wrap(vars(characterization), ncol = 1)

```
Wir sehen in dieser Visualisierung die Entwicklung der Transaktionen bezogene auf die Zeit (Nach den Quartalen). Über alle Typen sehen wir einen ganz klaren Anstieg der Transaktionen, dass kann durch den Zuwachs neuer Kundschaft enstanden sein. Desweiteren sehen wir das die meisten Transaktionen den Typ 'NA' aufweisen. Dieses Verhalten liegt sehr wahrscheinlich davon ab, dass der Typ von der Transaktion nur bei grösseren Transaktionen aufgenommen wurde oder bei der Ausführung der Transaktion am Schalter. Da die definierten Typen 'Credit Interest', 'Houhsehold' und 'Statement Payment' am meisten gebraucht wurden. Könnte man neue Angebote entwickeln die genau Vorteile bei diesen Transaktionstypen aufweisen.

### Kartografische Darstellung von Analysen

#### Verteilung der Kundschaft auf die Distrikte in Tschechien.[^119]

[^119]: Erstellt von Aaron Studer

Vorbereitung der externen geografischen Daten für die Visualisierung in
einer Kartenansicht.[^120]

[^120]: Erstellt von Aaron Studer

```{r}
# 
#Preparation of the geographical data of the RCzechia package.
geographical_data <- RCzechia::okresy("low")

# Analysis of the structure of the imported geographical data frame.
str(geographical_data)

# load("df_district_mod.RData")

# str(df_district_mod)
# 
# df_district_mod <- df_district_mod %>% mutate(
#   district_name = as.character(district_name),
#   district_name = ifelse(district_name == "Hl.m. Praha", "Praha", district_name)
#   )
# 
# df_district_mod <- df_district_mod %>%
#   arrange(district_name)
# 
# geographical_data <- geographical_data %>%
#   arrange(NAZ_LAU1)

str(df_cons$account_district_name)

# The data frame have different values for the district Praha therefore we will change the value in the consolidated data frame from 'H1.m. Praha' to 'Praha'. After the mutation we arrange the data frame by the district name, which will later be used to bind the values.
df_district_mod <- df_cons %>% mutate(
  district_name = as.character(account_district_name),
  district_name = ifelse(district_name == "Hl.m. Praha", "Praha", district_name)
  ) %>%
  arrange(district_name)

#Arrange the data frame to bind it easier in later steps.
geographical_data <- geographical_data %>%
  arrange(NAZ_LAU1)


```

Mithilfe des Data Frames 'geographical_data' wird uns in den folgenden R-Snippets ermöglicht Informationen zu den Distrikten in einer Heatmap darzustellen bei der das ganze Land untertrennt durch die Staaten dargestellt wird.

#### Anzahl der Kunden in den einzelnen Distrikten.[^121]

[^121]: Erstellt von Aaron Studer

```{r}
# Preparation of the data frame that will be used to display the count of customers in each district
df_customers_per_district <- df_district_mod %>%
  group_by(district_name) %>%
  mutate(count = sum(n())) %>%
  select(district_name, count) %>%
  distinct()

df_customers_per_district

# df_customers_per_district <- df_customers_per_district %>% mutate(
#     district_name = as.character(account_district_name),
#     district_name = ifelse(account_district_name == "Hl.m. Praha", "Praha", district_name)
#   ) %>%
#   arrange(account_district_name)

#add the native original name to the metric data frame.
df_customers_per_district <- cbind(df_customers_per_district, original_district_name = geographical_data$NAZ_LAU1) %>%
  select(district_name, original_district_name, count)

# We bind the geometry information from the data frame geographical_data with our metric data frame.
df_customers_per_district_incl_geo_data <- left_join(df_customers_per_district, geographical_data, by = c("original_district_name" = "NAZ_LAU1"))

ggplot(data = df_customers_per_district_incl_geo_data) +
  geom_sf(aes(fill = count, geometry = geometry), colour = NA) +
  geom_sf(data = republika("low"), color = "gray30", fill = NA) +
  scale_fill_viridis_c(trans = "log", labels = scales::comma) +
  labs(title = "Distribution of customer location in the districts",
       fill = "Customers") +
  theme(legend.text.align = 1,
        legend.title.align = 0.5)



```
Wir sehen in dieser Heatmap die Verteilung von Kunden in den einzelnen Distrikten. Wir haben das Land mithilfe der Geometry Formeln des Packages 'RCzechia' erstellt. Wir sehen das die meisten Kunden sich in dem Staat 'Hl.m. Praha' befinden. Eine grössere Dichte besteht auch im Osten des Landes. Aus dem Graph können wir ableiten, in welchen Staaten es sich lohnt die bereits vorhandenen Kundschaft weiter auszubauen, da die Infrastruktur schon besteht.

#### Durchschnittslohn in den verschiedenen Distrikten[^122]

[^122]: Erstellt von Aaron Studer

```{r}

# df_district_mod_names <- cbind(df_district_mod, original_name = geographical_data$NAZ_LAU1) %>%
#   select(account_district_name, original_name, account_district_average_salary)

# Prepare the data frame with the average_salary and the name of the district.
df_district_mod_names <- df_district_mod %>%
  select(account_district_name, account_district_average_salary) %>%
  distinct() %>%
  cbind(original_name = geographical_data$NAZ_LAU1)

# Join the prepared data frame by the native original district name with the data frame from RCzechia.
df_average_salary_per_district_including_geo_data <- left_join(df_district_mod_names, geographical_data, by = c("original_name" = "NAZ_LAU1"))

ggplot_average_salary_per_district <- ggplot(data = df_average_salary_per_district_including_geo_data) +
  geom_sf(aes(fill = account_district_average_salary, geometry= geometry), colour = NA) +
  geom_sf(data = republika("low"), color = "gray30", fill = NA) +
  scale_fill_viridis_c(trans = "log", labels = scales::comma) +
  labs(title = "Average Salary per District",
       fill = "Average Salary (CZK)") +
  theme(legend.text.align = 1,
        legend.title.align = 0.5)

```

Average Salary berechnet durch die von Kunden getätigten
Transaktionen in den verschiedenen Distrikten[^123]

[^123]: Erstellt von Aaron Studer

```{r}

# Join the two data frames to add the district name to the transactions
df_transaction_complete_with_district_information <- left_join(df_transaction_complete, df_cons %>% select(account_id, account_district_name), by = "account_id")

# Prepare the data frame with the data that will be displayed by grouping it by the district name and rounding the values.
incomes_average_overall_with_district_information <- df_transaction_complete_with_district_information %>%
  filter(incomes != 0) %>%
  group_by(
    account_district_name
  ) %>%
  summarise(incomes_avg = round(mean(incomes), digits = 0)) %>% 
  ungroup()

#add the native original name to the prepared dataframe to add the geometry data from RCzechia package which has already been prepared in a previous chunk.
df_transaction_complete_with_district_information <- left_join(incomes_average_overall_with_district_information, df_district_mod_names %>% select(account_district_name, original_name), by = "account_district_name")

#Join the map data frame with the prepared transaction data frame by using the native district name.
df_average_income_per_district_including_geo_data <- left_join(df_transaction_complete_with_district_information, geographical_data, by = c("original_name" = "NAZ_LAU1"))

ggplot_average_income_calculated <- ggplot(data = df_average_income_per_district_including_geo_data) +
  geom_sf(aes(fill = incomes_avg, geometry= geometry), colour = NA) +
  geom_sf(data = republika("low"), color = "gray30", fill = NA) +
  scale_fill_viridis_c(trans = "log", labels = scales::comma) +
  labs(title = "Average Income calulcated from transactions per District",
       fill = "Average Income (CZK)") +
  theme(legend.text.align = 1,
        legend.title.align = 0.5)

```


#### Vergleich Average Einkommen von den Distrikten und dem
Durchschnittlichen Einkommen der Kunden:


```{r}

# Create a nested plot to see the comparison between the heatmaps created from the customer transactions and the average salary from the district.
nested_income_and_salary_plot <- (ggplot_average_income_calculated/ggplot_average_salary_per_district)

nested_income_and_salary_plot

```

In den beiden Graphen sieht man beim ersten Blick klar, das sich die
beiden Fill-Attribute (Average Salary und Average Income) verschiedene
Skalen brauchen, dies kann zuerst ein bisschen täuschend erscheinen. Das
Average Income der Kunden der Bank liegt deutlich tiefer als das
allgmeine durschnittliche Einkommen (Average Salary) in den Distrikten.
Dies kann von folgenden Gründen abhängig sein: - Ein Kunde kann sein
Konto weiterhin erstellt haben, aber auch nach einem Datum x ein neues
Lohnkonto bei einer weiteren Bank eröffnen. - Die Kunden kommen aus den
tieferverdienenden Segmenten.


Aufräumen nach der Darstellungen in der Kartenübersicht

```{r}


# save(df_district_mod_names, file = "df_district_mod_names.RData")
rm(df_district_mod_names, df_transaction_complete_with_district_information, incomes_average_overall_with_district_information, df_transaction_complete_with_district_information, df_average_income_per_district_including_geo_data)

```

xi\. Können neue Sonderangebote/Pakete geschaffen werden für die am
meist verdienenden Kunden?[^124]

[^124]: Erstellt von Aaron Studer

Wie beim Density-Plot (Verteilung) kommt deutlich zum Ausdruck, dass die
meisten Konten Einkommen bis 320'000 CZK aufweisen. Die
Einkommensentwicklung ist nicht so leicht zu erkennen. Ein geringer
Anstieg über die beobachteten fünf Jahre lässt sich ausmachen mit
Ausnahme des Jahres 1996. Für die nächste Analyse werden alle Accounts
genommen, die ein Einkommen von mehr als 320'000 CZK haben.

Wir greifen hier auf die bereits vorhanden Analyse zu von Leonie.

```{r}

str(df_cons %>% select(!starts_with("balance")) %>% select(!starts_with("incomes_quarterly")) %>% select(!starts_with("outgoes_quarterly")))

account_ids_incomes_over_320K <- df_cons %>%
  filter(income_avg > 320000) %>%
  distinct()

str(account_ids_incomes_over_320K)

frequency_card_type_accounts_over_320K <- account_ids_incomes_over_320K %>%
  group_by(card_type) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n))

frequency_card_type_accounts_over_320K

```
Mithilfer der Häufigkeitstabelle erhalten wir eine klare Übersicht über die Verteilung der Kreditkarten Typen von den Grossverdienern. Wir sehene das ca. 29.46% der Kunden eine Kreditkarte vom Type 'Classic' besitzen und das ca. 60% der Kunden in diesem Segment keine Kreditkarten von dieser Bank besitzen. Daher kann nun ein Angebot erstellt werden, das zusammen mit der Aktivierung einer Kreditkarte eingelöst werden kann. Dadurch können weitere Kunden angezogen werden und auch die Kunden in diesem Segmente könnten sich entscheiden eine Kreditkarte zu beantragen.



### Korrelationen zwischen Datenattributen:

#### Wahrscheinlichkeit dass ein Kunden seinen Kredit zurückbezahlen wird

Ziel dieses Abschnittes ist es, Prognosen für die Bank zu erarbeiten, um festzustellen, ob Kunden ihre
Kredite zurückzahlen können. Die Kreditwürdigkeit des Kunden kann
mithilfe der Analyse festgestellt werden und bei bereits laufenden
Krediten können Massnahmen getroffen werden.[^125]

[^125]: Erstellt von Christian Heeb

```{r}
df_cons %>%
  drop_na(loan_status) %>%
  group_by(loan_status) %>%
  ggplot(aes(x = reorder(loan_status, loan_status,
                         function(x)-length(x)),
                         fill = loan_status)) +
  geom_bar() +
  theme(legend.position = "none") +
  labs(title = "Number and Status of Loans", 
        subtitle = "", 
        caption = "Source: PKDD’99 Discovery Challenge",
        x = "", y = "Number of loans",
        fill = paste("Loan status")) +
  coord_flip()
```

Das Balkendiagramm zeigt die Anzahl der gewährten Kredite inklusive
deren Status. Daraus wird ersichtlich, dass der grösste Teil der Kunden ihren Kredit bereits erfolgreich zurückzahlen wird, oder ihn bereits zurückbezahlt hat.

```{r message=FALSE}
# Preparation of Plots

# Calculate customer age at getting loan
df_cons$age_at_loan <- trunc((df_cons$owner_dateofbirth %--% df_cons$loan_start_date) / years(1))

#Relocate rows so new column "age_at_loan" is next to owner_dateofbirth
df_cons <- df_cons %>%
   relocate(age_at_loan, .after = card_issued)

# Divide yearly income column with yearly loan column
df_cons$loan_per_year <- df_cons$loan_total_amount / df_cons$loan_duration_in_years
df_cons <- df_cons %>%
   relocate(loan_per_year, .after = loan_redemption_amount)

df_cons$ratio_loan_to_sallary <-df_cons$income_avg / df_cons$loan_per_year  
df_cons <- df_cons %>%
   relocate(ratio_loan_to_sallary, .after = income_avg)



# Create Plots
loanplot1 <- df_cons %>%
  drop_na(loan_status) %>%
  ggplot(df_cons, mapping = aes(x = loan_duration_in_month, y = loan_status, fill = loan_status)) +
  geom_boxplot() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Loan Duration in Months", 
           subtitle = "", 
           caption = "",
           y = "", x = "Months") +
  coord_flip()


loanplot2 <- df_cons %>%
  drop_na(loan_status) %>%
  ggplot(df_cons, mapping = aes(x = loan_total_amount, y = loan_status, fill = loan_status)) +
  geom_boxplot() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  scale_x_continuous(breaks = scales::breaks_pretty(10)) +
  labs(title = "Loan total amount", 
           subtitle = "", 
           caption = "",
           y = "", x = "Loan in CZK") +
  coord_flip()


loanplot3 <- df_cons %>%
  drop_na(loan_status) %>%
  ggplot(df_cons, mapping = aes(x = age_at_loan, y = loan_status, fill = loan_status)) +
  geom_boxplot() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Customer Age at beginning of Loan", 
           subtitle = "", 
           caption = "",
           y = "", x = "Years") +
  coord_flip()


loanplot4 <- df_cons %>%
  drop_na(loan_status) %>%
  ggplot(df_cons, mapping = aes(x = ratio_loan_to_sallary, y = loan_status, fill = loan_status)) +
  geom_boxplot() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Ratio Salary to Loan", 
           subtitle = "Average annual salary divided by annual loan charge", 
           caption = "Source: PKDD’99 Discovery Challenge",
           y = "", x = "Ratio") +
  coord_flip()


loanplot5 <- df_cons %>%
  drop_na(loan_status) %>%
  ggplot(df_cons, mapping = aes(x = loan_start_date, y = loan_total_amount, color = loan_status)) +
  geom_point(size = 0.7) +
  geom_smooth(method="lm", se = FALSE, size = 0.6) +
  scale_y_continuous(breaks = scales::breaks_pretty(10)) +
  scale_x_date(breaks = scales::breaks_pretty(6)) +
  labs(title = "Loans granted throughout the Years", 
           subtitle = "", 
           caption = "",
           y = "Amount of Loan", x = "Years",
           color = "Status of loan") +
  theme(plot.background = element_rect(colour = "black", fill=NA, size=0.5)) 


# Create multi-panel Plot with patchwork
nested_loan_plot <- (loanplot5/(loanplot1|loanplot2|loanplot3|loanplot4)) 
nested_loan_plot


```

Die Abbildung oben zeigt fünf verschiedene Plots, welche alle
Zusammenhänge im Kreditstatus der Kunden aufzeigen. Ziel ist es daraus
Erkenntnisse zu gewinnen, um festzustellen welches die Gründe sind,
damit jemand seinen Kredit nicht zurückbezahlten kann. Der Scatterplot
zeigt auf wie sich die höhen der einzelnen Kredite in den Jahren 1993
bis 1999 verändert hat. Zusätzlich wird farblich der jeweilige Status
des Kredites hervorgehoben.

Die Boxplots in der unteren Reihe stellen den Kreditstatus gegenüber
verschiedenen Attributen dar. Dabei sind in den Boxplots 1 -3 keine
Besonderheiten bezüglich des Kreditstatus gegenüber den jeweiligen
Attributen festzustellen. Einzig in Plot 4 ("Ratio Salary to Loan")
sieht man, dass das Verhältnis von Kredit zu durchschnittlichem
Jahreseinkommen bei den unbezahlten ("Contract Finished unpaid") und den
Krediten, welche im Verzug sind ("Contract open indept") tiefer ist.
Dies bedeutet, dass die Kreditsumme einen höheren Anteil des jeweiligen
Jahreseinkommens ausmacht und somit auch schneller zu einer Belastung
wird, was ein Grund für das nicht- oder zu spät bezahlen der Kredite
sein könnte.



#### Erstellen von Decision Tree und Random Forest Modellen zur Vorhersage
der Kreditwürdigkeit[^126]

[^126]: Erstellt von Christian Heeb


Für einen einfacheren Umgang mit den Daten wird eine Kopie des
Originalen Datensatzes mit allen relevanten Attributen erstellt.

```{r}
# Preparation of Dataframe with 
df_cons_predict <- df_cons %>%
  drop_na(loan_status) %>%
  select(c(1, 23, 25, 27, 29, 34, 35, 189 ,190, 191)) 

df_cons_predict$loan_in_dept <- gsub("TRUE", "Yes",
                               gsub("FALSE", "No", df_cons_predict$loan_in_dept))

df_cons_predict$loan_in_dept <- as.factor(df_cons_predict$loan_in_dept)
  
# Checking Data
summary(df_cons_predict)
```

Aufteilung der Daten in Trainings- und Testsätze

Die split Methode wird verwendet, um die Daten in Trainings- und
Testsätze aufzuteilen. Der Datensatz wird in loan_train und loan_test
unterteilt. Das loan_test Set wird verwendet um festzustellen, ob das
Modell die richtigen Ausgaben vorhersagt.\
Es wird empfohlen, die Trainingsmengen größer zu halten als die
Testmengen.

Trainingsdatensatz: Der Trainingsdatensatz wird für die Anpassung des
Modells verwendet. Der Datensatz, auf dem das Modell trainiert wird.

Testdatensatz: Der Testdatensatz ist eine Teilmenge des
Trainingsdatensatzes, die verwendet wird, um eine genaue Bewertung der
endgültigen Anpassung des Modells zu erhalten.
\
Unausgeglichener Datensatz

```{r}
prop.table(table(df_cons_predict$loan_in_dept))
table(df_cons_predict$loan_in_dept)
```

Wie mit prop.table dargestellt, ist die Yes und No Verteilung im
Datensatz sehr unausgeglichen, von den 682 Beobachtungen sind 606 als No
deklariert. Dies liegt hauptsächlich daran, dass die meisten Kunden ihre
Kredite zurückzahlen. Dieses Problem kann mit over- oder undersamplig
gelöst werden. Durch oversampling werden nun künstliche Yes Werte
generiert um einen ausgeglichenen Datensatz zu erstellen.

```{r}
data_balanced_over <- ovun.sample(loan_in_dept ~ ., data = df_cons_predict, method = "over",N = 1212)$data
```

Im Code bezieht sich N auf die Anzahl der Beobachtungen welche das
angepasst Datensatz nach dem oversampling haben wird. Da sich im
originalen Datensatz 606 Yes Werte befinden, sollten die No Werte im
angepasste Datensatz diesen Wert nicht übersteigen. Allerdings sollten
auch nicht zu viele Yes Werte künstlich generiert werden, da dies die
Aussagekraft des Modells verschlechtern kann. Somit erscheint ein Wert
von N = 1212 als sinnvoll.

```{r}
prop.table(table(data_balanced_over$loan_in_dept))
table(data_balanced_over$loan_in_dept)

df_cons_predict <- data_balanced_over
```

Der angepasste Datensatz kann jetzt in in Trainings- und Testsätze
aufgeteilt werden.

```{r}
# splitting the data into training and test sets
set.seed(321)
sample <- sample.int(n = nrow(df_cons_predict), size = floor(.80*nrow(df_cons_predict)), replace = F)
loan_train <- df_cons_predict[sample, ]
loan_test  <- df_cons_predict[-sample, ]


# Size of traiing and test set
dim(loan_train)
dim(loan_test)
```

Verteilung der Yes und No Werte im Trainings- und Testdatensatz

```{r}
prop.table(table(loan_train$loan_in_dept))
prop.table(table(loan_test$loan_in_dept))
```

##### Decision Tree / Entscheidungsbaum[^126]

[^126]: Erstellt von Christian Heeb

Ein Entscheidungsbaum ist eine Art des supervised machine learning, das
zur Kategorisierung oder zur Erstellung von Vorhersagen auf der
Grundlage der Antworten auf eine frühere Reihe von Fragen verwendet
wird.

Durch die Anwendung dieses Modells erhoffen wir uns Attribute zu
definieren welche ein prägende Rolle spielen bei der Rückzahlung von
Krediten. Dazu wird ein Entscheidungsbaum mithilfe der loan_train Daten
erstellt.

```{r warning=FALSE}
# Building Decision Tree
set.seed(321)
dtree_loan <- rpart(loan_in_dept ~ loan_duration_in_month + loan_per_year + age_dec1999 + owner_sex + income_avg + outgoes_avg, 
               data = loan_train, 
               method = "class",
               control = rpart.control(cp = 0.0001))

# Plotting first draft of Tree, digits argument rounds numbers acording to value (-3) 
rpart.plot(dtree_loan, digits=-3)
```

Kreuzvalidierung zur Bestimmung der optimalen Größe des
Klassifikationsbaumes. Die Baumgrösse kann gesteuert werden, indem ein
sogenannter cp-Werte (complexity parameter) festgesetzt wird.

```{r}
plotcp(dtree_loan)
printcp(dtree_loan)
```

Die Spalten in der Ausgabe listen die cp-Werte, die zugehörige Anzahl
der Splits (nsplit), den relativen Fehler (rel error) bezogen auf den
Fehler im Wurzelknoten auf. Wie man der Tabelle, entnehmen kann, ist der
xerror + xstd bei 28 Blättern, also bei 27 Splits am kleinsten. Daraus
können wir einen optimalen cp-Wert von 0.00724638 ablesen.

```{r}
# Decision Tree with modifyled cp-Value
set.seed(321)
dtree_pruned <- rpart(loan_in_dept ~ loan_duration_in_month + loan_per_year + age_dec1999 + owner_sex + income_avg + outgoes_avg, 
               data = loan_train, 
               method = "class",
               control = rpart.control(cp = 0.00724638))

# Plotting pruned Tree
rpart.plot(dtree_pruned, split.prefix = "if ", fallen.leaves = TRUE, shadow.col = "gray", digits=-3, main = "Is Customer in Dept?\n(Training Data)")

# Numerical output of the tree
#dtree_pruned
```

Genauigkeit des Modells mit predict-Funktion und Confusion-Matrix
bestimmen

```{r}
dtred_pred_train <- predict(dtree_pruned, loan_train, type="class")

# Creating Confusion Matrix
confusion_matrix_train  <- table(loan_train$loan_in_dept, dtred_pred_train)
confusion_matrix_train


# Calculating accuracy 
accuracy_train <- sum(diag(confusion_matrix_train)) / sum(confusion_matrix_train)



paste("Genauigkeit des Modells: ", round((accuracy_train * 100), digits = 2), "%" )

```

Mithilfe der Confusion Matrix können wir unser Klassifikationsmodell
evaluieren. Die zweidimensionale Matrix stellt die vorhergesagten
Klassen steht sowie die tatsächlichen Klassen dar. Daraus kann abgelesen
werden, dass das Modell einen grossen Teil richtig klassifiziert hat.
Lediglich 108 Kunden wurden falsch klassifiziert.

\
Testen des Modells mithilfe des loan_test Datensatzes

```{r}
dtree_pred_test <- predict(dtree_pruned, loan_test, type="class")

# Creating Confusion Matrix
confusion_matrix_test  <- table(loan_test$loan_in_dept, dtree_pred_test)
confusion_matrix_test


# Calculating accuracy 
accuracy_test <- sum(diag(confusion_matrix_test)) / sum(confusion_matrix_test)

paste("Genauigkeit des Modells: ", round((accuracy_test * 100), digits = 2), "%" )
```

##### Random Forest[^126]

[^126]: Erstellt von Christian Heeb

Bei Random Forests werden viele Entscheidungsbäume gleichzeitig erstellt, wobei bei
jedem Baum nur eine Teilmenge der Daten genutzt wird. Für die Prognose
der Klasse eines neuen Objekts wird eine Mehrheitsentscheidung der Bäume
gefällt (majority vote). Es erfolgt kein Pruning der einzelnen Bäume, da
man davon ausgeht, dass sich Overﬁttingprobleme aufgrund der
verschiedenen Teilmengen ausgleichen und daher kein Problem mehr
darstellen.

Für den Aufbau des Random Forest erfolgt eine Zufallsauswahl auf zwei
Ebenen:

1.  Es wird bei jedem Split nur eine zufällig ausgewählte Teilmenge der
    möglichen Splitvariablen benutzt.

2.  Für jeden Baum werden Bootstrap-Stichproben aus der gesamten Datei
    gezogen. Bei Bootstrap-Stichproben werden aus der gesamten Datei mit
    n Objekten nach dem Zufallsprinzip Stichproben wiederum der Größe n
    gezogen. Die Ziehung erfolgt mit Zurücklegen, d. h. dasselbe Objekt
    kann auch mehrfach in eine Stichprobe gelangen.

Erstellen des Modells mit den loan_train Daten.

```{r}
set.seed(321)
# Creating of Random Forest Model (default Number of Trees = 100, na.action = na.omit removes incomplete cases)
rf_model <- randomForest(as.factor(loan_in_dept) ~ loan_duration_in_month + loan_per_year + age_dec1999 + owner_sex + income_avg + outgoes_avg, 
                   data = loan_train,
                   na.action = na.omit,
                   importance=TRUE)

# Output the total error rate
plot(rf_model)


```

Der Ausgabe können wir die Gesamtfehlerrate (schwarze Linie), die Rate
der fälschlicherweise als korrekt prognostizierten (grüne Linie) und die
fälschlicherweise als falsch prognostizierten (rote Linie) Objekte
entnehmen. In der Graﬁk sind die Werte für random forests mit 500 Bäumen
dargestellt. Bei spätestens 150 Bäumen stabilisieren sich alle Werte.
Daher führen wir die Analyse nochmals mit 150 Bäumen durch.

```{r}
set.seed(321)
rf_model_150 <- randomForest(as.factor(loan_in_dept) ~ loan_duration_in_month + loan_per_year + age_dec1999 + owner_sex + income_avg + outgoes_avg, 
                   data = loan_train,
                   na.action = na.omit,
                   importance = TRUE,
                   ntree = 150)

rf_model_150

# Output the total error rate
plot(rf_model_150)
```

Das Summary zeigt verschiedenen Angaben des Modells wie Art des Modells,
Anzahl Trees (von uns auf 150 gesetzt), sowie die OOB estimate of error
rate in Prozent. OOB steht für Out-Of-Bag Samples. OOB Samples sind
solche welche nicht im Bootstraped Dataset aufgenommen wurden.

Genauigkeit des Modells mit predict-Funktion und Confusion-Matrix and
den test Daten bestimmen

```{r}

rf_pred_test <- predict(rf_model_150, loan_test)

# Creating Confusion Matrix
rf_confusion_matrix_test  <- table(loan_test$loan_in_dept, rf_pred_test)
rf_confusion_matrix_test

# Calculating accuracy 
rf_accuracy_test <- sum(diag(rf_confusion_matrix_test)) / sum(rf_confusion_matrix_test)


paste("Genauigkeit des Modells: ", round((rf_accuracy_test * 100), digits = 2), "%" )
```

Mithilfe der Confusion Matrix können wir unser Klassifikationsmodell
evaluieren. Die zweidimensionale Matrix stellt die vorhergesagten
Klassen steht sowie die tatsächlichen Klassen dar. Daraus kann abgelesen
werden, dass das Modell einen grossen Teil richtig klassifiziert hat.

Anwenden des Modells auf den Gesamten Datensatz

```{r}
rf_pred_all <- predict(rf_model_150, df_cons_predict)

# Creating Confusion Matrix
rf_confusion_matrix_all  <- table(df_cons_predict$loan_in_dept, rf_pred_all)
rf_confusion_matrix_all

# Calculating accuracy 
rf_accuracy_all <- sum(diag(rf_confusion_matrix_all)) / sum(rf_confusion_matrix_all)



paste("Genauigkeit des Modells: ", round((rf_accuracy_all * 100), digits = 2), "%" )
```

Wichtigkeit der Variablen (Importance)

Neben der Bewertung der Gesamtleistung des Modells ist es auch nützlich,
die relative Bedeutung der verschiedenen Eingabevariablen für die
Vorhersagen des Modells zu untersuchen. Indem wir die Verbesserung mit
den Trainingsiterationen untersuchen, können wir auch Einblicke in den
Lernprozess des Modells gewinnen.

Das angegebene Maß für die relative Wichtigkeit ist der Gesamtrückgang
der Knotenverunreinigungen durch die Aufteilung auf diese Variable,
gemittelt über alle Bäume.\

```{r}
# Calculate  importance of Model
importance(rf_model_150, type = 2)

```

In unseren Modellen ist die wichtigste Variable loan_per_year und die
unwichtigste ist owner_sex.

Alternativ kann die importance auch in einem Variable Importance Plot
dargestellt werden

```{r}
varImpPlot(rf_model_150, pch = 20)
```

Der Variable Importance Plot ist ein grundlegendes Ergebnis des Random
Forest und zeigt für jede Variable, wie wichtig sie für die
Klassifizierung der Daten ist.\
Die Grafik "Mean Decrease Accuracy" drückt aus, wie viel Genauigkeit das
Modell durch den Ausschluss jeder Variable verliert. Je mehr die
Genauigkeit leidet, desto wichtiger ist die Variable für eine
erfolgreiche Klassifizierung. Die Variablen werden in absteigender
Reihenfolge ihrer Bedeutung dargestellt.\
Der "Mean Decrease Gini" Koeffizient ist ein Maß dafür, wie jede
Variable zur Homogenität der Knoten und Blätter im Random Forest
beiträgt. Ein Knoten wird als "reiner" betrachtet, wenn er nur Instanzen
einer Klasse enthält. Ein Knoten ist umso reiner, je niedriger der
Gini-Koeffizient ist. Der Gini-Koeffizient berechnet sich aus der Summe
der Wahrscheinlichkeiten, dass eine zufällig ausgewählte Instanz in
einem Knoten der Klasse i zugeordnet ist, multipliziert mit der
Wahrscheinlichkeit, dass eine zufällig ausgewählte Instanz nicht der
Klasse i zugeordnet ist. Für Entscheidungsbaum-Algorithmen, welche die
Gini-Impurity als Auswahlkriterium verwenden, werden bei jeder Stufe des
Baumes die Merkmale ausgewählt, die dazu beitragen, die Gini-Impurity zu
minimieren, also die Knotenreinheit zu maximieren, so das sich in jedem
Knoten eine Klasse bildet.\

Quelle: Von der Hude, M. (2020). *Predictive Analytics und Data Mining*
(S. 137 -166). Springer



#### Wie seiht das Verhältnis der der Verwendung von verschiedenen Zahlungsmittel in abhängigkeit der Zeit aus?[^127]

[^127]: Erstellt von Christian Heeb

```{r, warning = FALSE}
df_transaction_complete %>%
  filter(operation %in% c("CASH CREDIT", "CASH WIDTHDRAWAL", "COLLECTION OTHER BANK", "CREDIT CARD WITHDRAWAL", "REMITTANCE OTHER BANK")) %>%
  ggplot(mapping = aes(x = date, fill = operation)) +
  geom_histogram(binwidth = 5) +
  facet_wrap(~ operation, ncol = 2, scales = "free_y") +
  labs(title = "Overwiev distribution of Transaction methods used from 1993 to 1999 ", 
       subtitle = "Y-axis set independently",
       caption = "Source: PKDD’99 Discovery Challenge",
       fill = "Method of Transaction" ) +
  xlab("Years") +
  ylab("Count") +
  theme(legend.position = "none") +
  scale_x_date(date_labels="%y",date_breaks ="1 year", date_minor_breaks = "1 month") +
  theme(axis.text.x = element_text(size = 8, angle=90,vjust =0.2))

```

Der Facet-plot zeigt eine Übersicht der verwendeten Transaktionsmethoden
von 1993 bis 1999. In der Grafik wird ersichtlich, dass alle
Transaktionen kontinuierlich zugenommen haben und einem monatlichen oder
Jährlichen Zyklus folgen. Der Rückgang der Bezüge im Bereich "Credit
Card Withdrawal" und "Cash Withdrawal" im Jahr 1999 ist damit zu
begründen, dass wahrscheinlich noch weitere Bezüge nach dem
Jahreswechsel getätigt wurden, da die gespeicherten Daten aber nur bis
zum 31.12.1999 reichen, wurden diese Bezüge nicht aufgezeichnet.

#### Analyse der Kundengruppe welche eine Gold-Kreditkarte verwendet[^128]

[^128]: Erstellt von Christian Heeb

```{r}
# Overview of Card tpyes used
df_cons %>%
  group_by(card_type) %>%
  ggplot(aes(x = card_type, fill = card_type)) +
  geom_bar() +
  geom_text(aes(label=..count..), vjust = "bottom", stat = 'count') +
  labs(title = "Distribution of Credit Card Types", 
       subtitle = "",
       caption = "Source: PKDD’99 Discovery Challenge",
       fill = "Type of Credit Card" ) +
  xlab("Type of Credit Card") +
  ylab("Number of Users") +
  theme(legend.position = "none")
```

Das Balkendiagramm zeigt die Verteilung der verschiedenen Kreditkarten
Typen. 3608 der insgesamt 4500 Kunden besitzen keine Kreditkarte oder
sie ist nicht angegeben. Von den Kreditkartenbesitzern besitzt der
grösste Teil eine "Classic" Karte (659 Kunden). Insgesamt 145 Kunden
besitzen eine "Junior" Karte. Diese ist nur für Kunden unter 25 Jahren
verfügbar. Die restlichen Kunden besitzen eine "Gold" Kreditkarte. Da
diese Kundengruppe für die Bank interessant ist, möchten wir sie im
nächsten Abschnitt näher untersuchen.

```{r}
# Summarize all Cusotmers with Gold Card and list Attributes
gold_card <- df_cons %>%
  filter(card_type == "GOLD")
  
# Create Picture of average Gold Card user
cardplot1 <- gold_card %>%
  ggplot(gold_card, mapping = aes(x = age_dec1999, color = age_dec1999)) +
  geom_boxplot(fill = "#CE76FC") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Age of Cardholder", 
           subtitle = "", 
           caption = "",
           y = "", x = "Age") +
  coord_flip()

cardplot4 <- gold_card %>%
  ggplot(gold_card, mapping = aes(x = owner_sex, fill = owner_sex)) +
  geom_bar() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Distribution of Gender ", 
           subtitle = "", 
           caption = "Source: PKDD’99 Discovery Challenge",
           y = "Count", x = "")
 
cardplot2 <- gold_card %>%
  ggplot(gold_card, mapping = aes(x = income_avg / 12)) +
  geom_boxplot(fill = "#FC7870") +
  xlim(0,100000) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Monthly income of Cardholder", 
           subtitle = "", 
           caption = "",
           y = "", x = "Income [CZK]") +
  coord_flip()

cardplot3 <- gold_card %>%
  ggplot(gold_card, mapping = aes(x = outgoes_avg / 12, fill = age_dec1999)) +
  geom_boxplot(fill = "#FF64B0") +
  xlim(0,100000) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill=NA, size=0.5)) +
  labs(title = "Monthly expenses by cardholder", 
           subtitle = "", 
           caption = "",
           y = "", x = "Expenses [CZK]") +
  coord_flip()

cardplot5 <- gold_card %>%
  group_by(account_district_region) %>%
  mutate(count_region =n()) %>%
  ggplot(gold_card, mapping = aes(x = reorder(account_district_region, -count_region), fill = account_district_region)) +
  geom_bar() +
  theme(axis.text.x = element_text(size = 10, angle = 60, vjust = 0.9, hjust = 0.9),
        legend.position = "none",
        plot.background = element_rect(colour = "black", fill = NA, size = 0.5)) +
  labs(title = "Region of Residence", 
           subtitle = "", 
           caption = "Source: PKDD’99 Discovery Challenge",
           y = "Count", x = "")

nested_cardplot <- (cardplot1|cardplot2|cardplot3|cardplot4/(cardplot5)) 
nested_cardplot

```

Die Abbildung oben zeigt fünf verschiedene Plots, welche alle Attribute
von Kunden mit Gold-Status Kreditkarten aufzeigen. Ziel ist es
aufzuzeigen, welche Durchschnittliche Eigenschaften eine solcher Kunde
aufweist, um herauszufinden welche weiteren Kunden für diese spezielle
Kreditkarte in Frage kommen.



### Korrelationsanalyse zwischen den Bankdaten und den
soziodemografischen Daten.[^123]

[^123]: Erstellt von Luca Gisler

#### Distribution von Kunden in den Distrikten im Bezug
zu den restlichen Einwohnern

[^129]: Erstellt von Luca Gisler


```{r}
#create new df
df_owner_over_district_size <- df_cons %>% 
  #select the wanted Informations Age, district, sex for both owner and user
  select(
    account_district_inhabitants,
    account_district_name)

#count ammount of accountsi per district
new_version_count <- df_owner_over_district_size %>% count(account_district_name) %>% 
  arrange(desc(n))

#remove doublicates
df_owner_over_district_size <- df_owner_over_district_size %>% 
  distinct(account_district_inhabitants, .keep_all = TRUE) %>% 
  arrange(desc(account_district_inhabitants))

#put the two dftogether to get the right variables
combined_owner_over_district_size <- full_join(df_owner_over_district_size, new_version_count, by = "account_district_name" ) %>% 
  distinct(account_district_inhabitants, .keep_all = TRUE) %>% 
  relocate(n, .after = account_district_inhabitants) %>% 
  arrange(desc(account_district_inhabitants))

#check data
sum(combined_owner_over_district_size$n)

#calculate percentage of accountowner in every district
combined_owner_over_district_size <- combined_owner_over_district_size %>% 
  mutate(percentage_of_district_own_account = n/account_district_inhabitants*100)


#show the districts with the lowest percentage
head(combined_owner_over_district_size %>% arrange(percentage_of_district_own_account),30)

#show the districts with highest percentage
head(combined_owner_over_district_size %>% arrange(desc(percentage_of_district_own_account)),30)

```

Wir sehen In den grösseren Distrikten ist gibt es Prozentual weniger Kunden als in den kleinen. Als direkter Vergleich: Ceske Budejovice der Bezirk mit dem kleinsten Anteil an Kontoinhabern hat eine Einwohnerzahl von Insgesamt 177'686. Und der Bezirk mit dem grössten Anteil hat eine Grösse von 42'821 Einwohnern.
Ein Ansatz für die Bank ist, die Präsenz in den Distrikten mit niedrigem Prozentsatz ihre Präsenz zu verstärken. Um somit mehr Kunden in diesen Bezirken zu generieren.
Zusätzlich kann bei bestehenden Kunden ein Profitprogramm Eingeführt werden um neue Kunden zu akquirieren Damit ist gemeint, dass bestehende Kunden durch Akquisition gewisse Vorteile erhalten können.


#### Entwicklung des Einkommens im Bezug zu begangenen Straftaten[^130]

[^130]: Erstellt von Luca Gisler



Für diese Aufgabe beschränken wir uns auf die Jahre 1995 und 1996, da
und nur in diesen Jahren die Arbeitslosenrate und Kriminalität zur
Verfügung  steht.

```{r, error=FALSE}
#prepare new df to join with df_district_mod
district_new_name <- df_district %>% 
  rename(account_district_name = name)


#join dfcons with district_new_names
df_crimes_cons <- inner_join(df_cons, district_new_name, by = "account_district_name") %>% 
  filter(unemployment_rate_95 != "NA",
         unemployment_rate_96 != "NA",
         commited_crimes_95 != "NA",
         commited_crimes_96 != "NA",
         salary_groups != "NA")

 
#check data district number comparison
head(df_crimes_cons)

# Einkommen pro Monat 
incomes_per_month <- df_transaction_complete %>%
  group_by(
    account_id,
    year(date),
    month(date)
  ) %>%
  summarise(incomes_per_month = round(sum(incomes), digits = 0)) %>% 
  ungroup()

# monatliche Einkommen und Ausgaben und die Vermögensentwicklung
in_out_monthly <- incomes_per_month %>% 
  filter(incomes_per_month != 0) %>% 
  rename(year = `year(date)`,
         month = `month(date)`)


in_out_monthly <- incomes_per_month %>% 
  filter(incomes_per_month != 0) %>% 
  rename(year = `year(date)`,
         month = `month(date)`) 

in_out_yearly <- in_out_monthly %>% 
  group_by(account_id, year) %>% 
  summarise(incomes_per_year = round(mean(incomes_per_month), digits = 0) * 12) %>% 
  ungroup()



# Anfügen der Information an die Monatsübersicht
in_out_monthly <- in_out_monthly %>% 
  left_join(in_out_yearly, by = c("account_id", "year"))

in_out_yearly <- in_out_monthly %>% 
  group_by(account_id, year) %>% 
  summarise(incomes_per_year = round(mean(incomes_per_month), digits = 0) * 12) %>% 
  ungroup()


#prepare unemploymentrate for 1995 1996

in_out_yearly_crime_unemployment <- in_out_yearly [!(in_out_yearly$year=="1993" | in_out_yearly$year=="1994" | in_out_yearly$year=="1997" | in_out_yearly$year=="1998"),]

#check Data
in_out_yearly_crime_unemployment

```

Es wurden die nötigen Spalten in einem neuen DF hinzugefügt. Damit mit
der Kriminalität und Arbeitslosenrate gearbeitet werden kann.

```{r}

#plot salary 1995-1996 change appearence
in_out_yearly_crime_unemployment %>% 
  ggplot(aes(x = as.factor(year), y = incomes_per_year, fill = year)) +
  geom_boxplot() +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Incomes development") +
  labs(
    x = "",
    y = "Amount per year [CZK]",
    subtitle = "Time span: 1995-1996, across all accounts")


#plot unemploymentrate 1995
df_crimes_cons %>%
  ggplot(aes(x= unemployment_rate_95,
         group = salary_groups,
         fill = salary_groups))+
  labs(title = "Unemployment rate 1995",
       subtitle = "grouped by salary groups",
       x ="Unemployment Rate [%] ",
       y = "Density",
       fill = "Salary groups")+

  geom_density(adjust=1.5, alpha=.4)



#plot unemploymentrate 1996
df_crimes_cons %>%
  ggplot(aes(x= unemployment_rate_96,
         group = salary_groups,
         fill = salary_groups))+
  labs(title = "Unemployment rate 1996",
       subtitle = "grouped by salary groups",
       x ="Unemployment Rate [%]",
       y = "Density",
       fill = "Salary groups")+

  geom_density(adjust=1.5, alpha=.4)



```

Erkenntnisse bezüglich dem Einkommen, wie bereits in einer anderen
Fragestellung erläutert, gäbe es 1996 einen leichten Einbruch. Im
Vergleich mit der Arbeitslosenrate, sehen wir, dass in den höheren Einkommensgruppen
Kategorie im Jahr 1996 einen leichten Anstieg bei der Rate von 7.5% gab.
Dies kann einen grossen Einfluss gehabt haben, denn die höheren Einkommensgruppen
machen eben durch Ihre Grösse ein Grossteil des Volumens aus. Als die Arbeitslosenrate im Jahr
1995 im gleichen Bereich eine Abflachung im Schrumpfen der
Arbeitslosigkeit erfuhr, ist sie im 1996 bei den höheren Einkommen noch einen leichten Anstieg, mit 
angestiegen.


Überprüfung ob die Kriminalitätsrate einen Einfluss auf die
Einkommensentwicklung hat.

```{r}
#plot salary 1995-1996 change appearence
in_out_yearly_crime_unemployment %>%
ggplot(aes(x = as.factor(year), y = incomes_per_year, fill = year)) +
  geom_boxplot() +
    theme_minimal() +
    theme(
      legend.position = "none",
      plot.title = element_text(size = 15)
    ) +
    ggtitle("Incomes development") +
  labs(
    x = "",
    y = "Amount per year [CZK]",
    subtitle = "Time span: 1995-1996, across all accounts")



#plot crime rate 1995
df_crimes_cons %>%
  ggplot(aes(x= commited_crimes_95,
         group = salary_groups,
         fill = salary_groups))+
  labs(title = "Crime rate 1995",
       subtitle = "grouped by salary groups",
       x ="Crime Rate ",
       fill = "Salary groups")+

  geom_density(adjust=1.5, alpha=.4)



#plot crime rate 1996
df_crimes_cons %>%
  ggplot(aes(x= commited_crimes_96,
         group = salary_groups,
         fill = salary_groups))+
  labs(title = "Crime rate 1996",
       subtitle = "grouped by salary groups",
       x ="Crime Rate",
       fill = "Salary groups")+

  geom_density(adjust=1.5, alpha=.4)
```

Zwischen dem Einkommen und Kriminalitätsrate erkennen wir hier keinen
Zusammenhang. Die Kriminalitätsrate verändert sich von 1995 auf 1996
kaum. Somit ist die Einkommensentwicklung unabhängig von der
Kriminalitätsrate zu betrachten.


v\. Kann man Unterschiede herleiten, um Geschäfts- und Privatkunden zu
unterteilen?

[^1212]
[^1212]: Erstellt von Luca Gisler

Diese Frage ist in diesem Sinne interessant, dass man im Bereich des
Cross Sellings unterschiedliche Angebote für Geschäfts- und Privatkunden
ausarbeiten kann. Denn diese zwei Kundengruppen haben andere Ansprüche
und eine andere Beziehung zur Bank.

Eine Möglichkeit um herauszufinden ob es ein Geschäftskonto ist, wenn
viele Nutzer einer Karte die gleiche Adresse besitzen. Dann kann man
darauf schliessen, dass dies der Sitz und die Adresse der Firma ist.

Da wir über keine Adressen verfügen ist dieser Ansatz eine Sackgasse.

Kann man anhand von Transaktionen ein Geschäftskonto erkennen?

INSURRANCE - Ein Unternehmen muss auch Versicherungen bezahlen, deshalb
ist dieser Transaktionstyp kein sicheres Ausscheide Kriterium.
HOUSEHOLD - Hat ein Unternehmen Ausgaben die den Haushalt betreffen? Ein
Unternehmen zahlt Löhne, Mieten, Versicherungen. Wir vermuten dass ein
Unternehmen keine Ausgaben im Bereich Haushalt hat. Aber was ist wenn
eine Festlichkeit  ansteht? Dann fallen diese Ausgaben auch in den
Bereich des Haushaltes. Also kein Kriterium für das sichere
Identifizieren. LEASING - Ein Unternehmen kann auch ein Auto leasen,
also ist das kein sicheres Ausscheide Kriterium.

Ist es möglich anhand der Owner/User Kombination ein Geschäftliches
Konto zu erkennen?

Wenn es viele User mit unterschiedlichen Adressen auf einen Owner gibt,
könnte dies ein Indiz dafür sein, ein Geschäftskonto zu sein.

Auch diesen Ansatz wurde Verworfen, bei den Owner / User ist und ein
Muster Aufgefallen.

Für dieses Beispiel wurde die Alter bei Eröffnung des Kontos verglichen.

```{r}
#filter for the ages 30 and 50
age_correaltions_owner_user <-df_cons %>% filter((owner_age_at_account_opening == "50" | owner_age_at_account_opening == "30")) %>% 
  filter(user_age_at_account_opening != "NA") %>%  #remove all NA for this example
  #select the wanted Informations Age, district, sex for both owner and user
  select(
    owner_age_at_account_opening,
    owner_sex,
    user_age_at_account_opening,
    user_sex,
    owner_district_id,
    user_district_id
  )
#show the first 30 entries
head(age_correaltions_owner_user, 30)

```

Wir haben die Alter für diese Tabelle auf 30 und 50 festgelegt, und
können somit dieses erkannte Muster aufzeigen. Das Alter des Konto
Inhabers und das Alter des weiteren Benutzer (falls vorhanden) bewegt
sich im gleichen Altersbereich mit gewissen Abweichungen. Das Geschlecht
ergänzt sich auch so, dass wir annehmen können, dass diese Verbindung
eine Private und somit keine Geschäftliche Beziehung darstellt. Diese
Theorie wird noch davon gestützt, dass die Owner und User immer im
gleichen District Wohnhaft sind.

Aufgrund dieser Erkenntnisse sind wir auf den Schluss gekommen, dass man
Geschäfts- und Privatkunden anhand unserer Erkenntnisse nicht
unterteilen kann.

vi\. Wie sieht die Entwicklung der Kredite in Bezug auf Typ und Dauer
aus? Kann aus der Grafik ein Trend ausgelesen werden?

[^1212]
[^1212]: Erstellt von Luca Gisler

```{r}

#prepare informations, removed NAs and plot
Loan_trend_over_time <- df_cons %>%
  filter(loan_status != "NA") %>%
  ggplot(Loan_trend_over_time, mapping = aes(x = loan_start_date,
                                y = loan_duration_in_month)) +
  
  #add jittering for visability
  geom_jitter()+
  #add geom_smooth for visual trend changes
  geom_smooth()+
  #new Title, axis-labels
  labs(title = "Loan duration over Time")+
  xlab("Years")+
  ylab("Loan duration in Month")

#print plot
Loan_trend_over_time
```

Was direkt auffällt ist, dass wir über die Zeit eine Zunahme an neuen
neuen Krediten erkennen. Die Dauer der Kredite hat sich über dir Zeit
nicht spürbar verändert. Um das Jahr 1996 gab es Durchschnittlich
weniger Kredite mit kurzer Dauer als vor und nach dieser Zeit. An der
Regressionslinie ist ein leichter Aufwärtstrend ersichtlich, welche
einen kleinen Dämpfer hatte und zwar um die Jahre 1007 und 1998.

Über den Typ von Krediten kann keine Aussage getroffen werden, da diese
nicht ersichtlich sind. Deshalb können nur Veränderungen über die Zeit
Analysiert werden.

```{r}

#prepare informations, removed NAs and plot
Loan_trend_over_time_ammount <- df_cons %>%
  filter(loan_status != "NA") %>%
  ggplot(Loan_trend_over_time_ammount, mapping = aes(x = loan_start_date,
                                y = loan_total_amount)) +
  
  #add jittering
  geom_jitter()+
  #add geom_smooth for for visual trends
  geom_smooth()+
  scale_y_continuous(labels=comma)+
  #create new title and axis-labels
  labs(title = "Loan um over time")+
  xlab("Years")+
  ylab("Value of Loans [CZK]")

#print plot
Loan_trend_over_time_ammount
```

Die Kreditsumme hat sich über die Zeit nicht wesentlich verändert. Wir
sehen einen Stabiles verhalten der Summe von Krediten. Daraus schliessen
wir, dass es keine wesentlichen Veränderungen im Bereich der
Kreditvergabe, aber auch von Seitens Kreditnehmer gab. Das Volumen der
Kredite hat im in der Grafik von vorhin vergrössert.


#### Aufzeigen von Zusammenhänge im Kreditverhalten der Kunden

Gibt es einen Zusammenhang zwischen den unterschiedlichen Regionen und dem Kreditverhalten (Kreditgrösse, Dauer) von den Kunden? Für eine Optimierung der lokalen Werbekampagnen und Angebote in den entsprechenden Regionen(Cross Selling)[^1212]

[^1212]: Erstellt von Luca Gisler

```{r}
#filter the NAs and create plot
district_loan_correlation <- df_cons %>% 
  filter(!is.na(loan_start_date)) %>%
  ggplot(aes (x = account_district_region,
              y = loan_total_amount))+
  
  #add title and axis names, labels for CZK not in hex
  geom_boxplot()+
  scale_y_continuous(labels=comma)+
  labs(title = "Loan differences in districts",
       subtitle = "Loan size [CZK]")+
  xlab("regions")+
  ylab("Loan size [CZK]")+
  theme(axis.text.x = element_text(angle = 45))

#creat plotly plot, for more informations by hoverinfo
ggplotly(district_loan_correlation)
```

In den Distrikten haben wir einen MIN/MAX unterschied im Median von
58'782 CZK (MAX: east Bohemia 155'178, MIN: west Bohemia 96'396). Das
ist ein grosser Unterschied, auf was ist dieser zurückzuführen?

```{r}
#filter the NAs and create plot
district_loan_correlation_duartion <- df_cons %>% 
  filter(!is.na(loan_start_date)) %>%
  ggplot(aes (x = account_district_region,
              y = loan_duration_in_month))+
  
  #add title and axis names, labels for CZK not in hex  
  geom_boxplot()+
  scale_y_continuous(labels=comma)+
  labs(title = "Loan differences in districts",
       subtitle = "Loan duration")+
  xlab("region")+
  ylab("Loan duration [Monat]")+
  theme(axis.text.x = element_text(angle = 45))

#creat plotly plot, for more informations by hoverinfo
ggplotly(district_loan_correlation_duartion)
```

East Bohemia ist mit einem Median von 48 Monaten (4 Jahre) Kreditdauer
weit über dem anderen Regionen. In den anderen Regionen ist der Median
genau bei 36 Monaten (3 Jahre) Kreditdauer. In Kombination mit der für
Tschechien überdurchschnittlichen Kreditgrösse, kann man das in den
Zusammenhang bringen, das die Dauer und die Kreditgrösse zusammenhängen.

Jetzt werden wir uns die Monatliche Summe pro Region betrachten.

```{r}
#filter the NAs and create plot
district_loan_correlation_monthly_amount <- df_cons %>% 
  filter(!is.na(loan_start_date)) %>%
  ggplot(aes (x = account_district_region,
              y = loan_total_amount/loan_duration_in_month))+
  
  #add title and axis names, labels for CZK not in hex  
  geom_boxplot()+
  scale_y_continuous(labels=comma)+
  labs(title = "Loan differences in districts")+
  xlab("regions")+
  ylab("Loan size / Month [CZK]")+
  theme(axis.text.x = element_text(angle = 45))

#creat plotly plot, for more informations by hoverinfo
ggplotly(district_loan_correlation_monthly_amount)
```

Damit wir einen Einheitlichen Vergleich erstellen können, stellen wir
die Monatlichen Kreditkosten dar. Des weiteren Vergleichen  wir jetzt
diese Grafik mit dem Durchschnittlichen Distrikt Einkommen

Berechnung des Einkommens auf die Region.

```{r}
#calculate average salary per region for compariswon with loan
df_account_region_average_salary <- df_cons %>% 
  group_by(account_district_region) %>% 
  summarise(account_region_average_salary = mean(account_district_average_salary)) %>% 
  arrange(desc(account_region_average_salary))

 

#print the calculated values
df_account_region_average_salary
```

Wir sehen, Prag hat das höchste Einkommen aller Regionen in Tschechien.
Im Vergleich mit den monatlichen Kosten für einen Kredit ist Prag nicht
oben ausgerissen wie hier beim Lohn. Das heisst, in Prag wird MEHR
verdient und somit könnten auch die Angebote in höheren Preisklassen
beworben werden. In Prag könnte die Bank für ihre "STANDARD" und GOLD"
Kreditkarten Werbung machen. Zusätzlich kann die Bank ihre Angebote im
Bereich der Hypotheken bewerben, denn die Städte werden auf Grund der
guten Angebote weiter wachsen, und somit ist der Markt für Hypotheken
auch ein Boomendes Geschäft. Durch die Vergabe von mehr Krediten
verdient die Bank an den Zinsen und kann somit ihren Gewinn steigern und
das Angebot verbessern und wo nötig erweitern.


## Summary:

Ziel dieser Gruppenarbeit war es, aufgrund des vorgegebenen Datensatzes Einsicht in die Transaktionsvorgänge einer Bank zu erhalten, um daraus Erkenntnisse zu gewinnen welche für die Bank im Bereich des cross-selling von Relevanz sein könnten.

In einem ersten Schritt wurden dazu nach erster Sichtung der Daten, Fragestellungen erarbeitet, welche die Gruppe in dieser Arbeit beantworten möchte.

Da der Datensatz von einer Tschechischen Bank stammt und somit auf Tschechisch beschrieben war, musste er in einem ersten Schritt übersetzt werden. Weiter bestand der Datensatz aus mehreren Dateien, welche in einem nächsten Schritt konsolidiert, und zu einem einzigen Datensatz kombiniert wurden.

Der zusammengefasste, konsolidiert Datensatz konnte anschliessend mit verschiedenen Vorgehensweisen der explorativen Datenanalyse bearbeitet werden.

Dazu wurden die Hypothesen unter den Gruppenmittgliedern aufgeteilt und grösstenteils einzeln erarbeitet. Um eine Kontinuität innerhalb der Arbeit zu erhalten, besprachen wir uns mehrere male bezüglich des weiteren Vorgehens. Weiter wurde der erstelle Code in der Gruppe besprochen und verbessert.

Durch diese Gruppenarbeit haben wir gelernt, wie wichtig es ist, unsere Vorgehensweise sorgfältig zu planen und zu gestalten, um sicherzustellen, dass arbeiten nicht mehrere Male oder Parallel durchgeführt werden. Die Arbeit im Team hat es uns ermöglicht, uns gegenseitig mit Ideen zu versorgen und von einer Vielfalt von Perspektiven zu profitieren.

Die Fähigkeiten, die wir in den Bereichen R, Data Wrangling, explorativen Datenanalyse sowie supervised learning erworben haben, werden uns sicher bei zukünftigen Arbeiten sowie im Berufsalltag von Nutzen sein.

Wir freuen uns darauf, die Erkenntnisse dieser Arbeit am 27.01.2023 zu präsentieren. 